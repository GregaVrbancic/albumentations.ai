{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":true,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Albumentations documentation Albumentations is a fast and flexible image augmentation library. The library is widely used industry, deep learning research, machine learning competitions, and open source projects. If you are new to image augmentation, start with articles in the \"Introduction to image augmentation\" section. They describe what image augmentation is, how it can boost deep neural networks' performance, and why you should use Albumentations. Articles in the \"Getting started with Albumentations\" section show how you can use the library for different computer vision tasks: image classification, semantic segmentation, instance segmentation, and object detection. \"API Reference\" contains Albumentations' methods and classes. Introduction to image augmentation What is image augmentation and how it can improve the performance of deep neural networks Why you need a dedicated library for image augmentation Why Albumentations Getting started with Albumentations Installation Image augmentation for classification Mask augmentation for segmentation Bounding boxes augmentation for object detection Other topics Contributing API Reference Index Core API (albumentations.core) Augmentations (albumentations.augmentations) ImgAug Helpers (albumentations.imgaug) PyTorch Helpers (albumentations.pytorch)","title":"Welcome to Albumentations documentation"},{"location":"#welcome-to-albumentations-documentation","text":"Albumentations is a fast and flexible image augmentation library. The library is widely used industry, deep learning research, machine learning competitions, and open source projects. If you are new to image augmentation, start with articles in the \"Introduction to image augmentation\" section. They describe what image augmentation is, how it can boost deep neural networks' performance, and why you should use Albumentations. Articles in the \"Getting started with Albumentations\" section show how you can use the library for different computer vision tasks: image classification, semantic segmentation, instance segmentation, and object detection. \"API Reference\" contains Albumentations' methods and classes.","title":"Welcome to Albumentations documentation"},{"location":"#introduction-to-image-augmentation","text":"What is image augmentation and how it can improve the performance of deep neural networks Why you need a dedicated library for image augmentation Why Albumentations","title":"Introduction to image augmentation"},{"location":"#getting-started-with-albumentations","text":"Installation Image augmentation for classification Mask augmentation for segmentation Bounding boxes augmentation for object detection","title":"Getting started with Albumentations"},{"location":"#other-topics","text":"Contributing","title":"Other topics"},{"location":"#api-reference","text":"Index Core API (albumentations.core) Augmentations (albumentations.augmentations) ImgAug Helpers (albumentations.imgaug) PyTorch Helpers (albumentations.pytorch)","title":"API Reference"},{"location":"contributing/","text":"Contributing All development is done on GitHub: https://github.com/albumentations-team/albumentations If you find a bug or have a feature request file an issue at https://github.com/albumentations-team/albumentations/issues To create a pull request: Fork the repository. Clone the repository locally. Install pre-commit (a library for running pre-commit hooks), black (code formatter) and flake8 (code linter): pip install pre-commit black flake8 Initialize pre-commit : pre-commit install Install albumentations in development mode: pip install -e . [ tests ] Make changes to the code. Run tests: pytest Push the code to your forked repo. Create a pull request to https://github.com/albumentations-team/albumentations","title":"Contributing"},{"location":"contributing/#contributing","text":"All development is done on GitHub: https://github.com/albumentations-team/albumentations If you find a bug or have a feature request file an issue at https://github.com/albumentations-team/albumentations/issues To create a pull request: Fork the repository. Clone the repository locally. Install pre-commit (a library for running pre-commit hooks), black (code formatter) and flake8 (code linter): pip install pre-commit black flake8 Initialize pre-commit : pre-commit install Install albumentations in development mode: pip install -e . [ tests ] Make changes to the code. Run tests: pytest Push the code to your forked repo. Create a pull request to https://github.com/albumentations-team/albumentations","title":"Contributing"},{"location":"api_reference/","text":"Core API (albumentations.core) Composition API (albumentations.core.composition) Serialization API (albumentations.core.serialization) Transforms Interface (albumentations.core.transforms_interface) Augmentations (albumentations.augmentations) Transforms (albumentations.augmentations.transforms) Functional transforms (albumentations.augmentations.functional) Helper functions for working with bounding boxes (albumentations.augmentations.bbox_utils) Helper functions for working with keypoints (albumentations.augmentations.keypoints_utils) ImgAug Helpers (albumentations.imgaug) Transforms (albumentations.imgaug.transforms) PyTorch Helpers (albumentations.pytorch) Transforms (albumentations.pytorch.transforms)","title":"Index"},{"location":"api_reference/augmentations/","text":"Transforms (albumentations.augmentations.transforms) Functional transforms (albumentations.augmentations.functional) Helper functions for working with bounding boxes (albumentations.augmentations.bbox_utils) Helper functions for working with keypoints (albumentations.augmentations.keypoints_utils)","title":"Index"},{"location":"api_reference/augmentations/bbox_utils/","text":"Helper functions for working with bounding boxes (augmentations.bbox_utils) calculate_bbox_area ( bbox , rows , cols ) Calculate the area of a bounding box in pixels. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required rows int Image height. required cols int Image width. required Returns: Type Description int Area of a bounding box in pixels. check_bbox ( bbox ) Check if bbox boundaries are in range 0, 1 and minimums are lesser then maximums check_bboxes ( bboxes ) Check if bboxes boundaries are in range 0, 1 and minimums are lesser then maximums convert_bbox_from_albumentations ( bbox , target_format , rows , cols , check_validity = False ) Convert a bounding box from the format used by albumentations to a format, specified in target_format . Parameters: Name Type Description Default bbox tuple An albumentation bounding box (x_min, y_min, x_max, y_max) . required target_format str required format of the output bounding box. Should be 'coco', 'pascal_voc' or 'yolo'. required rows int Image height. required cols int Image width. required check_validity bool Check if all boxes are valid boxes. False Returns: Type Description tuple A bounding box. Note The coco format of a bounding box looks like [x_min, y_min, width, height] , e.g. [97, 12, 150, 200]. The pascal_voc format of a bounding box looks like [x_min, y_min, x_max, y_max] , e.g. [97, 12, 247, 212]. The yolo format of a bounding box looks like [x, y, width, height] , e.g. [0.3, 0.1, 0.05, 0.07]. Exceptions: Type Description ValueError if target_format is not equal to coco , pascal_voc or yolo . convert_bbox_to_albumentations ( bbox , source_format , rows , cols , check_validity = False ) Convert a bounding box from a format specified in source_format to the format used by albumentations: normalized coordinates of bottom-left and top-right corners of the bounding box in a form of (x_min, y_min, x_max, y_max) e.g. (0.15, 0.27, 0.67, 0.5) . Parameters: Name Type Description Default bbox tuple A bounding box tuple. required source_format str format of the bounding box. Should be 'coco', 'pascal_voc', or 'yolo'. required check_validity bool Check if all boxes are valid boxes. False rows int Image height. required cols int Image width. required Returns: Type Description tuple A bounding box (x_min, y_min, x_max, y_max) . Note The coco format of a bounding box looks like (x_min, y_min, width, height) , e.g. (97, 12, 150, 200). The pascal_voc format of a bounding box looks like (x_min, y_min, x_max, y_max) , e.g. (97, 12, 247, 212). The yolo format of a bounding box looks like (x, y, width, height) , e.g. (0.3, 0.1, 0.05, 0.07); where x , y coordinates of the center of the box, all values normalized to 1 by image height and width. Exceptions: Type Description ValueError if target_format is not equal to coco or pascal_voc , ot yolo . ValueError If in YOLO format all labels not in range (0, 1). convert_bboxes_from_albumentations ( bboxes , target_format , rows , cols , check_validity = False ) Convert a list of bounding boxes from the format used by albumentations to a format, specified in target_format . Parameters: Name Type Description Default bboxes List[tuple] List of albumentation bounding box (x_min, y_min, x_max, y_max) . required target_format str required format of the output bounding box. Should be 'coco', 'pascal_voc' or 'yolo'. required rows int Image height. required cols int Image width. required check_validity bool Check if all boxes are valid boxes. False Returns: Type Description list[tuple] List of bounding box. convert_bboxes_to_albumentations ( bboxes , source_format , rows , cols , check_validity = False ) Convert a list bounding boxes from a format specified in source_format to the format used by albumentations denormalize_bbox ( bbox , rows , cols ) Denormalize coordinates of a bounding box. Multiply x-coordinates by image width and y-coordinates by image height. This is an inverse operation for :func: ~albumentations.augmentations.bbox.normalize_bbox . Parameters: Name Type Description Default bbox tuple Normalized bounding box (x_min, y_min, x_max, y_max) . required rows int Image height. required cols int Image width. required Returns: Type Description tuple Denormalized bounding box (x_min, y_min, x_max, y_max) . Exceptions: Type Description ValueError If rows or cols is less or equal zero denormalize_bboxes ( bboxes , rows , cols ) Denormalize a list of bounding boxes. Parameters: Name Type Description Default bboxes List[tuple] Normalized bounding boxes [(x_min, y_min, x_max, y_max)] . required rows int Image height. required cols int Image width. required Returns: Type Description List[tuple] Denormalized bounding boxes [(x_min, y_min, x_max, y_max)] . filter_bboxes ( bboxes , rows , cols , min_area = 0.0 , min_visibility = 0.0 ) Remove bounding boxes that either lie outside of the visible area by more then min_visibility or whose area in pixels is under the threshold set by min_area . Also it crops boxes to final image size. Parameters: Name Type Description Default bboxes List[tuple] List of albumentation bounding box (x_min, y_min, x_max, y_max) . required rows int Image height. required cols int Image width. required min_area float Minimum area of a bounding box. All bounding boxes whose visible area in pixels. is less than this value will be removed. Default: 0.0. 0.0 min_visibility float Minimum fraction of area for a bounding box to remain this box in list. Default: 0.0. 0.0 Returns: Type Description List[tuple] List of bounding box. filter_bboxes_by_visibility ( original_shape , bboxes , transformed_shape , transformed_bboxes , threshold = 0.0 , min_area = 0.0 ) Filter bounding boxes and return only those boxes whose visibility after transformation is above the threshold and minimal area of bounding box in pixels is more then min_area. Parameters: Name Type Description Default original_shape tuple Original image shape (height, width) . required bboxes List[tuple] Original bounding boxes [(x_min, y_min, x_max, y_max)] . required transformed_shape tuple Transformed image shape (height, width) . required transformed_bboxes List[tuple] Transformed bounding boxes [(x_min, y_min, x_max, y_max)] . required threshold float visibility threshold. Should be a value in the range [0.0, 1.0]. 0.0 min_area float Minimal area threshold. 0.0 Returns: Type Description List[tuple] Filtered bounding boxes [(x_min, y_min, x_max, y_max)] . normalize_bbox ( bbox , rows , cols ) Normalize coordinates of a bounding box. Divide x-coordinates by image width and y-coordinates by image height. Parameters: Name Type Description Default bbox tuple Denormalized bounding box (x_min, y_min, x_max, y_max) . required rows int Image height. required cols int Image width. required Returns: Type Description tuple Normalized bounding box (x_min, y_min, x_max, y_max) . Exceptions: Type Description ValueError If rows or cols is less or equal zero normalize_bboxes ( bboxes , rows , cols ) Normalize a list of bounding boxes. Parameters: Name Type Description Default bboxes List[tuple] Denormalized bounding boxes [(x_min, y_min, x_max, y_max)] . required rows int Image height. required cols int Image width. required Returns: Type Description List[tuple] Normalized bounding boxes [(x_min, y_min, x_max, y_max)] . union_of_bboxes ( height , width , bboxes , erosion_rate = 0.0 ) Calculate union of bounding boxes. Parameters: Name Type Description Default height float Height of image or space. required width float Width of image or space. required bboxes List[tuple] List like bounding boxes. Format is [(x_min, y_min, x_max, y_max)] . required erosion_rate float How much each bounding box can be shrinked, useful for erosive cropping. Set this in range [0, 1]. 0 will not be erosive at all, 1.0 can make any bbox to lose its volume. 0.0 Returns: Type Description tuple A bounding box (x_min, y_min, x_max, y_max) .","title":"Helper functions for working with bounding boxes (augmentations.bbox_utils)"},{"location":"api_reference/augmentations/bbox_utils/#helper-functions-for-working-with-bounding-boxes-augmentationsbbox_utils","text":"","title":"Helper functions for working with bounding boxes (augmentations.bbox_utils)"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils","text":"","title":"albumentations.augmentations.bbox_utils"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area","text":"Calculate the area of a bounding box in pixels. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required rows int Image height. required cols int Image width. required Returns: Type Description int Area of a bounding box in pixels.","title":"calculate_bbox_area()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox","text":"Check if bbox boundaries are in range 0, 1 and minimums are lesser then maximums","title":"check_bbox()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes","text":"Check if bboxes boundaries are in range 0, 1 and minimums are lesser then maximums","title":"check_bboxes()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations","text":"Convert a bounding box from the format used by albumentations to a format, specified in target_format . Parameters: Name Type Description Default bbox tuple An albumentation bounding box (x_min, y_min, x_max, y_max) . required target_format str required format of the output bounding box. Should be 'coco', 'pascal_voc' or 'yolo'. required rows int Image height. required cols int Image width. required check_validity bool Check if all boxes are valid boxes. False Returns: Type Description tuple A bounding box. Note The coco format of a bounding box looks like [x_min, y_min, width, height] , e.g. [97, 12, 150, 200]. The pascal_voc format of a bounding box looks like [x_min, y_min, x_max, y_max] , e.g. [97, 12, 247, 212]. The yolo format of a bounding box looks like [x, y, width, height] , e.g. [0.3, 0.1, 0.05, 0.07]. Exceptions: Type Description ValueError if target_format is not equal to coco , pascal_voc or yolo .","title":"convert_bbox_from_albumentations()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations","text":"Convert a bounding box from a format specified in source_format to the format used by albumentations: normalized coordinates of bottom-left and top-right corners of the bounding box in a form of (x_min, y_min, x_max, y_max) e.g. (0.15, 0.27, 0.67, 0.5) . Parameters: Name Type Description Default bbox tuple A bounding box tuple. required source_format str format of the bounding box. Should be 'coco', 'pascal_voc', or 'yolo'. required check_validity bool Check if all boxes are valid boxes. False rows int Image height. required cols int Image width. required Returns: Type Description tuple A bounding box (x_min, y_min, x_max, y_max) . Note The coco format of a bounding box looks like (x_min, y_min, width, height) , e.g. (97, 12, 150, 200). The pascal_voc format of a bounding box looks like (x_min, y_min, x_max, y_max) , e.g. (97, 12, 247, 212). The yolo format of a bounding box looks like (x, y, width, height) , e.g. (0.3, 0.1, 0.05, 0.07); where x , y coordinates of the center of the box, all values normalized to 1 by image height and width. Exceptions: Type Description ValueError if target_format is not equal to coco or pascal_voc , ot yolo . ValueError If in YOLO format all labels not in range (0, 1).","title":"convert_bbox_to_albumentations()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations","text":"Convert a list of bounding boxes from the format used by albumentations to a format, specified in target_format . Parameters: Name Type Description Default bboxes List[tuple] List of albumentation bounding box (x_min, y_min, x_max, y_max) . required target_format str required format of the output bounding box. Should be 'coco', 'pascal_voc' or 'yolo'. required rows int Image height. required cols int Image width. required check_validity bool Check if all boxes are valid boxes. False Returns: Type Description list[tuple] List of bounding box.","title":"convert_bboxes_from_albumentations()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations","text":"Convert a list bounding boxes from a format specified in source_format to the format used by albumentations","title":"convert_bboxes_to_albumentations()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox","text":"Denormalize coordinates of a bounding box. Multiply x-coordinates by image width and y-coordinates by image height. This is an inverse operation for :func: ~albumentations.augmentations.bbox.normalize_bbox . Parameters: Name Type Description Default bbox tuple Normalized bounding box (x_min, y_min, x_max, y_max) . required rows int Image height. required cols int Image width. required Returns: Type Description tuple Denormalized bounding box (x_min, y_min, x_max, y_max) . Exceptions: Type Description ValueError If rows or cols is less or equal zero","title":"denormalize_bbox()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes","text":"Denormalize a list of bounding boxes. Parameters: Name Type Description Default bboxes List[tuple] Normalized bounding boxes [(x_min, y_min, x_max, y_max)] . required rows int Image height. required cols int Image width. required Returns: Type Description List[tuple] Denormalized bounding boxes [(x_min, y_min, x_max, y_max)] .","title":"denormalize_bboxes()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes","text":"Remove bounding boxes that either lie outside of the visible area by more then min_visibility or whose area in pixels is under the threshold set by min_area . Also it crops boxes to final image size. Parameters: Name Type Description Default bboxes List[tuple] List of albumentation bounding box (x_min, y_min, x_max, y_max) . required rows int Image height. required cols int Image width. required min_area float Minimum area of a bounding box. All bounding boxes whose visible area in pixels. is less than this value will be removed. Default: 0.0. 0.0 min_visibility float Minimum fraction of area for a bounding box to remain this box in list. Default: 0.0. 0.0 Returns: Type Description List[tuple] List of bounding box.","title":"filter_bboxes()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility","text":"Filter bounding boxes and return only those boxes whose visibility after transformation is above the threshold and minimal area of bounding box in pixels is more then min_area. Parameters: Name Type Description Default original_shape tuple Original image shape (height, width) . required bboxes List[tuple] Original bounding boxes [(x_min, y_min, x_max, y_max)] . required transformed_shape tuple Transformed image shape (height, width) . required transformed_bboxes List[tuple] Transformed bounding boxes [(x_min, y_min, x_max, y_max)] . required threshold float visibility threshold. Should be a value in the range [0.0, 1.0]. 0.0 min_area float Minimal area threshold. 0.0 Returns: Type Description List[tuple] Filtered bounding boxes [(x_min, y_min, x_max, y_max)] .","title":"filter_bboxes_by_visibility()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox","text":"Normalize coordinates of a bounding box. Divide x-coordinates by image width and y-coordinates by image height. Parameters: Name Type Description Default bbox tuple Denormalized bounding box (x_min, y_min, x_max, y_max) . required rows int Image height. required cols int Image width. required Returns: Type Description tuple Normalized bounding box (x_min, y_min, x_max, y_max) . Exceptions: Type Description ValueError If rows or cols is less or equal zero","title":"normalize_bbox()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes","text":"Normalize a list of bounding boxes. Parameters: Name Type Description Default bboxes List[tuple] Denormalized bounding boxes [(x_min, y_min, x_max, y_max)] . required rows int Image height. required cols int Image width. required Returns: Type Description List[tuple] Normalized bounding boxes [(x_min, y_min, x_max, y_max)] .","title":"normalize_bboxes()"},{"location":"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes","text":"Calculate union of bounding boxes. Parameters: Name Type Description Default height float Height of image or space. required width float Width of image or space. required bboxes List[tuple] List like bounding boxes. Format is [(x_min, y_min, x_max, y_max)] . required erosion_rate float How much each bounding box can be shrinked, useful for erosive cropping. Set this in range [0, 1]. 0 will not be erosive at all, 1.0 can make any bbox to lose its volume. 0.0 Returns: Type Description tuple A bounding box (x_min, y_min, x_max, y_max) .","title":"union_of_bboxes()"},{"location":"api_reference/augmentations/functional/","text":"Functional transforms (augmentations.functional) add_fog ( img , fog_coef , alpha_coef , haze_list ) Add fog to the image. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default img numpy.ndarray Image. required fog_coef float Fog coefficient. required alpha_coef float Alpha coefficient. required haze_list list required Returns: Type Description numpy.ndarray Image. add_rain ( img , slant , drop_length , drop_width , drop_color , blur_value , brightness_coefficient , rain_drops ) From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default img numpy.ndarray Image. required slant int required drop_length required drop_width required drop_color required blur_value int Rainy view are blurry. required brightness_coefficient float Rainy days are usually shady. required rain_drops required Returns: Type Description numpy.ndarray Image. add_shadow ( img , vertices_list ) Add shadows to the image. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default img numpy.ndarray required vertices_list list required Returns: Type Description numpy.ndarray add_snow ( img , snow_point , brightness_coeff ) Bleaches out pixels, imitation snow. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default img numpy.ndarray Image. required snow_point Number of show points. required brightness_coeff Brightness coefficient. required Returns: Type Description numpy.ndarray Image. add_sun_flare ( img , flare_center_x , flare_center_y , src_radius , src_color , circles ) Add sun flare. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default img numpy.ndarray required flare_center_x float required flare_center_y float required src_radius required src_color int, int, int required circles list required Returns: Type Description numpy.ndarray bbox_crop ( bbox , x_min , y_min , x_max , y_max , rows , cols ) Crop a bounding box. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required x_min int required y_min int required x_max int required y_max int required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A cropped bounding box (x_min, y_min, x_max, y_max) . bbox_flip ( bbox , d , rows , cols ) Flip a bounding box either vertically, horizontally or both depending on the value of d . Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required d int required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A bounding box (x_min, y_min, x_max, y_max) . Exceptions: Type Description ValueError if value of d is not -1, 0 or 1. bbox_hflip ( bbox , rows , cols ) Flip a bounding box horizontally around the y-axis. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A bounding box (x_min, y_min, x_max, y_max) . bbox_rot90 ( bbox , factor , rows , cols ) Rotates a bounding box by 90 degrees CCW (see np.rot90) Parameters: Name Type Description Default bbox tuple A bounding box tuple (x_min, y_min, x_max, y_max). required factor int Number of CCW rotations. Must be in set {0, 1, 2, 3} See np.rot90. required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A bounding box tuple (x_min, y_min, x_max, y_max). bbox_rotate ( bbox , angle , rows , cols ) Rotates a bounding box by angle degrees. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required angle int Angle of rotation in degrees. required rows int Image rows. required cols int Image cols. required Returns: Type Description A bounding box (x_min, y_min, x_max, y_max) . bbox_transpose ( bbox , axis , rows , cols ) Transposes a bounding box along given axis. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required axis int 0 - main axis, 1 - secondary axis. required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A bounding box tuple (x_min, y_min, x_max, y_max) . Exceptions: Type Description ValueError If axis not equal to 0 or 1. bbox_vflip ( bbox , rows , cols ) Flip a bounding box vertically around the x-axis. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A bounding box (x_min, y_min, x_max, y_max) . crop_bbox_by_coords ( bbox , crop_coords , crop_height , crop_width , rows , cols ) Crop a bounding box using the provided coordinates of bottom-left and top-right corners in pixels and the required height and width of the crop. Parameters: Name Type Description Default bbox tuple A cropped box (x_min, y_min, x_max, y_max) . required crop_coords tuple Crop coordinates (x1, y1, x2, y2) . required crop_height int required crop_width int required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A cropped bounding box (x_min, y_min, x_max, y_max) . crop_keypoint_by_coords ( keypoint , crop_coords , crop_height , crop_width , rows , cols ) Crop a keypoint using the provided coordinates of bottom-left and top-right corners in pixels and the required height and width of the crop. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required crop_coords tuple Crop box coords (x1, x2, y1, y2) . required crop height (int Crop height. required crop_width int Crop width. required rows int Image height. required cols int Image width. required Returns: Type Description A keypoint (x, y, angle, scale) . elastic_transform ( img , alpha , sigma , alpha_affine , interpolation = 1 , border_mode = 4 , value = None , random_state = None , approximate = False ) Elastic deformation of images as described in [Simard2003]_ (with modifications). Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5 .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for Convolutional Neural Networks applied to Visual Document Analysis\", in Proc. of the International Conference on Document Analysis and Recognition, 2003. elastic_transform_approx ( img , alpha , sigma , alpha_affine , interpolation = 1 , border_mode = 4 , value = None , random_state = None ) Elastic deformation of images as described in [Simard2003]_ (with modifications for speed). Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5 .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for Convolutional Neural Networks applied to Visual Document Analysis\", in Proc. of the International Conference on Document Analysis and Recognition, 2003. equalize ( img , mask = None , mode = 'cv' , by_channels = True ) Equalize the image histogram. Parameters: Name Type Description Default img numpy.ndarray RGB or grayscale image. required mask numpy.ndarray An optional mask. If given, only the pixels selected by the mask are included in the analysis. Maybe 1 channel or 3 channel array. None mode str {'cv', 'pil'}. Use OpenCV or Pillow equalization method. 'cv' by_channels bool If True, use equalization by channels separately, else convert image to YCbCr representation and use equalization by Y channel. True Returns: Type Description numpy.ndarray Equalized image. fancy_pca ( img , alpha = 0.1 ) Perform 'Fancy PCA' augmentation from: http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf Parameters: Name Type Description Default img numpy array with (h, w, rgb) shape, as ints between 0-255) required alpha how much to perturb/scale the eigen vecs and vals the paper used std=0.1 0.1 Returns: Type Description numpy image-like array as float range(0, 1) grid_distortion ( img , num_steps = 10 , xsteps = (), ysteps = (), interpolation = 1 , border_mode = 4 , value = None ) Reference http://pythology.blogspot.sg/2014/03/interpolation-on-regular-distorted-grid.html iso_noise ( image , color_shift = 0.05 , intensity = 0.5 , random_state = None , ** kwargs ) Apply poisson noise to image to simulate camera sensor noise. Parameters: Name Type Description Default image numpy.ndarray Input image, currently, only RGB, uint8 images are supported. required color_shift float 0.05 intensity float Multiplication factor for noise values. Values of ~0.5 are produce noticeable, yet acceptable level of noise. 0.5 random_state None **kwargs {} Returns: Type Description numpy.ndarray Noised image keypoint_center_crop ( keypoint , crop_height , crop_width , rows , cols ) Keypoint center crop. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required crop_height int Crop height. required crop_width int Crop width. required h_start int Crop height start. required w_start int Crop width start. required rows int Image height. required cols int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) . keypoint_flip ( keypoint , d , rows , cols ) Flip a keypoint either vertically, horizontally or both depending on the value of d . Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required d int Number of flip. Must be -1, 0 or 1: * 0 - vertical flip, * 1 - horizontal flip, * -1 - vertical and horizontal flip. required rows int Image height. required cols int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) . Exceptions: Type Description ValueError if value of d is not -1, 0 or 1. keypoint_hflip ( keypoint , rows , cols ) Flip a keypoint horizontally around the y-axis. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required rows int Image height. required cols int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) . keypoint_random_crop ( keypoint , crop_height , crop_width , h_start , w_start , rows , cols ) Keypoint random crop. Parameters: Name Type Description Default keypoint (tuple): A keypoint (x, y, angle, scale) . required crop_height int Crop height. required crop_width int Crop width. required h_start int Crop height start. required w_start int Crop width start. required rows int Image height. required cols int Image width. required Returns: Type Description A keypoint (x, y, angle, scale) . keypoint_rot90 ( keypoint , factor , rows , cols , ** params ) Rotates a keypoint by 90 degrees CCW (see np.rot90) Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required factor int Number of CCW rotations. Must be in range [0;3] See np.rot90. required rows int Image height. required cols int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) . Exceptions: Type Description ValueError if factor not in set {0, 1, 2, 3} keypoint_rotate ( keypoint , angle , rows , cols , ** params ) Rotate a keypoint by angle. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required angle float Rotation angle. required rows int Image height. required cols int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) . keypoint_scale ( keypoint , scale_x , scale_y ) Scales a keypoint by scale_x and scale_y. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required scale_x int Scale coefficient x-axis. required scale_y int Scale coefficient y-axis. required Returns: Type Description A keypoint (x, y, angle, scale) . keypoint_transpose ( keypoint ) Rotate a keypoint by angle. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required Returns: Type Description tuple A keypoint (x, y, angle, scale) . keypoint_vflip ( keypoint , rows , cols ) Flip a keypoint vertically around the x-axis. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required rows int Image height. required cols( int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) . multiply ( img , multiplier ) Parameters: Name Type Description Default img numpy.ndarray Image. required multiplier numpy.ndarray Multiplier coefficient. required Returns: Type Description numpy.ndarray Image multiplied by multiplier coefficient. optical_distortion ( img , k = 0 , dx = 0 , dy = 0 , interpolation = 1 , border_mode = 4 , value = None ) Barrel / pincushion distortion. Unconventional augment. Reference | https://stackoverflow.com/questions/6199636/formulas-for-barrel-pincushion-distortion | https://stackoverflow.com/questions/10364201/image-transformation-in-opencv | https://stackoverflow.com/questions/2477774/correcting-fisheye-distortion-programmatically | http://www.coldvision.io/2017/03/02/advanced-lane-finding-using-opencv/ posterize ( img , bits ) Reduce the number of bits for each color channel. Parameters: Name Type Description Default img numpy.ndarray image to posterize. required bits int number of high bits. Must be in range [0, 8] required Returns: Type Description numpy.ndarray Image with reduced color channels. preserve_channel_dim ( func ) Preserve dummy channel dim. preserve_shape ( func ) Preserve shape of the image py3round ( number ) Unified rounding in all python versions. solarize ( img , threshold = 128 ) Invert all pixel values above a threshold. Parameters: Name Type Description Default img numpy.ndarray The image to solarize. required threshold int All pixels above this greyscale level are inverted. 128 Returns: Type Description numpy.ndarray Solarized image. swap_tiles_on_image ( image , tiles ) Swap tiles on image. Parameters: Name Type Description Default image np.ndarray Input image. required tiles np.ndarray array of tuples( current_left_up_corner_row, current_left_up_corner_col, old_left_up_corner_row, old_left_up_corner_col, height_tile, width_tile) required Returns: Type Description np.ndarray Output image.","title":"Functional transforms (augmentations.functional)"},{"location":"api_reference/augmentations/functional/#functional-transforms-augmentationsfunctional","text":"","title":"Functional transforms (augmentations.functional)"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional","text":"","title":"albumentations.augmentations.functional"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog","text":"Add fog to the image. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default img numpy.ndarray Image. required fog_coef float Fog coefficient. required alpha_coef float Alpha coefficient. required haze_list list required Returns: Type Description numpy.ndarray Image.","title":"add_fog()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain","text":"From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default img numpy.ndarray Image. required slant int required drop_length required drop_width required drop_color required blur_value int Rainy view are blurry. required brightness_coefficient float Rainy days are usually shady. required rain_drops required Returns: Type Description numpy.ndarray Image.","title":"add_rain()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow","text":"Add shadows to the image. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default img numpy.ndarray required vertices_list list required Returns: Type Description numpy.ndarray","title":"add_shadow()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow","text":"Bleaches out pixels, imitation snow. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default img numpy.ndarray Image. required snow_point Number of show points. required brightness_coeff Brightness coefficient. required Returns: Type Description numpy.ndarray Image.","title":"add_snow()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare","text":"Add sun flare. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default img numpy.ndarray required flare_center_x float required flare_center_y float required src_radius required src_color int, int, int required circles list required Returns: Type Description numpy.ndarray","title":"add_sun_flare()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop","text":"Crop a bounding box. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required x_min int required y_min int required x_max int required y_max int required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A cropped bounding box (x_min, y_min, x_max, y_max) .","title":"bbox_crop()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip","text":"Flip a bounding box either vertically, horizontally or both depending on the value of d . Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required d int required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A bounding box (x_min, y_min, x_max, y_max) . Exceptions: Type Description ValueError if value of d is not -1, 0 or 1.","title":"bbox_flip()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip","text":"Flip a bounding box horizontally around the y-axis. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A bounding box (x_min, y_min, x_max, y_max) .","title":"bbox_hflip()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90","text":"Rotates a bounding box by 90 degrees CCW (see np.rot90) Parameters: Name Type Description Default bbox tuple A bounding box tuple (x_min, y_min, x_max, y_max). required factor int Number of CCW rotations. Must be in set {0, 1, 2, 3} See np.rot90. required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A bounding box tuple (x_min, y_min, x_max, y_max).","title":"bbox_rot90()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate","text":"Rotates a bounding box by angle degrees. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required angle int Angle of rotation in degrees. required rows int Image rows. required cols int Image cols. required Returns: Type Description A bounding box (x_min, y_min, x_max, y_max) .","title":"bbox_rotate()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose","text":"Transposes a bounding box along given axis. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required axis int 0 - main axis, 1 - secondary axis. required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A bounding box tuple (x_min, y_min, x_max, y_max) . Exceptions: Type Description ValueError If axis not equal to 0 or 1.","title":"bbox_transpose()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip","text":"Flip a bounding box vertically around the x-axis. Parameters: Name Type Description Default bbox tuple A bounding box (x_min, y_min, x_max, y_max) . required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A bounding box (x_min, y_min, x_max, y_max) .","title":"bbox_vflip()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords","text":"Crop a bounding box using the provided coordinates of bottom-left and top-right corners in pixels and the required height and width of the crop. Parameters: Name Type Description Default bbox tuple A cropped box (x_min, y_min, x_max, y_max) . required crop_coords tuple Crop coordinates (x1, y1, x2, y2) . required crop_height int required crop_width int required rows int Image rows. required cols int Image cols. required Returns: Type Description tuple A cropped bounding box (x_min, y_min, x_max, y_max) .","title":"crop_bbox_by_coords()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords","text":"Crop a keypoint using the provided coordinates of bottom-left and top-right corners in pixels and the required height and width of the crop. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required crop_coords tuple Crop box coords (x1, x2, y1, y2) . required crop height (int Crop height. required crop_width int Crop width. required rows int Image height. required cols int Image width. required Returns: Type Description A keypoint (x, y, angle, scale) .","title":"crop_keypoint_by_coords()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform","text":"Elastic deformation of images as described in [Simard2003]_ (with modifications). Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5 .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for Convolutional Neural Networks applied to Visual Document Analysis\", in Proc. of the International Conference on Document Analysis and Recognition, 2003.","title":"elastic_transform()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx","text":"Elastic deformation of images as described in [Simard2003]_ (with modifications for speed). Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5 .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for Convolutional Neural Networks applied to Visual Document Analysis\", in Proc. of the International Conference on Document Analysis and Recognition, 2003.","title":"elastic_transform_approx()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize","text":"Equalize the image histogram. Parameters: Name Type Description Default img numpy.ndarray RGB or grayscale image. required mask numpy.ndarray An optional mask. If given, only the pixels selected by the mask are included in the analysis. Maybe 1 channel or 3 channel array. None mode str {'cv', 'pil'}. Use OpenCV or Pillow equalization method. 'cv' by_channels bool If True, use equalization by channels separately, else convert image to YCbCr representation and use equalization by Y channel. True Returns: Type Description numpy.ndarray Equalized image.","title":"equalize()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca","text":"Perform 'Fancy PCA' augmentation from: http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf Parameters: Name Type Description Default img numpy array with (h, w, rgb) shape, as ints between 0-255) required alpha how much to perturb/scale the eigen vecs and vals the paper used std=0.1 0.1 Returns: Type Description numpy image-like array as float range(0, 1)","title":"fancy_pca()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.grid_distortion","text":"Reference http://pythology.blogspot.sg/2014/03/interpolation-on-regular-distorted-grid.html","title":"grid_distortion()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise","text":"Apply poisson noise to image to simulate camera sensor noise. Parameters: Name Type Description Default image numpy.ndarray Input image, currently, only RGB, uint8 images are supported. required color_shift float 0.05 intensity float Multiplication factor for noise values. Values of ~0.5 are produce noticeable, yet acceptable level of noise. 0.5 random_state None **kwargs {} Returns: Type Description numpy.ndarray Noised image","title":"iso_noise()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop","text":"Keypoint center crop. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required crop_height int Crop height. required crop_width int Crop width. required h_start int Crop height start. required w_start int Crop width start. required rows int Image height. required cols int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) .","title":"keypoint_center_crop()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip","text":"Flip a keypoint either vertically, horizontally or both depending on the value of d . Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required d int Number of flip. Must be -1, 0 or 1: * 0 - vertical flip, * 1 - horizontal flip, * -1 - vertical and horizontal flip. required rows int Image height. required cols int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) . Exceptions: Type Description ValueError if value of d is not -1, 0 or 1.","title":"keypoint_flip()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip","text":"Flip a keypoint horizontally around the y-axis. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required rows int Image height. required cols int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) .","title":"keypoint_hflip()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop","text":"Keypoint random crop. Parameters: Name Type Description Default keypoint (tuple): A keypoint (x, y, angle, scale) . required crop_height int Crop height. required crop_width int Crop width. required h_start int Crop height start. required w_start int Crop width start. required rows int Image height. required cols int Image width. required Returns: Type Description A keypoint (x, y, angle, scale) .","title":"keypoint_random_crop()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90","text":"Rotates a keypoint by 90 degrees CCW (see np.rot90) Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required factor int Number of CCW rotations. Must be in range [0;3] See np.rot90. required rows int Image height. required cols int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) . Exceptions: Type Description ValueError if factor not in set {0, 1, 2, 3}","title":"keypoint_rot90()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate","text":"Rotate a keypoint by angle. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required angle float Rotation angle. required rows int Image height. required cols int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) .","title":"keypoint_rotate()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale","text":"Scales a keypoint by scale_x and scale_y. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required scale_x int Scale coefficient x-axis. required scale_y int Scale coefficient y-axis. required Returns: Type Description A keypoint (x, y, angle, scale) .","title":"keypoint_scale()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose","text":"Rotate a keypoint by angle. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required Returns: Type Description tuple A keypoint (x, y, angle, scale) .","title":"keypoint_transpose()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip","text":"Flip a keypoint vertically around the x-axis. Parameters: Name Type Description Default keypoint tuple A keypoint (x, y, angle, scale) . required rows int Image height. required cols( int Image width. required Returns: Type Description tuple A keypoint (x, y, angle, scale) .","title":"keypoint_vflip()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply","text":"Parameters: Name Type Description Default img numpy.ndarray Image. required multiplier numpy.ndarray Multiplier coefficient. required Returns: Type Description numpy.ndarray Image multiplied by multiplier coefficient.","title":"multiply()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion","text":"Barrel / pincushion distortion. Unconventional augment. Reference | https://stackoverflow.com/questions/6199636/formulas-for-barrel-pincushion-distortion | https://stackoverflow.com/questions/10364201/image-transformation-in-opencv | https://stackoverflow.com/questions/2477774/correcting-fisheye-distortion-programmatically | http://www.coldvision.io/2017/03/02/advanced-lane-finding-using-opencv/","title":"optical_distortion()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize","text":"Reduce the number of bits for each color channel. Parameters: Name Type Description Default img numpy.ndarray image to posterize. required bits int number of high bits. Must be in range [0, 8] required Returns: Type Description numpy.ndarray Image with reduced color channels.","title":"posterize()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_channel_dim","text":"Preserve dummy channel dim.","title":"preserve_channel_dim()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_shape","text":"Preserve shape of the image","title":"preserve_shape()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.py3round","text":"Unified rounding in all python versions.","title":"py3round()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize","text":"Invert all pixel values above a threshold. Parameters: Name Type Description Default img numpy.ndarray The image to solarize. required threshold int All pixels above this greyscale level are inverted. 128 Returns: Type Description numpy.ndarray Solarized image.","title":"solarize()"},{"location":"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image","text":"Swap tiles on image. Parameters: Name Type Description Default image np.ndarray Input image. required tiles np.ndarray array of tuples( current_left_up_corner_row, current_left_up_corner_col, old_left_up_corner_row, old_left_up_corner_col, height_tile, width_tile) required Returns: Type Description np.ndarray Output image.","title":"swap_tiles_on_image()"},{"location":"api_reference/augmentations/keypoints_utils/","text":"Helper functions for working with keypoints (augmentations.keypoints_utils) check_keypoint ( kp , rows , cols ) Check if keypoint coordinates are less than image shapes check_keypoints ( keypoints , rows , cols ) Check if keypoints boundaries are less than image shapes","title":"Helper functions for working with keypoints (augmentations.keypoints_utils)"},{"location":"api_reference/augmentations/keypoints_utils/#helper-functions-for-working-with-keypoints-augmentationskeypoints_utils","text":"","title":"Helper functions for working with keypoints (augmentations.keypoints_utils)"},{"location":"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils","text":"","title":"albumentations.augmentations.keypoints_utils"},{"location":"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoint","text":"Check if keypoint coordinates are less than image shapes","title":"check_keypoint()"},{"location":"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoints","text":"Check if keypoints boundaries are less than image shapes","title":"check_keypoints()"},{"location":"api_reference/augmentations/transforms/","text":"Transforms (augmentations.transforms) Blur Blur the input image using a random-sized kernel. Parameters: Name Type Description Default blur_limit int, [int, int] maximum kernel size for blurring the input image. Should be in range [3, inf). Default: (3, 7). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 CenterCrop Crop the central part of the input. Parameters: Name Type Description Default height int height of the crop. required width int width of the crop. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 Note It is recommended to use uint8 images as input. Otherwise the operation will require internal conversion float32 -> uint8 -> float32 that causes worse performance. ChannelDropout Randomly Drop Channels in the input Image. Parameters: Name Type Description Default channel_drop_range [int, int] range from which we choose the number of channels to drop. required fill_value int, float pixel value for the dropped channel. required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, uint16, unit32, float32 ChannelShuffle Randomly rearrange channels of the input RGB image. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 CLAHE Apply Contrast Limited Adaptive Histogram Equalization to the input image. Parameters: Name Type Description Default clip_limit float or [float, float] upper threshold value for contrast limiting. If clip_limit is a single float value, the range will be (1, clip_limit). Default: (1, 4). required tile_grid_size [int, int] size of grid for histogram equalization. Default: (8, 8). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8 CoarseDropout CoarseDropout of the rectangular regions in the image. Parameters: Name Type Description Default max_holes int Maximum number of regions to zero out. required max_height int Maximum height of the hole. required max_width int Maximum width of the hole. required min_holes int Minimum number of regions to zero out. If None , min_holes is be set to max_holes . Default: None . required min_height int Minimum height of the hole. Default: None. If None , min_height is set to max_height . Default: None . required min_width int Minimum width of the hole. If None , min_height is set to max_width . Default: None . required fill_value int, float, lisf of int, list of float value for dropped pixels. required Targets image Image-types uint8, float32 Reference: | https://arxiv.org/abs/1708.04552 | https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py | https://github.com/aleju/imgaug/blob/master/imgaug/augmenters/arithmetic.py Crop Crop region from image. Parameters: Name Type Description Default x_min int Minimum upper left x coordinate. required y_min int Minimum upper left y coordinate. required x_max int Maximum lower right x coordinate. required y_max int Maximum lower right y coordinate. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 CropNonEmptyMaskIfExists Crop area with mask if mask is non-empty, else make random crop. Parameters: Name Type Description Default height int vertical size of crop in pixels required width int horizontal size of crop in pixels required ignore_values list of int values to ignore in mask, 0 values are always ignored (e.g. if background value is 5 set ignore_values=[5] to ignore) required ignore_channels list of int channels to ignore in mask (e.g. if background is a first channel set ignore_channels=[0] to ignore) required p float probability of applying the transform. Default: 1.0. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 Cutout CoarseDropout of the square regions in the image. Parameters: Name Type Description Default num_holes int number of regions to zero out required max_h_size int maximum height of the hole required max_w_size int maximum width of the hole required fill_value int, float, lisf of int, list of float value for dropped pixels. required Targets image Image-types uint8, float32 Reference: | https://arxiv.org/abs/1708.04552 | https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py | https://github.com/aleju/imgaug/blob/master/imgaug/augmenters/arithmetic.py Downscale Decreases image quality by downscaling and upscaling back. Parameters: Name Type Description Default scale_min float lower bound on the image scale. Should be < 1. required scale_max float lower bound on the image scale. Should be . required interpolation cv2 interpolation method. cv2.INTER_NEAREST by default required Targets image Image-types uint8, float32 ElasticTransform Elastic deformation of images as described in [Simard2003]_ (with modifications). Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5 .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for Convolutional Neural Networks applied to Visual Document Analysis\", in Proc. of the International Conference on Document Analysis and Recognition, 2003. Parameters: Name Type Description Default alpha float required sigma float Gaussian filter parameter. required alpha_affine float The range will be (-alpha_affine, alpha_affine) required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required border_mode OpenCV flag flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 required value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. required approximate boolean Whether to smooth displacement map with fixed kernel size. Enabling this option gives ~2X speedup on large images. required Targets image, mask Image-types uint8, float32 Equalize Equalize the image histogram. Parameters: Name Type Description Default mode str {'cv', 'pil'}. Use OpenCV or Pillow equalization method. required by_channels bool If True, use equalization by channels separately, else convert image to YCbCr representation and use equalization by Y channel. required mask np.ndarray, callable If given, only the pixels selected by the mask are included in the analysis. Maybe 1 channel or 3 channel array or callable. Function signature must include image argument. required mask_params list of str Params for mask function. required Targets image Image-types uint8 FancyPCA Augment RGB image using FancyPCA from Krizhevsky's paper \"ImageNet Classification with Deep Convolutional Neural Networks\" Parameters: Name Type Description Default alpha float how much to perturb/scale the eigen vecs and vals. scale is samples from gaussian distribution (mu=0, sigma=alpha) required Targets image Image-types 3-channel uint8 images only Credit http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf https://deshanadesai.github.io/notes/Fancy-PCA-with-Scikit-Image https://pixelatedbrian.github.io/2018-04-29-fancy_pca/ __init__ ( self , alpha = 0.1 , always_apply = False , p = 0.5 ) special Flip Flip the input either horizontally, vertically or both horizontally and vertically. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 apply ( self , img , d = 0 , ** params ) Parameters: Name Type Description Default d int code that specifies how to flip the input. 0 for vertical flipping, 1 for horizontal flipping, -1 for both vertical and horizontal flipping (which is also could be seen as rotating the input by 180 degrees). 0 FromFloat Take an input array where all values should lie in the range [0, 1.0], multiply them by max_value and then cast the resulted value to a type specified by dtype . If max_value is None the transform will try to infer the maximum value for the data type from the dtype argument. This is the inverse transform for :class: ~albumentations.augmentations.transforms.ToFloat . Parameters: Name Type Description Default max_value float maximum possible input value. Default: None. required dtype string or numpy data type data type of the output. See the 'Data types' page from the NumPy docs _. Default: 'uint16'. required p float probability of applying the transform. Default: 1.0. required Targets image Image-types float32 .. _'Data types' page from the NumPy docs: https://docs.scipy.org/doc/numpy/user/basics.types.html GaussianBlur Blur the input image using using a Gaussian filter with a random kernel size. Parameters: Name Type Description Default blur_limit int maximum Gaussian kernel size for blurring the input image. Must be zero or odd and in range [3, inf). Default: (3, 7). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 GaussNoise Apply gaussian noise to the input image. Parameters: Name Type Description Default var_limit [float, float] or float variance range for noise. If var_limit is a single float, the range will be (0, var_limit). Default: (10.0, 50.0). required mean float mean of the noise. Default: 0 required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 GlassBlur Apply glass noise to the input image. Parameters: Name Type Description Default sigma float standard deviation for Gaussian kernel. required max_delta int max distance between pixels which are swapped. required iterations int number of repeats. Should be in range [1, inf). Default: (2). required mode str mode of computation: fast or exact. Default: \"fast\". required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 Reference: | https://arxiv.org/abs/1903.12261 | https://github.com/hendrycks/robustness/blob/master/ImageNet-C/create_c/make_imagenet_c.py GridDistortion Parameters: Name Type Description Default num_steps int count of grid cells on each side. required distort_limit float, [float, float] If distort_limit is a single float, the range will be (-distort_limit, distort_limit). Default: (-0.03, 0.03). required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required border_mode OpenCV flag flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 required value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. required Targets image, mask Image-types uint8, float32 GridDropout GridDropout, drops out rectangular regions of an image and the corresponding mask in a grid fashion. Parameters: Name Type Description Default ratio float the ratio of the mask holes to the unit_size (same for horizontal and vertical directions). Must be between 0 and 1. Default: 0.5. required unit_size_min int minimum size of the grid unit. Must be between 2 and the image shorter edge. If 'None', holes_number_x and holes_number_y are used to setup the grid. Default: None . required unit_size_max int maximum size of the grid unit. Must be between 2 and the image shorter edge. If 'None', holes_number_x and holes_number_y are used to setup the grid. Default: None . required holes_number_x int the number of grid units in x direction. Must be between 1 and image width//2. If 'None', grid unit width is set as image_width//10. Default: None . required holes_number_y int the number of grid units in y direction. Must be between 1 and image height//2. If None , grid unit height is set equal to the grid unit width or image height, whatever is smaller. required shift_x int offsets of the grid start in x direction from (0,0) coordinate. Clipped between 0 and grid unit_width - hole_width. Default: 0. required shift_y int offsets of the grid start in y direction from (0,0) coordinate. Clipped between 0 and grid unit height - hole_height. Default: 0. required random_offset boolean weather to offset the grid randomly between 0 and grid unit size - hole size If 'True', entered shift_x, shift_y are ignored and set randomly. Default: False . required fill_value int value for the dropped pixels. Default = 0 required mask_fill_value int value for the dropped pixels in mask. If None , tranformation is not applied to the mask. Default: None . required Targets image, mask Image-types uint8, float32 References https://arxiv.org/abs/2001.04086 HorizontalFlip Flip the input horizontally around the y-axis. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 HueSaturationValue Randomly change hue, saturation and value of the input image. Parameters: Name Type Description Default hue_shift_limit [int, int] or int range for changing hue. If hue_shift_limit is a single int, the range will be (-hue_shift_limit, hue_shift_limit). Default: (-20, 20). required sat_shift_limit [int, int] or int range for changing saturation. If sat_shift_limit is a single int, the range will be (-sat_shift_limit, sat_shift_limit). Default: (-30, 30). required val_shift_limit [int, int] or int range for changing value. If val_shift_limit is a single int, the range will be (-val_shift_limit, val_shift_limit). Default: (-20, 20). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 ImageCompression Decrease Jpeg, WebP compression of an image. Parameters: Name Type Description Default quality_lower float lower bound on the image quality. Should be in [0, 100] range for jpeg and [1, 100] for webp. required quality_upper float upper bound on the image quality. Should be in [0, 100] range for jpeg and [1, 100] for webp. required compression_type ImageCompressionType should be ImageCompressionType.JPEG or ImageCompressionType.WEBP. Default: ImageCompressionType.JPEG required Targets image Image-types uint8, float32 ImageCompressionType An enumeration. InvertImg Invert the input image by subtracting pixel values from 255. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8 ISONoise Apply camera sensor noise. Parameters: Name Type Description Default color_shift [float, float] variance range for color hue change. Measured as a fraction of 360 degree Hue angle in HLS colorspace. required intensity [float, float] Multiplicative factor that control strength of color and luminace noise. required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8 JpegCompression Decrease Jpeg compression of an image. Parameters: Name Type Description Default quality_lower float lower bound on the jpeg quality. Should be in [0, 100] range required quality_upper float upper bound on the jpeg quality. Should be in [0, 100] range required Targets image Image-types uint8, float32 Lambda A flexible transformation class for using user-defined transformation functions per targets. Function signature must include **kwargs to accept optinal arguments like interpolation method, image size, etc: Parameters: Name Type Description Default image callable Image transformation function. required mask callable Mask transformation function. required keypoint callable Keypoint transformation function. required bbox callable BBox transformation function. required always_apply bool Indicates whether this transformation should be always applied. required p float probability of applying the transform. Default: 1.0. required Targets image, mask, bboxes, keypoints Image-types Any LongestMaxSize Rescale an image so that maximum side is equal to max_size, keeping the aspect ratio of the initial image. Parameters: Name Type Description Default max_size int maximum size of the image after the transformation. required interpolation OpenCV flag interpolation method. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 MaskDropout Image & mask augmentation that zero out mask and image regions corresponding to randomly chosen object instance from mask. Mask must be single-channel image, zero values treated as background. Image can be any number of channels. Inspired by https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/114254 __init__ ( self , max_objects = 1 , image_fill_value = 0 , mask_fill_value = 0 , always_apply = False , p = 0.5 ) special Parameters: Name Type Description Default max_objects Maximum number of labels that can be zeroed out. Can be tuple, in this case it's [min, max] 1 image_fill_value Fill value to use when filling image. Can be 'inpaint' to apply inpaining (works only for 3-chahnel images) 0 mask_fill_value Fill value to use when filling mask. 0 Targets image, mask Image-types uint8, float32 MedianBlur Blur the input image using using a median filter with a random aperture linear size. Parameters: Name Type Description Default blur_limit int maximum aperture linear size for blurring the input image. Must be odd and in range [3, inf). Default: (3, 7). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 MotionBlur Apply motion blur to the input image using a random-sized kernel. Parameters: Name Type Description Default blur_limit int maximum kernel size for blurring the input image. Should be in range [3, inf). Default: (3, 7). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 MultiplicativeNoise Multiply image to random number or array of numbers. Parameters: Name Type Description Default multiplier float or tuple of floats If single float image will be multiplied to this number. If tuple of float multiplier will be in range [multiplier[0], multiplier[1]) . Default: (0.9, 1.1). required per_channel bool If False , same values for all channels will be used. If True use sample values for each channels. Default False. required elementwise bool If False multiply multiply all pixels in an image with a random value sampled once. If True Multiply image pixels with values that are pixelwise randomly sampled. Defaule: False. required Targets image Image-types Any Normalize Divide pixel values by 255 = 2**8 - 1, subtract mean per channel and divide by std per channel. Parameters: Name Type Description Default mean float, list of float mean values required std (float, list of float std values required max_pixel_value float maximum possible pixel value required Targets image Image-types uint8, float32 OpticalDistortion Parameters: Name Type Description Default distort_limit float, [float, float] If distort_limit is a single float, the range will be (-distort_limit, distort_limit). Default: (-0.05, 0.05). required shift_limit float, [float, float] If shift_limit is a single float, the range will be (-shift_limit, shift_limit). Default: (-0.05, 0.05). required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required border_mode OpenCV flag flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 required value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. required Targets image, mask Image-types uint8, float32 PadIfNeeded Pad side of the image / max if side is less than desired number. Parameters: Name Type Description Default min_height int minimal result image height. required min_width int minimal result image width. required border_mode OpenCV flag OpenCV border mode. required value int, float, list of int, lisft of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of int, lisft of float padding value for mask if border_mode is cv2.BORDER_CONSTANT. required p float probability of applying the transform. Default: 1.0. required Targets image, mask, bbox, keypoints Image-types uint8, float32 Posterize Reduce the number of bits for each color channel. Parameters: Name Type Description Default num_bits [int, int] or int, or list of ints [r, g, b], or list of ints [[r1, r1], [g1, g2], [b1, b2]] number of high bits. If num_bits is a single value, the range will be [num_bits, num_bits]. Must be in range [0, 8]. Default: 4. required p float probability of applying the transform. Default: 0.5. required Targets: image Image-types uint8 RandomBrightness Randomly change brightness of the input image. Parameters: Name Type Description Default limit [float, float] or float factor range for changing brightness. If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 RandomBrightnessContrast Randomly change brightness and contrast of the input image. Parameters: Name Type Description Default brightness_limit [float, float] or float factor range for changing brightness. If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2). required contrast_limit [float, float] or float factor range for changing contrast. If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2). required brightness_by_max Boolean If True adjust contrast by image dtype maximum, else adjust contrast by image mean. required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 RandomContrast Randomly change contrast of the input image. Parameters: Name Type Description Default limit [float, float] or float factor range for changing contrast. If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 RandomCrop Crop a random part of the input. Parameters: Name Type Description Default height int height of the crop. required width int width of the crop. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 RandomCropNearBBox Crop bbox from image with random shift by x,y coordinates Parameters: Name Type Description Default max_part_shift float float value in (0.0, 1.0) range. Default 0.3 required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 RandomFog Simulates fog for the image From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default fog_coef_lower float lower limit for fog intensity coefficient. Should be in [0, 1] range. required fog_coef_upper float upper limit for fog intensity coefficient. Should be in [0, 1] range. required alpha_coef float transparency of the fog circles. Should be in [0, 1] range. required Targets image Image-types uint8, float32 RandomGamma Parameters: Name Type Description Default gamma_limit float or [float, float] If gamma_limit is a single float value, the range will be (-gamma_limit, gamma_limit). Default: (80, 120). required eps Deprecated. required Targets image Image-types uint8, float32 RandomGridShuffle Random shuffle grid's cells on image. Parameters: Name Type Description Default grid [int, int] size of grid for splitting image. required Targets image, mask Image-types uint8, float32 RandomRain Adds rain effects. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default slant_lower should be in range [-20, 20]. required slant_upper should be in range [-20, 20]. required drop_length should be in range [0, 100]. required drop_width should be in range [1, 5]. required drop_color list of (r, g, b rain lines color. required blur_value int rainy view are blurry required brightness_coefficient float rainy days are usually shady. Should be in range [0, 1]. required rain_type One of [None, \"drizzle\", \"heavy\", \"torrestial\"] required Targets image Image-types uint8, float32 RandomResizedCrop Torchvision's variant of crop a random part of the input and rescale it to some size. Parameters: Name Type Description Default height int height after crop and resize. required width int width after crop and resize. required scale [float, float] range of size of the origin size cropped required ratio [float, float] range of aspect ratio of the origin aspect ratio cropped required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 RandomRotate90 Randomly rotate the input by 90 degrees zero or more times. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 apply ( self , img , factor = 0 , ** params ) Parameters: Name Type Description Default factor int number of times the input will be rotated by 90 degrees. 0 RandomScale Randomly resize the input. Output image size is different from the input image size. Parameters: Name Type Description Default scale_limit [float, float] or float scaling factor range. If scale_limit is a single float value, the range will be (1 - scale_limit, 1 + scale_limit). Default: (0.9, 1.1). required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 RandomShadow Simulates shadows for the image From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default shadow_roi float, float, float, float region of the image where shadows will appear (x_min, y_min, x_max, y_max). All values should be in range [0, 1]. required num_shadows_lower int Lower limit for the possible number of shadows. Should be in range [0, num_shadows_upper ]. required num_shadows_upper int Lower limit for the possible number of shadows. Should be in range [ num_shadows_lower , inf]. required shadow_dimension int number of edges in the shadow polygons required Targets image Image-types uint8, float32 RandomSizedBBoxSafeCrop Crop a random part of the input and rescale it to some size without loss of bboxes. Parameters: Name Type Description Default height int height after crop and resize. required width int width after crop and resize. required erosion_rate float erosion rate applied on input image height before crop. required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes Image-types uint8, float32 RandomSizedCrop Crop a random part of the input and rescale it to some size. Parameters: Name Type Description Default min_max_height [int, int] crop size limits. required height int height after crop and resize. required width int width after crop and resize. required w2h_ratio float aspect ratio of crop. required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 RandomSnow Bleach out some pixel values simulating snow. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default snow_point_lower float lower_bond of the amount of snow. Should be in [0, 1] range required snow_point_upper float upper_bond of the amount of snow. Should be in [0, 1] range required brightness_coeff float larger number will lead to a more snow on the image. Should be >= 0 required Targets image Image-types uint8, float32 RandomSunFlare Simulates Sun Flare for the image From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default flare_roi float, float, float, float region of the image where flare will appear (x_min, y_min, x_max, y_max). All values should be in range [0, 1]. required angle_lower float should be in range [0, angle_upper ]. required angle_upper float should be in range [ angle_lower , 1]. required num_flare_circles_lower int lower limit for the number of flare circles. Should be in range [0, num_flare_circles_upper ]. required num_flare_circles_upper int upper limit for the number of flare circles. Should be in range [ num_flare_circles_lower , inf]. required src_radius int required src_color int, int, int color of the flare required Targets image Image-types uint8, float32 Resize Resize the input to the given height and width. Parameters: Name Type Description Default height int desired height of the output. required width int desired width of the output. required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 RGBShift Randomly shift values for each channel of the input RGB image. Parameters: Name Type Description Default r_shift_limit [int, int] or int range for changing values for the red channel. If r_shift_limit is a single int, the range will be (-r_shift_limit, r_shift_limit). Default: (-20, 20). required g_shift_limit [int, int] or int range for changing values for the green channel. If g_shift_limit is a single int, the range will be (-g_shift_limit, g_shift_limit). Default: (-20, 20). required b_shift_limit [int, int] or int range for changing values for the blue channel. If b_shift_limit is a single int, the range will be (-b_shift_limit, b_shift_limit). Default: (-20, 20). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 Rotate Rotate the input by an angle selected randomly from the uniform distribution. Parameters: Name Type Description Default limit [int, int] or int range from which a random angle is picked. If limit is a single int an angle is picked from (-limit, limit). Default: (-90, 90) required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required border_mode OpenCV flag flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 required value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. required p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 ShiftScaleRotate Randomly apply affine transforms: translate, scale and rotate the input. Parameters: Name Type Description Default shift_limit [float, float] or float shift factor range for both height and width. If shift_limit is a single float value, the range will be (-shift_limit, shift_limit). Absolute values for lower and upper bounds should lie in range [0, 1]. Default: (-0.0625, 0.0625). required scale_limit [float, float] or float scaling factor range. If scale_limit is a single float value, the range will be (-scale_limit, scale_limit). Default: (-0.1, 0.1). required rotate_limit [int, int] or int rotation range. If rotate_limit is a single int value, the range will be (-rotate_limit, rotate_limit). Default: (-45, 45). required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required border_mode OpenCV flag flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 required value int, float, list of int, list of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of int, list of float padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. required p float probability of applying the transform. Default: 0.5. required Targets image, mask, keypoints Image-types uint8, float32 SmallestMaxSize Rescale an image so that minimum side is equal to max_size, keeping the aspect ratio of the initial image. Parameters: Name Type Description Default max_size int maximum size of smallest side of the image after the transformation. required interpolation OpenCV flag interpolation method. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 Solarize Invert all pixel values above a threshold. Parameters: Name Type Description Default threshold [int, int] or int, or [float, float] or float range for solarizing threshold. required If threshold is a single value, the range will be [threshold, threshold]. Default 128. required p float probability of applying the transform. Default: 0.5. required Targets image Image-types any ToFloat Divide pixel values by max_value to get a float32 output array where all values lie in the range [0, 1.0]. If max_value is None the transform will try to infer the maximum value by inspecting the data type of the input image. See Also: :class: ~albumentations.augmentations.transforms.FromFloat Parameters: Name Type Description Default max_value float maximum possible input value. Default: None. required p float probability of applying the transform. Default: 1.0. required Targets image Image-types any type ToGray Convert the input RGB image to grayscale. If the mean pixel value for the resulting image is greater than 127, invert the resulting grayscale image. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 ToSepia Applies sepia filter to the input RGB image Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 Transpose Transpose the input by swapping rows and columns. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 VerticalFlip Flip the input vertically around the x-axis. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"Transforms (augmentations.transforms)"},{"location":"api_reference/augmentations/transforms/#transforms-augmentationstransforms","text":"","title":"Transforms (augmentations.transforms)"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms","text":"","title":"albumentations.augmentations.transforms"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur","text":"Blur the input image using a random-sized kernel. Parameters: Name Type Description Default blur_limit int, [int, int] maximum kernel size for blurring the input image. Should be in range [3, inf). Default: (3, 7). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"Blur"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop","text":"Crop the central part of the input. Parameters: Name Type Description Default height int height of the crop. required width int width of the crop. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32 Note It is recommended to use uint8 images as input. Otherwise the operation will require internal conversion float32 -> uint8 -> float32 that causes worse performance.","title":"CenterCrop"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout","text":"Randomly Drop Channels in the input Image. Parameters: Name Type Description Default channel_drop_range [int, int] range from which we choose the number of channels to drop. required fill_value int, float pixel value for the dropped channel. required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, uint16, unit32, float32","title":"ChannelDropout"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle","text":"Randomly rearrange channels of the input RGB image. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"ChannelShuffle"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE","text":"Apply Contrast Limited Adaptive Histogram Equalization to the input image. Parameters: Name Type Description Default clip_limit float or [float, float] upper threshold value for contrast limiting. If clip_limit is a single float value, the range will be (1, clip_limit). Default: (1, 4). required tile_grid_size [int, int] size of grid for histogram equalization. Default: (8, 8). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8","title":"CLAHE"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout","text":"CoarseDropout of the rectangular regions in the image. Parameters: Name Type Description Default max_holes int Maximum number of regions to zero out. required max_height int Maximum height of the hole. required max_width int Maximum width of the hole. required min_holes int Minimum number of regions to zero out. If None , min_holes is be set to max_holes . Default: None . required min_height int Minimum height of the hole. Default: None. If None , min_height is set to max_height . Default: None . required min_width int Minimum width of the hole. If None , min_height is set to max_width . Default: None . required fill_value int, float, lisf of int, list of float value for dropped pixels. required Targets image Image-types uint8, float32 Reference: | https://arxiv.org/abs/1708.04552 | https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py | https://github.com/aleju/imgaug/blob/master/imgaug/augmenters/arithmetic.py","title":"CoarseDropout"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop","text":"Crop region from image. Parameters: Name Type Description Default x_min int Minimum upper left x coordinate. required y_min int Minimum upper left y coordinate. required x_max int Maximum lower right x coordinate. required y_max int Maximum lower right y coordinate. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"Crop"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists","text":"Crop area with mask if mask is non-empty, else make random crop. Parameters: Name Type Description Default height int vertical size of crop in pixels required width int horizontal size of crop in pixels required ignore_values list of int values to ignore in mask, 0 values are always ignored (e.g. if background value is 5 set ignore_values=[5] to ignore) required ignore_channels list of int channels to ignore in mask (e.g. if background is a first channel set ignore_channels=[0] to ignore) required p float probability of applying the transform. Default: 1.0. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"CropNonEmptyMaskIfExists"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout","text":"CoarseDropout of the square regions in the image. Parameters: Name Type Description Default num_holes int number of regions to zero out required max_h_size int maximum height of the hole required max_w_size int maximum width of the hole required fill_value int, float, lisf of int, list of float value for dropped pixels. required Targets image Image-types uint8, float32 Reference: | https://arxiv.org/abs/1708.04552 | https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py | https://github.com/aleju/imgaug/blob/master/imgaug/augmenters/arithmetic.py","title":"Cutout"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale","text":"Decreases image quality by downscaling and upscaling back. Parameters: Name Type Description Default scale_min float lower bound on the image scale. Should be < 1. required scale_max float lower bound on the image scale. Should be . required interpolation cv2 interpolation method. cv2.INTER_NEAREST by default required Targets image Image-types uint8, float32","title":"Downscale"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform","text":"Elastic deformation of images as described in [Simard2003]_ (with modifications). Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5 .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for Convolutional Neural Networks applied to Visual Document Analysis\", in Proc. of the International Conference on Document Analysis and Recognition, 2003. Parameters: Name Type Description Default alpha float required sigma float Gaussian filter parameter. required alpha_affine float The range will be (-alpha_affine, alpha_affine) required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required border_mode OpenCV flag flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 required value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. required approximate boolean Whether to smooth displacement map with fixed kernel size. Enabling this option gives ~2X speedup on large images. required Targets image, mask Image-types uint8, float32","title":"ElasticTransform"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize","text":"Equalize the image histogram. Parameters: Name Type Description Default mode str {'cv', 'pil'}. Use OpenCV or Pillow equalization method. required by_channels bool If True, use equalization by channels separately, else convert image to YCbCr representation and use equalization by Y channel. required mask np.ndarray, callable If given, only the pixels selected by the mask are included in the analysis. Maybe 1 channel or 3 channel array or callable. Function signature must include image argument. required mask_params list of str Params for mask function. required Targets image Image-types uint8","title":"Equalize"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA","text":"Augment RGB image using FancyPCA from Krizhevsky's paper \"ImageNet Classification with Deep Convolutional Neural Networks\" Parameters: Name Type Description Default alpha float how much to perturb/scale the eigen vecs and vals. scale is samples from gaussian distribution (mu=0, sigma=alpha) required Targets image Image-types 3-channel uint8 images only Credit http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf https://deshanadesai.github.io/notes/Fancy-PCA-with-Scikit-Image https://pixelatedbrian.github.io/2018-04-29-fancy_pca/","title":"FancyPCA"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA.__init__","text":"","title":"__init__()"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip","text":"Flip the input either horizontally, vertically or both horizontally and vertically. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"Flip"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply","text":"Parameters: Name Type Description Default d int code that specifies how to flip the input. 0 for vertical flipping, 1 for horizontal flipping, -1 for both vertical and horizontal flipping (which is also could be seen as rotating the input by 180 degrees). 0","title":"apply()"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat","text":"Take an input array where all values should lie in the range [0, 1.0], multiply them by max_value and then cast the resulted value to a type specified by dtype . If max_value is None the transform will try to infer the maximum value for the data type from the dtype argument. This is the inverse transform for :class: ~albumentations.augmentations.transforms.ToFloat . Parameters: Name Type Description Default max_value float maximum possible input value. Default: None. required dtype string or numpy data type data type of the output. See the 'Data types' page from the NumPy docs _. Default: 'uint16'. required p float probability of applying the transform. Default: 1.0. required Targets image Image-types float32 .. _'Data types' page from the NumPy docs: https://docs.scipy.org/doc/numpy/user/basics.types.html","title":"FromFloat"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur","text":"Blur the input image using using a Gaussian filter with a random kernel size. Parameters: Name Type Description Default blur_limit int maximum Gaussian kernel size for blurring the input image. Must be zero or odd and in range [3, inf). Default: (3, 7). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"GaussianBlur"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise","text":"Apply gaussian noise to the input image. Parameters: Name Type Description Default var_limit [float, float] or float variance range for noise. If var_limit is a single float, the range will be (0, var_limit). Default: (10.0, 50.0). required mean float mean of the noise. Default: 0 required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"GaussNoise"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur","text":"Apply glass noise to the input image. Parameters: Name Type Description Default sigma float standard deviation for Gaussian kernel. required max_delta int max distance between pixels which are swapped. required iterations int number of repeats. Should be in range [1, inf). Default: (2). required mode str mode of computation: fast or exact. Default: \"fast\". required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32 Reference: | https://arxiv.org/abs/1903.12261 | https://github.com/hendrycks/robustness/blob/master/ImageNet-C/create_c/make_imagenet_c.py","title":"GlassBlur"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion","text":"Parameters: Name Type Description Default num_steps int count of grid cells on each side. required distort_limit float, [float, float] If distort_limit is a single float, the range will be (-distort_limit, distort_limit). Default: (-0.03, 0.03). required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required border_mode OpenCV flag flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 required value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. required Targets image, mask Image-types uint8, float32","title":"GridDistortion"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout","text":"GridDropout, drops out rectangular regions of an image and the corresponding mask in a grid fashion. Parameters: Name Type Description Default ratio float the ratio of the mask holes to the unit_size (same for horizontal and vertical directions). Must be between 0 and 1. Default: 0.5. required unit_size_min int minimum size of the grid unit. Must be between 2 and the image shorter edge. If 'None', holes_number_x and holes_number_y are used to setup the grid. Default: None . required unit_size_max int maximum size of the grid unit. Must be between 2 and the image shorter edge. If 'None', holes_number_x and holes_number_y are used to setup the grid. Default: None . required holes_number_x int the number of grid units in x direction. Must be between 1 and image width//2. If 'None', grid unit width is set as image_width//10. Default: None . required holes_number_y int the number of grid units in y direction. Must be between 1 and image height//2. If None , grid unit height is set equal to the grid unit width or image height, whatever is smaller. required shift_x int offsets of the grid start in x direction from (0,0) coordinate. Clipped between 0 and grid unit_width - hole_width. Default: 0. required shift_y int offsets of the grid start in y direction from (0,0) coordinate. Clipped between 0 and grid unit height - hole_height. Default: 0. required random_offset boolean weather to offset the grid randomly between 0 and grid unit size - hole size If 'True', entered shift_x, shift_y are ignored and set randomly. Default: False . required fill_value int value for the dropped pixels. Default = 0 required mask_fill_value int value for the dropped pixels in mask. If None , tranformation is not applied to the mask. Default: None . required Targets image, mask Image-types uint8, float32 References https://arxiv.org/abs/2001.04086","title":"GridDropout"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip","text":"Flip the input horizontally around the y-axis. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"HorizontalFlip"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue","text":"Randomly change hue, saturation and value of the input image. Parameters: Name Type Description Default hue_shift_limit [int, int] or int range for changing hue. If hue_shift_limit is a single int, the range will be (-hue_shift_limit, hue_shift_limit). Default: (-20, 20). required sat_shift_limit [int, int] or int range for changing saturation. If sat_shift_limit is a single int, the range will be (-sat_shift_limit, sat_shift_limit). Default: (-30, 30). required val_shift_limit [int, int] or int range for changing value. If val_shift_limit is a single int, the range will be (-val_shift_limit, val_shift_limit). Default: (-20, 20). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"HueSaturationValue"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression","text":"Decrease Jpeg, WebP compression of an image. Parameters: Name Type Description Default quality_lower float lower bound on the image quality. Should be in [0, 100] range for jpeg and [1, 100] for webp. required quality_upper float upper bound on the image quality. Should be in [0, 100] range for jpeg and [1, 100] for webp. required compression_type ImageCompressionType should be ImageCompressionType.JPEG or ImageCompressionType.WEBP. Default: ImageCompressionType.JPEG required Targets image Image-types uint8, float32","title":"ImageCompression"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression.ImageCompressionType","text":"An enumeration.","title":"ImageCompressionType"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg","text":"Invert the input image by subtracting pixel values from 255. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8","title":"InvertImg"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise","text":"Apply camera sensor noise. Parameters: Name Type Description Default color_shift [float, float] variance range for color hue change. Measured as a fraction of 360 degree Hue angle in HLS colorspace. required intensity [float, float] Multiplicative factor that control strength of color and luminace noise. required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8","title":"ISONoise"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression","text":"Decrease Jpeg compression of an image. Parameters: Name Type Description Default quality_lower float lower bound on the jpeg quality. Should be in [0, 100] range required quality_upper float upper bound on the jpeg quality. Should be in [0, 100] range required Targets image Image-types uint8, float32","title":"JpegCompression"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda","text":"A flexible transformation class for using user-defined transformation functions per targets. Function signature must include **kwargs to accept optinal arguments like interpolation method, image size, etc: Parameters: Name Type Description Default image callable Image transformation function. required mask callable Mask transformation function. required keypoint callable Keypoint transformation function. required bbox callable BBox transformation function. required always_apply bool Indicates whether this transformation should be always applied. required p float probability of applying the transform. Default: 1.0. required Targets image, mask, bboxes, keypoints Image-types Any","title":"Lambda"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize","text":"Rescale an image so that maximum side is equal to max_size, keeping the aspect ratio of the initial image. Parameters: Name Type Description Default max_size int maximum size of the image after the transformation. required interpolation OpenCV flag interpolation method. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"LongestMaxSize"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout","text":"Image & mask augmentation that zero out mask and image regions corresponding to randomly chosen object instance from mask. Mask must be single-channel image, zero values treated as background. Image can be any number of channels. Inspired by https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/114254","title":"MaskDropout"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__","text":"Parameters: Name Type Description Default max_objects Maximum number of labels that can be zeroed out. Can be tuple, in this case it's [min, max] 1 image_fill_value Fill value to use when filling image. Can be 'inpaint' to apply inpaining (works only for 3-chahnel images) 0 mask_fill_value Fill value to use when filling mask. 0 Targets image, mask Image-types uint8, float32","title":"__init__()"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur","text":"Blur the input image using using a median filter with a random aperture linear size. Parameters: Name Type Description Default blur_limit int maximum aperture linear size for blurring the input image. Must be odd and in range [3, inf). Default: (3, 7). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"MedianBlur"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur","text":"Apply motion blur to the input image using a random-sized kernel. Parameters: Name Type Description Default blur_limit int maximum kernel size for blurring the input image. Should be in range [3, inf). Default: (3, 7). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"MotionBlur"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise","text":"Multiply image to random number or array of numbers. Parameters: Name Type Description Default multiplier float or tuple of floats If single float image will be multiplied to this number. If tuple of float multiplier will be in range [multiplier[0], multiplier[1]) . Default: (0.9, 1.1). required per_channel bool If False , same values for all channels will be used. If True use sample values for each channels. Default False. required elementwise bool If False multiply multiply all pixels in an image with a random value sampled once. If True Multiply image pixels with values that are pixelwise randomly sampled. Defaule: False. required Targets image Image-types Any","title":"MultiplicativeNoise"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize","text":"Divide pixel values by 255 = 2**8 - 1, subtract mean per channel and divide by std per channel. Parameters: Name Type Description Default mean float, list of float mean values required std (float, list of float std values required max_pixel_value float maximum possible pixel value required Targets image Image-types uint8, float32","title":"Normalize"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion","text":"Parameters: Name Type Description Default distort_limit float, [float, float] If distort_limit is a single float, the range will be (-distort_limit, distort_limit). Default: (-0.05, 0.05). required shift_limit float, [float, float] If shift_limit is a single float, the range will be (-shift_limit, shift_limit). Default: (-0.05, 0.05). required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required border_mode OpenCV flag flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 required value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. required Targets image, mask Image-types uint8, float32","title":"OpticalDistortion"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded","text":"Pad side of the image / max if side is less than desired number. Parameters: Name Type Description Default min_height int minimal result image height. required min_width int minimal result image width. required border_mode OpenCV flag OpenCV border mode. required value int, float, list of int, lisft of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of int, lisft of float padding value for mask if border_mode is cv2.BORDER_CONSTANT. required p float probability of applying the transform. Default: 1.0. required Targets image, mask, bbox, keypoints Image-types uint8, float32","title":"PadIfNeeded"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize","text":"Reduce the number of bits for each color channel. Parameters: Name Type Description Default num_bits [int, int] or int, or list of ints [r, g, b], or list of ints [[r1, r1], [g1, g2], [b1, b2]] number of high bits. If num_bits is a single value, the range will be [num_bits, num_bits]. Must be in range [0, 8]. Default: 4. required p float probability of applying the transform. Default: 0.5. required Targets: image Image-types uint8","title":"Posterize"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness","text":"Randomly change brightness of the input image. Parameters: Name Type Description Default limit [float, float] or float factor range for changing brightness. If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"RandomBrightness"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast","text":"Randomly change brightness and contrast of the input image. Parameters: Name Type Description Default brightness_limit [float, float] or float factor range for changing brightness. If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2). required contrast_limit [float, float] or float factor range for changing contrast. If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2). required brightness_by_max Boolean If True adjust contrast by image dtype maximum, else adjust contrast by image mean. required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"RandomBrightnessContrast"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast","text":"Randomly change contrast of the input image. Parameters: Name Type Description Default limit [float, float] or float factor range for changing contrast. If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"RandomContrast"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop","text":"Crop a random part of the input. Parameters: Name Type Description Default height int height of the crop. required width int width of the crop. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"RandomCrop"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox","text":"Crop bbox from image with random shift by x,y coordinates Parameters: Name Type Description Default max_part_shift float float value in (0.0, 1.0) range. Default 0.3 required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"RandomCropNearBBox"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog","text":"Simulates fog for the image From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default fog_coef_lower float lower limit for fog intensity coefficient. Should be in [0, 1] range. required fog_coef_upper float upper limit for fog intensity coefficient. Should be in [0, 1] range. required alpha_coef float transparency of the fog circles. Should be in [0, 1] range. required Targets image Image-types uint8, float32","title":"RandomFog"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma","text":"Parameters: Name Type Description Default gamma_limit float or [float, float] If gamma_limit is a single float value, the range will be (-gamma_limit, gamma_limit). Default: (80, 120). required eps Deprecated. required Targets image Image-types uint8, float32","title":"RandomGamma"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle","text":"Random shuffle grid's cells on image. Parameters: Name Type Description Default grid [int, int] size of grid for splitting image. required Targets image, mask Image-types uint8, float32","title":"RandomGridShuffle"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain","text":"Adds rain effects. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default slant_lower should be in range [-20, 20]. required slant_upper should be in range [-20, 20]. required drop_length should be in range [0, 100]. required drop_width should be in range [1, 5]. required drop_color list of (r, g, b rain lines color. required blur_value int rainy view are blurry required brightness_coefficient float rainy days are usually shady. Should be in range [0, 1]. required rain_type One of [None, \"drizzle\", \"heavy\", \"torrestial\"] required Targets image Image-types uint8, float32","title":"RandomRain"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop","text":"Torchvision's variant of crop a random part of the input and rescale it to some size. Parameters: Name Type Description Default height int height after crop and resize. required width int width after crop and resize. required scale [float, float] range of size of the origin size cropped required ratio [float, float] range of aspect ratio of the origin aspect ratio cropped required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"RandomResizedCrop"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90","text":"Randomly rotate the input by 90 degrees zero or more times. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"RandomRotate90"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply","text":"Parameters: Name Type Description Default factor int number of times the input will be rotated by 90 degrees. 0","title":"apply()"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale","text":"Randomly resize the input. Output image size is different from the input image size. Parameters: Name Type Description Default scale_limit [float, float] or float scaling factor range. If scale_limit is a single float value, the range will be (1 - scale_limit, 1 + scale_limit). Default: (0.9, 1.1). required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"RandomScale"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow","text":"Simulates shadows for the image From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default shadow_roi float, float, float, float region of the image where shadows will appear (x_min, y_min, x_max, y_max). All values should be in range [0, 1]. required num_shadows_lower int Lower limit for the possible number of shadows. Should be in range [0, num_shadows_upper ]. required num_shadows_upper int Lower limit for the possible number of shadows. Should be in range [ num_shadows_lower , inf]. required shadow_dimension int number of edges in the shadow polygons required Targets image Image-types uint8, float32","title":"RandomShadow"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop","text":"Crop a random part of the input and rescale it to some size without loss of bboxes. Parameters: Name Type Description Default height int height after crop and resize. required width int width after crop and resize. required erosion_rate float erosion rate applied on input image height before crop. required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes Image-types uint8, float32","title":"RandomSizedBBoxSafeCrop"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop","text":"Crop a random part of the input and rescale it to some size. Parameters: Name Type Description Default min_max_height [int, int] crop size limits. required height int height after crop and resize. required width int width after crop and resize. required w2h_ratio float aspect ratio of crop. required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"RandomSizedCrop"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow","text":"Bleach out some pixel values simulating snow. From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default snow_point_lower float lower_bond of the amount of snow. Should be in [0, 1] range required snow_point_upper float upper_bond of the amount of snow. Should be in [0, 1] range required brightness_coeff float larger number will lead to a more snow on the image. Should be >= 0 required Targets image Image-types uint8, float32","title":"RandomSnow"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare","text":"Simulates Sun Flare for the image From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library Parameters: Name Type Description Default flare_roi float, float, float, float region of the image where flare will appear (x_min, y_min, x_max, y_max). All values should be in range [0, 1]. required angle_lower float should be in range [0, angle_upper ]. required angle_upper float should be in range [ angle_lower , 1]. required num_flare_circles_lower int lower limit for the number of flare circles. Should be in range [0, num_flare_circles_upper ]. required num_flare_circles_upper int upper limit for the number of flare circles. Should be in range [ num_flare_circles_lower , inf]. required src_radius int required src_color int, int, int color of the flare required Targets image Image-types uint8, float32","title":"RandomSunFlare"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize","text":"Resize the input to the given height and width. Parameters: Name Type Description Default height int desired height of the output. required width int desired width of the output. required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"Resize"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift","text":"Randomly shift values for each channel of the input RGB image. Parameters: Name Type Description Default r_shift_limit [int, int] or int range for changing values for the red channel. If r_shift_limit is a single int, the range will be (-r_shift_limit, r_shift_limit). Default: (-20, 20). required g_shift_limit [int, int] or int range for changing values for the green channel. If g_shift_limit is a single int, the range will be (-g_shift_limit, g_shift_limit). Default: (-20, 20). required b_shift_limit [int, int] or int range for changing values for the blue channel. If b_shift_limit is a single int, the range will be (-b_shift_limit, b_shift_limit). Default: (-20, 20). required p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"RGBShift"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate","text":"Rotate the input by an angle selected randomly from the uniform distribution. Parameters: Name Type Description Default limit [int, int] or int range from which a random angle is picked. If limit is a single int an angle is picked from (-limit, limit). Default: (-90, 90) required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required border_mode OpenCV flag flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 required value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of ints, list of float padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. required p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"Rotate"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate","text":"Randomly apply affine transforms: translate, scale and rotate the input. Parameters: Name Type Description Default shift_limit [float, float] or float shift factor range for both height and width. If shift_limit is a single float value, the range will be (-shift_limit, shift_limit). Absolute values for lower and upper bounds should lie in range [0, 1]. Default: (-0.0625, 0.0625). required scale_limit [float, float] or float scaling factor range. If scale_limit is a single float value, the range will be (-scale_limit, scale_limit). Default: (-0.1, 0.1). required rotate_limit [int, int] or int rotation range. If rotate_limit is a single int value, the range will be (-rotate_limit, rotate_limit). Default: (-45, 45). required interpolation OpenCV flag flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR. required border_mode OpenCV flag flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101 required value int, float, list of int, list of float padding value if border_mode is cv2.BORDER_CONSTANT. required mask_value int, float, list of int, list of float padding value if border_mode is cv2.BORDER_CONSTANT applied for masks. required p float probability of applying the transform. Default: 0.5. required Targets image, mask, keypoints Image-types uint8, float32","title":"ShiftScaleRotate"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize","text":"Rescale an image so that minimum side is equal to max_size, keeping the aspect ratio of the initial image. Parameters: Name Type Description Default max_size int maximum size of smallest side of the image after the transformation. required interpolation OpenCV flag interpolation method. Default: cv2.INTER_LINEAR. required p float probability of applying the transform. Default: 1. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"SmallestMaxSize"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize","text":"Invert all pixel values above a threshold. Parameters: Name Type Description Default threshold [int, int] or int, or [float, float] or float range for solarizing threshold. required If threshold is a single value, the range will be [threshold, threshold]. Default 128. required p float probability of applying the transform. Default: 0.5. required Targets image Image-types any","title":"Solarize"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat","text":"Divide pixel values by max_value to get a float32 output array where all values lie in the range [0, 1.0]. If max_value is None the transform will try to infer the maximum value by inspecting the data type of the input image. See Also: :class: ~albumentations.augmentations.transforms.FromFloat Parameters: Name Type Description Default max_value float maximum possible input value. Default: None. required p float probability of applying the transform. Default: 1.0. required Targets image Image-types any type","title":"ToFloat"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray","text":"Convert the input RGB image to grayscale. If the mean pixel value for the resulting image is greater than 127, invert the resulting grayscale image. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"ToGray"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia","text":"Applies sepia filter to the input RGB image Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image Image-types uint8, float32","title":"ToSepia"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose","text":"Transpose the input by swapping rows and columns. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"Transpose"},{"location":"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip","text":"Flip the input vertically around the x-axis. Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask, bboxes, keypoints Image-types uint8, float32","title":"VerticalFlip"},{"location":"api_reference/core/","text":"Composition API (albumentations.core.composition) Serialization API (albumentations.core.serialization) Transforms Interface (albumentations.core.transforms_interface)","title":"Index"},{"location":"api_reference/core/composition/","text":"Composition API (core.composition) BboxParams Parameters of bounding boxes Parameters: Name Type Description Default format str format of bounding boxes. Should be 'coco', 'pascal_voc', 'albumentations' or 'yolo'. The coco format [x_min, y_min, width, height] , e.g. [97, 12, 150, 200]. The pascal_voc format [x_min, y_min, x_max, y_max] , e.g. [97, 12, 247, 212]. The albumentations format is like pascal_voc , but normalized, in other words: [x_min, y_min, x_max, y_max] , e.g. [0.2, 0.3, 0.4, 0.5]. The yolo format [x, y, width, height] , e.g. [0.1, 0.2, 0.3, 0.4]; x , y - normalized bbox center; width , height` - normalized bbox width and height. required label_fields list list of fields that are joined with boxes, e.g labels. Should be same type as boxes. required min_area float minimum area of a bounding box. All bounding boxes whose visible area in pixels is less than this value will be removed. Default: 0.0. required min_visibility float minimum fraction of area for a bounding box to remain this box in list. Default: 0.0. required Compose Compose transforms and handle all transformations regrading bounding boxes Parameters: Name Type Description Default transforms list list of transformations to compose. required bbox_params BboxParams Parameters for bounding boxes transforms required keypoint_params KeypointParams Parameters for keypoints transforms required additional_targets dict Dict with keys - new target name, values - old target name. ex: {'image2': 'image'} required p float probability of applying all list of transforms. Default: 1.0. required KeypointParams Parameters of keypoints Parameters: Name Type Description Default format str format of keypoints. Should be 'xy', 'yx', 'xya', 'xys', 'xyas', 'xysa'. x - X coordinate, y - Y coordinate s - Keypoint scale a - Keypoint orientation in radians or degrees (depending on KeypointParams.angle_in_degrees) required label_fields list list of fields that are joined with keypoints, e.g labels. Should be same type as keypoints. required remove_invisible bool to remove invisible points after transform or not required angle_in_degrees bool angle in degrees or radians in 'xya', 'xyas', 'xysa' keypoints required OneOf Select one of transforms to apply Parameters: Name Type Description Default transforms list list of transformations to compose. required p float probability of applying selected transform. Default: 0.5. required PerChannel Apply transformations per-channel Parameters: Name Type Description Default transforms list list of transformations to compose. required channels list channels to apply the transform to. Pass None to apply to all. Default: None (apply to all) required p float probability of applying the transform. Default: 0.5. required","title":"Composition API (core.composition)"},{"location":"api_reference/core/composition/#composition-api-corecomposition","text":"","title":"Composition API (core.composition)"},{"location":"api_reference/core/composition/#albumentations.core.composition","text":"","title":"albumentations.core.composition"},{"location":"api_reference/core/composition/#albumentations.core.composition.BboxParams","text":"Parameters of bounding boxes Parameters: Name Type Description Default format str format of bounding boxes. Should be 'coco', 'pascal_voc', 'albumentations' or 'yolo'. The coco format [x_min, y_min, width, height] , e.g. [97, 12, 150, 200]. The pascal_voc format [x_min, y_min, x_max, y_max] , e.g. [97, 12, 247, 212]. The albumentations format is like pascal_voc , but normalized, in other words: [x_min, y_min, x_max, y_max] , e.g. [0.2, 0.3, 0.4, 0.5]. The yolo format [x, y, width, height] , e.g. [0.1, 0.2, 0.3, 0.4]; x , y - normalized bbox center; width , height` - normalized bbox width and height. required label_fields list list of fields that are joined with boxes, e.g labels. Should be same type as boxes. required min_area float minimum area of a bounding box. All bounding boxes whose visible area in pixels is less than this value will be removed. Default: 0.0. required min_visibility float minimum fraction of area for a bounding box to remain this box in list. Default: 0.0. required","title":"BboxParams"},{"location":"api_reference/core/composition/#albumentations.core.composition.Compose","text":"Compose transforms and handle all transformations regrading bounding boxes Parameters: Name Type Description Default transforms list list of transformations to compose. required bbox_params BboxParams Parameters for bounding boxes transforms required keypoint_params KeypointParams Parameters for keypoints transforms required additional_targets dict Dict with keys - new target name, values - old target name. ex: {'image2': 'image'} required p float probability of applying all list of transforms. Default: 1.0. required","title":"Compose"},{"location":"api_reference/core/composition/#albumentations.core.composition.KeypointParams","text":"Parameters of keypoints Parameters: Name Type Description Default format str format of keypoints. Should be 'xy', 'yx', 'xya', 'xys', 'xyas', 'xysa'. x - X coordinate, y - Y coordinate s - Keypoint scale a - Keypoint orientation in radians or degrees (depending on KeypointParams.angle_in_degrees) required label_fields list list of fields that are joined with keypoints, e.g labels. Should be same type as keypoints. required remove_invisible bool to remove invisible points after transform or not required angle_in_degrees bool angle in degrees or radians in 'xya', 'xyas', 'xysa' keypoints required","title":"KeypointParams"},{"location":"api_reference/core/composition/#albumentations.core.composition.OneOf","text":"Select one of transforms to apply Parameters: Name Type Description Default transforms list list of transformations to compose. required p float probability of applying selected transform. Default: 0.5. required","title":"OneOf"},{"location":"api_reference/core/composition/#albumentations.core.composition.PerChannel","text":"Apply transformations per-channel Parameters: Name Type Description Default transforms list list of transformations to compose. required channels list channels to apply the transform to. Pass None to apply to all. Default: None (apply to all) required p float probability of applying the transform. Default: 0.5. required","title":"PerChannel"},{"location":"api_reference/core/serialization/","text":"Serialization API (core.serialization) SerializableMeta A metaclass that is used to register classes in SERIALIZABLE_REGISTRY so they can be found later while deserializing transformation pipeline using classes full names. __new__ ( cls , name , bases , class_dict ) special staticmethod Create and return a new object. See help(type) for accurate signature. from_dict ( transform_dict , lambda_transforms = None ) Parameters: Name Type Description Default transform dict A dictionary with serialized transform pipeline. required lambda_transforms dict A dictionary that contains lambda transforms, that is instances of the Lambda class. This dictionary is required when you are restoring a pipeline that contains lambda transforms. Keys in that dictionary should be named same as name arguments in respective lambda transforms from a serialized pipeline. None load ( filepath , data_format = 'json' , lambda_transforms = None ) Load a serialized pipeline from a json or yaml file and construct a transform pipeline. Parameters: Name Type Description Default transform obj Transform to serialize. required filepath str Filepath to read from. required data_format str Serialization format. Should be either json or 'yaml'. 'json' lambda_transforms dict A dictionary that contains lambda transforms, that is instances of the Lambda class. This dictionary is required when you are restoring a pipeline that contains lambda transforms. Keys in that dictionary should be named same as name arguments in respective lambda transforms from a serialized pipeline. None save ( transform , filepath , data_format = 'json' , on_not_implemented_error = 'raise' ) Take a transform pipeline, serialize it and save a serialized version to a file using either json or yaml format. Parameters: Name Type Description Default transform obj Transform to serialize. required filepath str Filepath to write to. required data_format str Serialization format. Should be either json or 'yaml'. 'json' on_not_implemented_error str Parameter that describes what to do if a transform doesn't implement the to_dict method. If 'raise' then NotImplementedError is raised, if warn then the exception will be ignored and no transform arguments will be saved. 'raise' to_dict ( transform , on_not_implemented_error = 'raise' ) Take a transform pipeline and convert it to a serializable representation that uses only standard python data types: dictionaries, lists, strings, integers, and floats. Parameters: Name Type Description Default transform object A transform that should be serialized. If the transform doesn't implement the to_dict method and on_not_implemented_error equals to 'raise' then NotImplementedError is raised. If on_not_implemented_error equals to 'warn' then NotImplementedError will be ignored but no transform parameters will be serialized. required","title":"Serialization API (core.serialization)"},{"location":"api_reference/core/serialization/#serialization-api-coreserialization","text":"","title":"Serialization API (core.serialization)"},{"location":"api_reference/core/serialization/#albumentations.core.serialization","text":"","title":"albumentations.core.serialization"},{"location":"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta","text":"A metaclass that is used to register classes in SERIALIZABLE_REGISTRY so they can be found later while deserializing transformation pipeline using classes full names.","title":"SerializableMeta"},{"location":"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__","text":"Create and return a new object. See help(type) for accurate signature.","title":"__new__()"},{"location":"api_reference/core/serialization/#albumentations.core.serialization.from_dict","text":"Parameters: Name Type Description Default transform dict A dictionary with serialized transform pipeline. required lambda_transforms dict A dictionary that contains lambda transforms, that is instances of the Lambda class. This dictionary is required when you are restoring a pipeline that contains lambda transforms. Keys in that dictionary should be named same as name arguments in respective lambda transforms from a serialized pipeline. None","title":"from_dict()"},{"location":"api_reference/core/serialization/#albumentations.core.serialization.load","text":"Load a serialized pipeline from a json or yaml file and construct a transform pipeline. Parameters: Name Type Description Default transform obj Transform to serialize. required filepath str Filepath to read from. required data_format str Serialization format. Should be either json or 'yaml'. 'json' lambda_transforms dict A dictionary that contains lambda transforms, that is instances of the Lambda class. This dictionary is required when you are restoring a pipeline that contains lambda transforms. Keys in that dictionary should be named same as name arguments in respective lambda transforms from a serialized pipeline. None","title":"load()"},{"location":"api_reference/core/serialization/#albumentations.core.serialization.save","text":"Take a transform pipeline, serialize it and save a serialized version to a file using either json or yaml format. Parameters: Name Type Description Default transform obj Transform to serialize. required filepath str Filepath to write to. required data_format str Serialization format. Should be either json or 'yaml'. 'json' on_not_implemented_error str Parameter that describes what to do if a transform doesn't implement the to_dict method. If 'raise' then NotImplementedError is raised, if warn then the exception will be ignored and no transform arguments will be saved. 'raise'","title":"save()"},{"location":"api_reference/core/serialization/#albumentations.core.serialization.to_dict","text":"Take a transform pipeline and convert it to a serializable representation that uses only standard python data types: dictionaries, lists, strings, integers, and floats. Parameters: Name Type Description Default transform object A transform that should be serialized. If the transform doesn't implement the to_dict method and on_not_implemented_error equals to 'raise' then NotImplementedError is raised. If on_not_implemented_error equals to 'warn' then NotImplementedError will be ignored but no transform parameters will be serialized. required","title":"to_dict()"},{"location":"api_reference/core/transforms_interface/","text":"Transforms Interface (core.transforms_interface) BasicTransform add_targets ( self , additional_targets ) Add targets to transform them the same way as one of existing targets ex: {'target_image': 'image'} ex: {'obj1_mask': 'mask', 'obj2_mask': 'mask'} by the way you must have at least one object with key 'image' !!! args additional_targets (dict): keys - new target name, values - old target name. ex: {'image2': 'image'} DualTransform Transform for segmentation task. ImageOnlyTransform Transform applied to image only. NoOp Does nothing to_tuple ( param , low = None , bias = None ) Convert input argument to min-max tuple Parameters: Name Type Description Default param scalar, tuple or list of 2+ elements Input value. If value is scalar, return value would be (offset - value, offset + value). If value is tuple, return value would be value + offset (broadcasted). required low Second element of tuple can be passed as optional argument None bias An offset factor added to each element None","title":"Transforms Interface (core.transforms_interface)"},{"location":"api_reference/core/transforms_interface/#transforms-interface-coretransforms_interface","text":"","title":"Transforms Interface (core.transforms_interface)"},{"location":"api_reference/core/transforms_interface/#albumentations.core.transforms_interface","text":"","title":"albumentations.core.transforms_interface"},{"location":"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform","text":"","title":"BasicTransform"},{"location":"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets","text":"Add targets to transform them the same way as one of existing targets ex: {'target_image': 'image'} ex: {'obj1_mask': 'mask', 'obj2_mask': 'mask'} by the way you must have at least one object with key 'image' !!! args additional_targets (dict): keys - new target name, values - old target name. ex: {'image2': 'image'}","title":"add_targets()"},{"location":"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.DualTransform","text":"Transform for segmentation task.","title":"DualTransform"},{"location":"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.ImageOnlyTransform","text":"Transform applied to image only.","title":"ImageOnlyTransform"},{"location":"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.NoOp","text":"Does nothing","title":"NoOp"},{"location":"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple","text":"Convert input argument to min-max tuple Parameters: Name Type Description Default param scalar, tuple or list of 2+ elements Input value. If value is scalar, return value would be (offset - value, offset + value). If value is tuple, return value would be value + offset (broadcasted). required low Second element of tuple can be passed as optional argument None bias An offset factor added to each element None","title":"to_tuple()"},{"location":"api_reference/imgaug/","text":"Transforms (albumentations.imgaug.transforms)","title":"Index"},{"location":"api_reference/imgaug/transforms/","text":"Transforms (imgaug.transforms) IAAAdditiveGaussianNoise Add gaussian noise to the input image. Parameters: Name Type Description Default loc int mean of the normal distribution that generates the noise. Default: 0. required scale [float, float] standard deviation of the normal distribution that generates the noise. Default: (0.01 * 255, 0.05 * 255). required p float probability of applying the transform. Default: 0.5. required Targets image IAAAffine Place a regular grid of points on the input and randomly move the neighbourhood of these point around via affine transformations. Note: This class introduce interpolation artifacts to mask if it has values other than {0;1} Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask IAAEmboss Emboss the input image and overlays the result with the original image. Parameters: Name Type Description Default alpha [float, float] range to choose the visibility of the embossed image. At 0, only the original image is visible,at 1.0 only its embossed version is visible. Default: (0.2, 0.5). required strength [float, float] strength range of the embossing. Default: (0.2, 0.7). required p float probability of applying the transform. Default: 0.5. required Targets image IAAPerspective Perform a random four point perspective transform of the input. Note: This class introduce interpolation artifacts to mask if it has values other than {0;1} Parameters: Name Type Description Default scale [float, float] standard deviation of the normal distributions. These are used to sample the random distances of the subimage's corners from the full image's corners. Default: (0.05, 0.1). required p float probability of applying the transform. Default: 0.5. required Targets image, mask IAAPiecewiseAffine Place a regular grid of points on the input and randomly move the neighbourhood of these point around via affine transformations. Note: This class introduce interpolation artifacts to mask if it has values other than {0;1} Parameters: Name Type Description Default scale [float, float] factor range that determines how far each point is moved. Default: (0.03, 0.05). required nb_rows int number of rows of points that the regular grid should have. Default: 4. required nb_cols int number of columns of points that the regular grid should have. Default: 4. required p float probability of applying the transform. Default: 0.5. required Targets image, mask IAASharpen Sharpen the input image and overlays the result with the original image. Parameters: Name Type Description Default alpha [float, float] range to choose the visibility of the sharpened image. At 0, only the original image is visible, at 1.0 only its sharpened version is visible. Default: (0.2, 0.5). required lightness [float, float] range to choose the lightness of the sharpened image. Default: (0.5, 1.0). required p float probability of applying the transform. Default: 0.5. required Targets image IAASuperpixels Completely or partially transform the input image to its superpixel representation. Uses skimage's version of the SLIC algorithm. May be slow. Parameters: Name Type Description Default p_replace float defines the probability of any superpixel area being replaced by the superpixel, i.e. by the average pixel color within its area. Default: 0.1. required n_segments int target number of superpixels to generate. Default: 100. required p float probability of applying the transform. Default: 0.5. required Targets image","title":"Transforms (imgaug.transforms)"},{"location":"api_reference/imgaug/transforms/#transforms-imgaugtransforms","text":"","title":"Transforms (imgaug.transforms)"},{"location":"api_reference/imgaug/transforms/#albumentations.imgaug.transforms","text":"","title":"albumentations.imgaug.transforms"},{"location":"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise","text":"Add gaussian noise to the input image. Parameters: Name Type Description Default loc int mean of the normal distribution that generates the noise. Default: 0. required scale [float, float] standard deviation of the normal distribution that generates the noise. Default: (0.01 * 255, 0.05 * 255). required p float probability of applying the transform. Default: 0.5. required Targets image","title":"IAAAdditiveGaussianNoise"},{"location":"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine","text":"Place a regular grid of points on the input and randomly move the neighbourhood of these point around via affine transformations. Note: This class introduce interpolation artifacts to mask if it has values other than {0;1} Parameters: Name Type Description Default p float probability of applying the transform. Default: 0.5. required Targets image, mask","title":"IAAAffine"},{"location":"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss","text":"Emboss the input image and overlays the result with the original image. Parameters: Name Type Description Default alpha [float, float] range to choose the visibility of the embossed image. At 0, only the original image is visible,at 1.0 only its embossed version is visible. Default: (0.2, 0.5). required strength [float, float] strength range of the embossing. Default: (0.2, 0.7). required p float probability of applying the transform. Default: 0.5. required Targets image","title":"IAAEmboss"},{"location":"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective","text":"Perform a random four point perspective transform of the input. Note: This class introduce interpolation artifacts to mask if it has values other than {0;1} Parameters: Name Type Description Default scale [float, float] standard deviation of the normal distributions. These are used to sample the random distances of the subimage's corners from the full image's corners. Default: (0.05, 0.1). required p float probability of applying the transform. Default: 0.5. required Targets image, mask","title":"IAAPerspective"},{"location":"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine","text":"Place a regular grid of points on the input and randomly move the neighbourhood of these point around via affine transformations. Note: This class introduce interpolation artifacts to mask if it has values other than {0;1} Parameters: Name Type Description Default scale [float, float] factor range that determines how far each point is moved. Default: (0.03, 0.05). required nb_rows int number of rows of points that the regular grid should have. Default: 4. required nb_cols int number of columns of points that the regular grid should have. Default: 4. required p float probability of applying the transform. Default: 0.5. required Targets image, mask","title":"IAAPiecewiseAffine"},{"location":"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen","text":"Sharpen the input image and overlays the result with the original image. Parameters: Name Type Description Default alpha [float, float] range to choose the visibility of the sharpened image. At 0, only the original image is visible, at 1.0 only its sharpened version is visible. Default: (0.2, 0.5). required lightness [float, float] range to choose the lightness of the sharpened image. Default: (0.5, 1.0). required p float probability of applying the transform. Default: 0.5. required Targets image","title":"IAASharpen"},{"location":"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels","text":"Completely or partially transform the input image to its superpixel representation. Uses skimage's version of the SLIC algorithm. May be slow. Parameters: Name Type Description Default p_replace float defines the probability of any superpixel area being replaced by the superpixel, i.e. by the average pixel color within its area. Default: 0.1. required n_segments int target number of superpixels to generate. Default: 100. required p float probability of applying the transform. Default: 0.5. required Targets image","title":"IAASuperpixels"},{"location":"api_reference/pytorch/","text":"Transforms (albumentations.pytorch.transforms)","title":"Index"},{"location":"api_reference/pytorch/transforms/","text":"Transforms (pytorch.transforms) ToTensor Convert image and mask to torch.Tensor and divide by 255 if image or mask are uint8 type. WARNING! Please use this with care and look into sources before usage. Parameters: Name Type Description Default num_classes int only for segmentation required sigmoid bool only for segmentation, transform mask to LongTensor or not. required normalize dict dict with keys [mean, std] to pass it into torchvision.normalize required ToTensorV2 Convert image and mask to torch.Tensor .","title":"Transforms (pytorch.transforms)"},{"location":"api_reference/pytorch/transforms/#transforms-pytorchtransforms","text":"","title":"Transforms (pytorch.transforms)"},{"location":"api_reference/pytorch/transforms/#albumentations.pytorch.transforms","text":"","title":"albumentations.pytorch.transforms"},{"location":"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor","text":"Convert image and mask to torch.Tensor and divide by 255 if image or mask are uint8 type. WARNING! Please use this with care and look into sources before usage. Parameters: Name Type Description Default num_classes int only for segmentation required sigmoid bool only for segmentation, transform mask to LongTensor or not. required normalize dict dict with keys [mean, std] to pass it into torchvision.normalize required","title":"ToTensor"},{"location":"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensorV2","text":"Convert image and mask to torch.Tensor .","title":"ToTensorV2"},{"location":"getting_started/bounding_boxes_augmentation/","text":"Bounding boxes augmentation for object detection Different annotations formats Bounding boxes are rectangles that mark objects on an image. There are multiple formats of bounding boxes annotations. Each format uses its specific representation of bouning boxes coordinates. Albumentations supports four formats: pascal_voc , albumentations , coco , and yolo . Let's take a look at each of those formats and how they represent coordinates of bounding boxes. As an example, we will use an image from the dataset named Common Objects in Context . It contains one bounding box that marks a cat. The image width is 640 pixels, and its height is 480 pixels. The width of the bounding box is 322 pixels, and its height is 117 pixels. The bounding box has the following (x, y) coordinates of its corners: top-left is (x_min, y_min) or (98px, 345px) , top-right is (x_max, y_min) or (420px, 345px) , bottom-left is (x_min, y_max) or (98px, 462px) , bottom-right is (x_max, y_max) or (420px, 462px) . As you see, coordinates of the bounding box's corners are calculated with respect to the top-left corner of the image which has (x, y) coordinates (0, 0) . An example image with a bounding box from the COCO dataset pascal_voc pascal_voc is a format used by the Pascal VOC dataset . Coordinates of a bounding box are encoded with four values in pixels: [x_min, x_max, y_min, y_max] . x_min and x_max are coordinates of the beginning and end of the bounding box on the x-axis. y_min and y_max are coordinates of the beginning and end of the bounding box on the y-axis. Coordinates of the example bounding box in this format are [98, 420, 345, 462] . albumentations albumentations is similar to pascal_voc , because it also uses four values [x_min, x_max, y_min, y_max] to represent a bounding box. But unlike pascal_voc , albumentations uses normalized values. To normalize values, we divide coordinates in pixels for the x- and y-axis by the width and the height of the image. Coordinates of the example bounding box in this format are [98 / 640, 420 / 640, 345 / 480, 462 / 480] which are [0.153125, 0.65625, 0.71875, 0.9625] . Albumentations uses this format internally to work with bounding boxes and augment them. A popular dataset Open Images also uses this format to represent coordinates of bounding boxes. coco coco is a format used by the Common Objects in Context (COCO) dataset. In coco , a bounding box is defined by four values in pixels [x_min, y_min, width, height] . They are coordinates of the top-left corner along with the width and height of the bounding box. Coordinates of the example bounding box in this format are [98, 345, 322, 117] . yolo In yolo , a bounding box is represented by four values [x_center, y_center, width, height] . x_center and y_center are the normalized coordinates of the center of the bounding box. To make coordinates normalized, we take pixel values of x and y, which marks the center of the bounding box on the x- and y-axis. Then we divide the value of x by the width of the image and value of y by the height of the image. width and height represent the width and the height of the bounding box. They are normalized as well. Coordinates of the example bounding box in this format are [((420 + 98) / 2) / 640, ((462 + 365) / 2) / 640, 322 / 640, 117 / 480] which are [0.4046875, 0.64609375, 0.503125, 0.24375] . How different formats represent coordinates of a bounding box Bounding boxes augmentation Just like with images and masks augmentation, the process of augmenting bounding boxes consists of 4 steps. You import the required libraries. You define an augmentation pipeline. You read images and bounding boxes from the disk. You pass an image and bounding boxes to the augmentation pipeline and receive augmented images and boxes. Step 1. Import the required libraries. import albumentations as A import cv2 Step 2. Define an augmentation pipeline. Here an example of a minimal declaration of an augmentation pipeline that works with bounding boxes. transform = A . Compose ([ A . RandomCrop ( width = 450 , height = 450 ), A . HorizontalFlip ( p = 0.5 ), A . RandomBrightnessContrast ( p = 0.2 ), ], bbox_params = A . BboxParams ( format = 'coco' )) Note that unlike image and masks augmentation, Compose now has an additional parameter bbox_params . You need to pass an instance of A.BboxParams to that argument. A.BboxParams specifies settings for working with bounding boxes. format sets the format for bounding boxes coordinates. It can either be pascal_voc , albumentations , coco or yolo . This value is required because Albumentation needs to know the coordinates' source format for bounding boxes to apply augmentations correctly. Besides format , A.BboxParams supports a few more settings. Here is an example of Compose that shows all available settings with A.BboxParams : transform = A . Compose ([ A . RandomCrop ( width = 450 , height = 450 ), A . HorizontalFlip ( p = 0.5 ), A . RandomBrightnessContrast ( p = 0.2 ), ], bbox_params = A . BboxParams ( format = 'coco' , min_area = 1024 , min_visibility = 0.1 , label_fields = [ 'class_labels' ])) min_area and min_visibility min_area and min_visibility parameters control what Albumentations should do to the augmented bounding boxes if their size has changed after augmentation. The size of bounding boxes could change if you apply spatial augmentations, for example, when you crop a part of an image or when you resize an image. min_area is a value in pixels. If the area of a bounding box after augmentation becomes smaller than min_area , Albumentations will drop that box. So the returned list of augmented bounding boxes won't contain that bounding box. min_visibility is a value between 0 and 1. If the ratio of the bounding box area after augmentation to the area of the bounding box before augmentation becomes smaller than min_visibility , Albumentations will drop that box. So if the augmentation process cuts the most of the bounding box, that box won't be present in the returned list of the augmented bounding boxes. Here is an example image that contains two bounding boxes. Bounding boxes coordinates are declared using the coco format. An example image with two bounding boxes First, we apply the CenterCrop augmentation without declaring parameters min_area and min_visiiblity . The augmented image contains two bounding boxes. An example image with two bounding boxes after applying augmentation Next, we apply the same CenterCrop augmentation, but now we also use the min_area parameter. Now, the augmented image contains only one bounding box, because the other bounding box's area after augmentation became smaller than min_area , so Albumentations dropped that bounding box. An example image with one bounding box after applying augmentation with 'min_area' Finally, we apply the CenterCrop augmentation with the min_visibility . After that augmentation, the resulting image doesn't contain any bounding box, because visibility of all bounding boxes after augmentation are below threshold set by min_visibility . An example image with zero bounding boxes after applying augmentation with 'min_visibility' Class labels for bounding boxes Besides coordinates, each bounding box should have an associated class label that tells which object lies inside the bounding box. There are two ways to pass a label for a bounding box. Let's say you have an example image with three objects: dog , cat , and sports ball . Bounding boxes coordinates in the coco format for those objects are [23, 74, 295, 388] , [377, 294, 252, 161] , and [333, 421, 49, 49] . An example image with 3 bounding boxes from the COCO dataset 1. You can pass labels along with bounding boxes coordinates by adding them as additional values to the list of coordinates. For the image above, bounding boxes with class labels will become [23, 74, 295, 388, 'dog'] , [377, 294, 252, 161, 'cat'] , and [333, 421, 49, 49, 'sports ball'] . Class labels could be of any type: integer, string, or any other Python data type. For example, integer values as class labels will look the following: [23, 74, 295, 388, 18] , [377, 294, 252, 161, 17] , and [333, 421, 49, 49, 37]. Also, you can use multiple class values for each bounding box, for example [23, 74, 295, 388, 'dog', 'animal'] , [377, 294, 252, 161, 'cat', 'animal'] , and [333, 421, 49, 49, 'sports ball', 'item'] . 2.You can pass labels for bounding boxes as a separate list. For example, if you have three bounding boxes like [23, 74, 295, 388] , [377, 294, 252, 161] , and [333, 421, 49, 49] you can create a separate list with values like ['cat', 'dog', 'sports ball'] , or [18, 17, 37] that contains class labels for those bounding boxes. Next, you pass that list with class labels as a separate argument to the transform function. Albumentations needs to know the names of all those lists with class labels to join them with augmented bounding boxes correctly. Then, if a bounding box is dropped after augmentation because it is no longer visible, Albumentations will drop the class label for that box as well. Use label_fields parameter to set names for all arguments in transform that will contain label descriptions for bounding boxes (more on that in Step 4). Step 3. Read images and bounding boxes from the disk. Read an image from the disk. image = cv2 . imread ( \"/path/to/image.jpg\" ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) Bounding boxes can be stored on the disk in different serialization formats: JSON, XML, YAML, CSV, etc. So the code to read bounding boxes depends on the actual format of data on the disk. After you read the data from the disk, you need to prepare bounding boxes for Albumentations. Albumentations expects that bounding boxes will be represented as a list of lists. Each list contains information about a single bounding box. A bounding box definition should have at list four elements that represent the coordinates of that bounding box. The actual meaning of those four values depends on the format of bounding boxes (either pascal_voc , albumentations , coco , or yolo ). Besides four coordinates, each definition of a bounding box may contain one or more extra values. You can use those extra values to store additional information about the bounding box, such as a class label of the object inside the box. During augmentation, Albumentations will not process those extra values. The library will return them as is along with the updated coordinates of the augmented bounding box. Step 4. Pass an image and bounding boxes to the augmentation pipeline and receive augmented images and boxes. As discussed in Step 2, there are two ways of passing class labels along with bounding boxes coordinates: 1. Pass class labels along with coordinates. So, if you have coordinates of three bounding boxes that look like this: bboxes = [ [ 23 , 74 , 295 , 388 ], [ 377 , 294 , 252 , 161 ], [ 333 , 421 , 49 , 49 ], ] you can add a class label for each bounding box as an additional element of the list along with four coordinates. So now a list with bounding boxes and their coordinates will look the following: bboxes = [ [ 23 , 74 , 295 , 388 , 'dog' ], [ 377 , 294 , 252 , 161 , 'cat' ], [ 333 , 421 , 49 , 49 , 'sports ball' ], ] or with multiple labels per each bounding box: bboxes = [ [ 23 , 74 , 295 , 388 , 'dog' , 'animal' ], [ 377 , 294 , 252 , 161 , 'cat' , 'animal' ], [ 333 , 421 , 49 , 49 , 'sports ball' , 'item' ], ] You can use any data type for declaring class labels. It can be string, integer, or any other Python data type. Next, you pass an image and bounding boxes for it to the transform function and receive the augmented image and bounding boxes. transformed = transform ( image = image , bboxes = bboxes ) transformed_image = transformed [ 'image' ] transformed_bboxes = transformed [ 'bboxes' ] Example input and output data for bounding boxes augmentation 2. Pass class labels in a separate argument to transform . Let's say you have coordinates of three bounding boxes bboxes = [ [ 23 , 74 , 295 , 388 ], [ 377 , 294 , 252 , 161 ], [ 333 , 421 , 49 , 49 ], ] You can create a separate list that contains class labels for those bounding boxes: class_labels = [ 'cat' , 'dog' , 'parrot' ] Then you pass both bounding boxes and class labels to transform . Note that to pass class labels, you need to use the name of the argument that you declared in label_fields when creating an instance of Compose in step 2. In our cse, we set the name of the argument to class_labels . transformed = transform ( image = image , bboxes = bboxes , class_labels = class_labels ) transformed_image = transformed [ 'image' ] transformed_bboxes = transformed [ 'bboxes' ] transformed_class_labels = transformed [ 'class_labels' ] Example input and output data for bounding boxes augmentation with a separate argument for class labels Note that label_fields expects a list, so you can set multiple fields that contain labels for your bounding boxes. So if you declare Compose like transform = A . Compose ([ A . RandomCrop ( width = 450 , height = 450 ), A . HorizontalFlip ( p = 0.5 ), A . RandomBrightnessContrast ( p = 0.2 ), ], bbox_params = A . BboxParams ( format = 'coco' , label_fields = [ 'class_labels' , 'class_category' ]))) you can use those multiple arguments to pass info about class labels, like class_labels = [ 'cat' , 'dog' , 'parrot' ] class_category = [ 'animal' , 'animal' , 'item' ] transformed = transform ( image = image , bboxes = bboxes , class_labels = class_labels , class_category = class_category ) transformed_image = transformed [ 'image' ] transformed_bboxes = transformed [ 'bboxes' ] transformed_class_labels = transformed [ 'class_labels' ] transformed_class_category = transformed [ 'class_category' ]","title":"Bounding boxes augmentation for object detection"},{"location":"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation-for-object-detection","text":"","title":"Bounding boxes augmentation for object detection"},{"location":"getting_started/bounding_boxes_augmentation/#different-annotations-formats","text":"Bounding boxes are rectangles that mark objects on an image. There are multiple formats of bounding boxes annotations. Each format uses its specific representation of bouning boxes coordinates. Albumentations supports four formats: pascal_voc , albumentations , coco , and yolo . Let's take a look at each of those formats and how they represent coordinates of bounding boxes. As an example, we will use an image from the dataset named Common Objects in Context . It contains one bounding box that marks a cat. The image width is 640 pixels, and its height is 480 pixels. The width of the bounding box is 322 pixels, and its height is 117 pixels. The bounding box has the following (x, y) coordinates of its corners: top-left is (x_min, y_min) or (98px, 345px) , top-right is (x_max, y_min) or (420px, 345px) , bottom-left is (x_min, y_max) or (98px, 462px) , bottom-right is (x_max, y_max) or (420px, 462px) . As you see, coordinates of the bounding box's corners are calculated with respect to the top-left corner of the image which has (x, y) coordinates (0, 0) . An example image with a bounding box from the COCO dataset","title":"Different annotations formats"},{"location":"getting_started/bounding_boxes_augmentation/#pascal_voc","text":"pascal_voc is a format used by the Pascal VOC dataset . Coordinates of a bounding box are encoded with four values in pixels: [x_min, x_max, y_min, y_max] . x_min and x_max are coordinates of the beginning and end of the bounding box on the x-axis. y_min and y_max are coordinates of the beginning and end of the bounding box on the y-axis. Coordinates of the example bounding box in this format are [98, 420, 345, 462] .","title":"pascal_voc"},{"location":"getting_started/bounding_boxes_augmentation/#albumentations","text":"albumentations is similar to pascal_voc , because it also uses four values [x_min, x_max, y_min, y_max] to represent a bounding box. But unlike pascal_voc , albumentations uses normalized values. To normalize values, we divide coordinates in pixels for the x- and y-axis by the width and the height of the image. Coordinates of the example bounding box in this format are [98 / 640, 420 / 640, 345 / 480, 462 / 480] which are [0.153125, 0.65625, 0.71875, 0.9625] . Albumentations uses this format internally to work with bounding boxes and augment them. A popular dataset Open Images also uses this format to represent coordinates of bounding boxes.","title":"albumentations"},{"location":"getting_started/bounding_boxes_augmentation/#coco","text":"coco is a format used by the Common Objects in Context (COCO) dataset. In coco , a bounding box is defined by four values in pixels [x_min, y_min, width, height] . They are coordinates of the top-left corner along with the width and height of the bounding box. Coordinates of the example bounding box in this format are [98, 345, 322, 117] .","title":"coco"},{"location":"getting_started/bounding_boxes_augmentation/#yolo","text":"In yolo , a bounding box is represented by four values [x_center, y_center, width, height] . x_center and y_center are the normalized coordinates of the center of the bounding box. To make coordinates normalized, we take pixel values of x and y, which marks the center of the bounding box on the x- and y-axis. Then we divide the value of x by the width of the image and value of y by the height of the image. width and height represent the width and the height of the bounding box. They are normalized as well. Coordinates of the example bounding box in this format are [((420 + 98) / 2) / 640, ((462 + 365) / 2) / 640, 322 / 640, 117 / 480] which are [0.4046875, 0.64609375, 0.503125, 0.24375] . How different formats represent coordinates of a bounding box","title":"yolo"},{"location":"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation","text":"Just like with images and masks augmentation, the process of augmenting bounding boxes consists of 4 steps. You import the required libraries. You define an augmentation pipeline. You read images and bounding boxes from the disk. You pass an image and bounding boxes to the augmentation pipeline and receive augmented images and boxes.","title":"Bounding boxes augmentation"},{"location":"getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries","text":"import albumentations as A import cv2","title":"Step 1. Import the required libraries."},{"location":"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline","text":"Here an example of a minimal declaration of an augmentation pipeline that works with bounding boxes. transform = A . Compose ([ A . RandomCrop ( width = 450 , height = 450 ), A . HorizontalFlip ( p = 0.5 ), A . RandomBrightnessContrast ( p = 0.2 ), ], bbox_params = A . BboxParams ( format = 'coco' )) Note that unlike image and masks augmentation, Compose now has an additional parameter bbox_params . You need to pass an instance of A.BboxParams to that argument. A.BboxParams specifies settings for working with bounding boxes. format sets the format for bounding boxes coordinates. It can either be pascal_voc , albumentations , coco or yolo . This value is required because Albumentation needs to know the coordinates' source format for bounding boxes to apply augmentations correctly. Besides format , A.BboxParams supports a few more settings. Here is an example of Compose that shows all available settings with A.BboxParams : transform = A . Compose ([ A . RandomCrop ( width = 450 , height = 450 ), A . HorizontalFlip ( p = 0.5 ), A . RandomBrightnessContrast ( p = 0.2 ), ], bbox_params = A . BboxParams ( format = 'coco' , min_area = 1024 , min_visibility = 0.1 , label_fields = [ 'class_labels' ]))","title":"Step 2. Define an augmentation pipeline."},{"location":"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility","text":"min_area and min_visibility parameters control what Albumentations should do to the augmented bounding boxes if their size has changed after augmentation. The size of bounding boxes could change if you apply spatial augmentations, for example, when you crop a part of an image or when you resize an image. min_area is a value in pixels. If the area of a bounding box after augmentation becomes smaller than min_area , Albumentations will drop that box. So the returned list of augmented bounding boxes won't contain that bounding box. min_visibility is a value between 0 and 1. If the ratio of the bounding box area after augmentation to the area of the bounding box before augmentation becomes smaller than min_visibility , Albumentations will drop that box. So if the augmentation process cuts the most of the bounding box, that box won't be present in the returned list of the augmented bounding boxes. Here is an example image that contains two bounding boxes. Bounding boxes coordinates are declared using the coco format. An example image with two bounding boxes First, we apply the CenterCrop augmentation without declaring parameters min_area and min_visiiblity . The augmented image contains two bounding boxes. An example image with two bounding boxes after applying augmentation Next, we apply the same CenterCrop augmentation, but now we also use the min_area parameter. Now, the augmented image contains only one bounding box, because the other bounding box's area after augmentation became smaller than min_area , so Albumentations dropped that bounding box. An example image with one bounding box after applying augmentation with 'min_area' Finally, we apply the CenterCrop augmentation with the min_visibility . After that augmentation, the resulting image doesn't contain any bounding box, because visibility of all bounding boxes after augmentation are below threshold set by min_visibility . An example image with zero bounding boxes after applying augmentation with 'min_visibility'","title":"min_area and min_visibility"},{"location":"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes","text":"Besides coordinates, each bounding box should have an associated class label that tells which object lies inside the bounding box. There are two ways to pass a label for a bounding box. Let's say you have an example image with three objects: dog , cat , and sports ball . Bounding boxes coordinates in the coco format for those objects are [23, 74, 295, 388] , [377, 294, 252, 161] , and [333, 421, 49, 49] . An example image with 3 bounding boxes from the COCO dataset","title":"Class labels for bounding boxes"},{"location":"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates","text":"For the image above, bounding boxes with class labels will become [23, 74, 295, 388, 'dog'] , [377, 294, 252, 161, 'cat'] , and [333, 421, 49, 49, 'sports ball'] . Class labels could be of any type: integer, string, or any other Python data type. For example, integer values as class labels will look the following: [23, 74, 295, 388, 18] , [377, 294, 252, 161, 17] , and [333, 421, 49, 49, 37]. Also, you can use multiple class values for each bounding box, for example [23, 74, 295, 388, 'dog', 'animal'] , [377, 294, 252, 161, 'cat', 'animal'] , and [333, 421, 49, 49, 'sports ball', 'item'] .","title":"1. You can pass labels along with bounding boxes coordinates by adding them as additional values to the list of coordinates."},{"location":"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list","text":"For example, if you have three bounding boxes like [23, 74, 295, 388] , [377, 294, 252, 161] , and [333, 421, 49, 49] you can create a separate list with values like ['cat', 'dog', 'sports ball'] , or [18, 17, 37] that contains class labels for those bounding boxes. Next, you pass that list with class labels as a separate argument to the transform function. Albumentations needs to know the names of all those lists with class labels to join them with augmented bounding boxes correctly. Then, if a bounding box is dropped after augmentation because it is no longer visible, Albumentations will drop the class label for that box as well. Use label_fields parameter to set names for all arguments in transform that will contain label descriptions for bounding boxes (more on that in Step 4).","title":"2.You can pass labels for bounding boxes as a separate list."},{"location":"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk","text":"Read an image from the disk. image = cv2 . imread ( \"/path/to/image.jpg\" ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) Bounding boxes can be stored on the disk in different serialization formats: JSON, XML, YAML, CSV, etc. So the code to read bounding boxes depends on the actual format of data on the disk. After you read the data from the disk, you need to prepare bounding boxes for Albumentations. Albumentations expects that bounding boxes will be represented as a list of lists. Each list contains information about a single bounding box. A bounding box definition should have at list four elements that represent the coordinates of that bounding box. The actual meaning of those four values depends on the format of bounding boxes (either pascal_voc , albumentations , coco , or yolo ). Besides four coordinates, each definition of a bounding box may contain one or more extra values. You can use those extra values to store additional information about the bounding box, such as a class label of the object inside the box. During augmentation, Albumentations will not process those extra values. The library will return them as is along with the updated coordinates of the augmented bounding box.","title":"Step 3. Read images and bounding boxes from the disk."},{"location":"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes","text":"As discussed in Step 2, there are two ways of passing class labels along with bounding boxes coordinates:","title":"Step 4. Pass an image and bounding boxes to the augmentation pipeline and receive augmented images and boxes."},{"location":"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates","text":"So, if you have coordinates of three bounding boxes that look like this: bboxes = [ [ 23 , 74 , 295 , 388 ], [ 377 , 294 , 252 , 161 ], [ 333 , 421 , 49 , 49 ], ] you can add a class label for each bounding box as an additional element of the list along with four coordinates. So now a list with bounding boxes and their coordinates will look the following: bboxes = [ [ 23 , 74 , 295 , 388 , 'dog' ], [ 377 , 294 , 252 , 161 , 'cat' ], [ 333 , 421 , 49 , 49 , 'sports ball' ], ] or with multiple labels per each bounding box: bboxes = [ [ 23 , 74 , 295 , 388 , 'dog' , 'animal' ], [ 377 , 294 , 252 , 161 , 'cat' , 'animal' ], [ 333 , 421 , 49 , 49 , 'sports ball' , 'item' ], ] You can use any data type for declaring class labels. It can be string, integer, or any other Python data type. Next, you pass an image and bounding boxes for it to the transform function and receive the augmented image and bounding boxes. transformed = transform ( image = image , bboxes = bboxes ) transformed_image = transformed [ 'image' ] transformed_bboxes = transformed [ 'bboxes' ] Example input and output data for bounding boxes augmentation","title":"1. Pass class labels along with coordinates."},{"location":"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform","text":"Let's say you have coordinates of three bounding boxes bboxes = [ [ 23 , 74 , 295 , 388 ], [ 377 , 294 , 252 , 161 ], [ 333 , 421 , 49 , 49 ], ] You can create a separate list that contains class labels for those bounding boxes: class_labels = [ 'cat' , 'dog' , 'parrot' ] Then you pass both bounding boxes and class labels to transform . Note that to pass class labels, you need to use the name of the argument that you declared in label_fields when creating an instance of Compose in step 2. In our cse, we set the name of the argument to class_labels . transformed = transform ( image = image , bboxes = bboxes , class_labels = class_labels ) transformed_image = transformed [ 'image' ] transformed_bboxes = transformed [ 'bboxes' ] transformed_class_labels = transformed [ 'class_labels' ] Example input and output data for bounding boxes augmentation with a separate argument for class labels Note that label_fields expects a list, so you can set multiple fields that contain labels for your bounding boxes. So if you declare Compose like transform = A . Compose ([ A . RandomCrop ( width = 450 , height = 450 ), A . HorizontalFlip ( p = 0.5 ), A . RandomBrightnessContrast ( p = 0.2 ), ], bbox_params = A . BboxParams ( format = 'coco' , label_fields = [ 'class_labels' , 'class_category' ]))) you can use those multiple arguments to pass info about class labels, like class_labels = [ 'cat' , 'dog' , 'parrot' ] class_category = [ 'animal' , 'animal' , 'item' ] transformed = transform ( image = image , bboxes = bboxes , class_labels = class_labels , class_category = class_category ) transformed_image = transformed [ 'image' ] transformed_bboxes = transformed [ 'bboxes' ] transformed_class_labels = transformed [ 'class_labels' ] transformed_class_category = transformed [ 'class_category' ]","title":"2. Pass class labels in a separate argument to transform."},{"location":"getting_started/image_augmentation/","text":"Image augmentation for classification We can divide the process of image augmentation into four steps: Import albumentations and a library to read images from the disk (e.g., OpenCV). Define an augmentation pipeline. Read images from the disk. Pass images to the augmentation pipeline and receive augmented images. Step 1. Import the required libraries. Import Albumentations import albumentations as A Import a library to read images from the disk. In this example, we will use OpenCV . It is an open-source computer vision library that supports many image formats. Albumentations has OpenCV as a dependency, so you already have OpenCV installed. import cv2 Step 2. Define an augmentation pipeline. To define an augmentation pipeline, you need to create an instance of the Compose class. As an argument to the Compose class, you need to pass a list of augmentations you want to apply. A call to Compose will return a transform function that will perform image augmentation. Let's look at an example: transform = A . Compose ([ A . RandomCrop ( width = 256 , height = 256 ), A . HorizontalFlip ( p = 0.5 ), A . RandomBrightnessContrast ( p = 0.2 ), ]) In the example, Compose receives a list with three augmentations: A.RandomCrop , A.HorizontalFlip , and A.RandomBrighntessContrast . You can find the full list of all available augmentations in the GitHub repository and in the API Docs . A demo playground that demonstrates how augmentations will transform the input image is available at https://albumentations-demo.herokuapp.com . To create an augmentation, you create an instance of the required augmentation class and pass augmentation parameters to it. A.RandomCrop receives two parameters, height and width . A.RandomCrop(width=256, height=256) means that A.RandomCrop will take an input image, extract a random patch with size 256 by 256 pixels from it and then pass the result to the next augmentation in the pipeline (in this case to A.HorizontalFlip ). A.HorizontalFlip in this example has one parameter named p . p is a special parameter that is supported by almost all augmentations. It controls the probability of applying the augmentation. p=0.5 means that with a probability of 50%, the transform will flip the image horizontally, and with a probability of 50%, the transform won't modify the input image. A.RandomBrighntessContrast in the example also has one parameter, p . With a probability of 20%, this augmentation will change the brightness and contrast of the image received from A.HorizontalFlip . And with a probability of 80%, it will keep the received image unchanged. A visualized version of the augmentation pipeline. You pass an image to it, the image goes through all transformations, and then you receive an augmented image from the pipeline. Step 3. Read images from the disk. To pass an image to the augmentation pipeline, you need to read it from the disk. The pipeline expects to receive an image in the form of a NumPy array. If it is a color image, it should have three channels in the following order: Red, Green, Blue (so a regular RGB image). To read images from the disk, you can use OpenCV - a popular library for image processing. It supports a lot of input formats and is installed along with Albumentations since Albumentations utilizes that library under the hood for a lot of augmentations. To import OpenCV import cv2 To read an image with OpenCV image = cv2 . imread ( \"/path/to/image.jpg\" ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) Note the usage of cv2.cvtColor . For historical reasons , OpenCV reads an image in BGR format (so color channels of the image have the following order: Blue, Green, Red). Albumentations uses the most common and popular RGB image format. So when using OpenCV, we need to convert the image format to RGB explicitly. Besides OpenCV, you can use other image processing libraries. Pillow Pillow is a popular Python image processing library. Install Pillow pip install pillow Import Pillow and NumPy (we need NumPy to convert a Pillow image to a NumPy array. NumPy is already installed along with Albumentations). from PIL import Image import numpy as np Read an image with Pillow and convert it to a NumPy array. pillow_image = Image . open ( \"image.jpg\" ) image = np . array ( pillow_image ) Step 4. Pass images to the augmentation pipeline and receive augmented images. To pass an image to the augmentation pipeline you need to call the transform function created by a call to A.Compose at Step 2. In the image argument to that function, you need to pass an image that you want to augment. transformed = transform ( image = image ) transform will return a dictionary with a single key image . Value at that key will contain an augmented image. transformed_image = transformed [ \"image\" ] To augment the next image, you need to call transform again and pass a new image as the image argument: another_transformed_image = transform ( image = another_image )[ \"image\" ] Each augmentation will change the input image with the probability set by the parameter p . Also, many augmentations have parameters that control the magnitude of changes that will be applied to an image. For example, A.RandomBrightnessContrast has two parameters: brightness_limit that controls the magnitude of adjusting brightness and contrast_limit that controls the magnitude of adjusting contrast. The bigger the value, the more the augmentation will change an image. During augmentation, a magnitude of the transformation is sampled from a uniform distribution limited by brightness_limit and contrast_limit . That means that if you make multiple calls to transform with the same input image, you will get a different output image each time. transform = A . Compose ([ A . RandomBrightnessContrast ( brightness_limit = 1 , contrast_limit = 1 , p = 1.0 ), ]) transformed_image_1 = transform ( image = image )[ 'image' ] transformed_image_2 = transform ( image = image )[ 'image' ] transformed_image_3 = transform ( image = image )[ 'image' ]","title":"Image augmentation for classification"},{"location":"getting_started/image_augmentation/#image-augmentation-for-classification","text":"We can divide the process of image augmentation into four steps: Import albumentations and a library to read images from the disk (e.g., OpenCV). Define an augmentation pipeline. Read images from the disk. Pass images to the augmentation pipeline and receive augmented images.","title":"Image augmentation for classification"},{"location":"getting_started/image_augmentation/#step-1-import-the-required-libraries","text":"Import Albumentations import albumentations as A Import a library to read images from the disk. In this example, we will use OpenCV . It is an open-source computer vision library that supports many image formats. Albumentations has OpenCV as a dependency, so you already have OpenCV installed. import cv2","title":"Step 1. Import the required libraries."},{"location":"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline","text":"To define an augmentation pipeline, you need to create an instance of the Compose class. As an argument to the Compose class, you need to pass a list of augmentations you want to apply. A call to Compose will return a transform function that will perform image augmentation. Let's look at an example: transform = A . Compose ([ A . RandomCrop ( width = 256 , height = 256 ), A . HorizontalFlip ( p = 0.5 ), A . RandomBrightnessContrast ( p = 0.2 ), ]) In the example, Compose receives a list with three augmentations: A.RandomCrop , A.HorizontalFlip , and A.RandomBrighntessContrast . You can find the full list of all available augmentations in the GitHub repository and in the API Docs . A demo playground that demonstrates how augmentations will transform the input image is available at https://albumentations-demo.herokuapp.com . To create an augmentation, you create an instance of the required augmentation class and pass augmentation parameters to it. A.RandomCrop receives two parameters, height and width . A.RandomCrop(width=256, height=256) means that A.RandomCrop will take an input image, extract a random patch with size 256 by 256 pixels from it and then pass the result to the next augmentation in the pipeline (in this case to A.HorizontalFlip ). A.HorizontalFlip in this example has one parameter named p . p is a special parameter that is supported by almost all augmentations. It controls the probability of applying the augmentation. p=0.5 means that with a probability of 50%, the transform will flip the image horizontally, and with a probability of 50%, the transform won't modify the input image. A.RandomBrighntessContrast in the example also has one parameter, p . With a probability of 20%, this augmentation will change the brightness and contrast of the image received from A.HorizontalFlip . And with a probability of 80%, it will keep the received image unchanged. A visualized version of the augmentation pipeline. You pass an image to it, the image goes through all transformations, and then you receive an augmented image from the pipeline.","title":"Step 2. Define an augmentation pipeline."},{"location":"getting_started/image_augmentation/#step-3-read-images-from-the-disk","text":"To pass an image to the augmentation pipeline, you need to read it from the disk. The pipeline expects to receive an image in the form of a NumPy array. If it is a color image, it should have three channels in the following order: Red, Green, Blue (so a regular RGB image). To read images from the disk, you can use OpenCV - a popular library for image processing. It supports a lot of input formats and is installed along with Albumentations since Albumentations utilizes that library under the hood for a lot of augmentations. To import OpenCV import cv2 To read an image with OpenCV image = cv2 . imread ( \"/path/to/image.jpg\" ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) Note the usage of cv2.cvtColor . For historical reasons , OpenCV reads an image in BGR format (so color channels of the image have the following order: Blue, Green, Red). Albumentations uses the most common and popular RGB image format. So when using OpenCV, we need to convert the image format to RGB explicitly. Besides OpenCV, you can use other image processing libraries.","title":"Step 3. Read images from the disk."},{"location":"getting_started/image_augmentation/#pillow","text":"Pillow is a popular Python image processing library. Install Pillow pip install pillow Import Pillow and NumPy (we need NumPy to convert a Pillow image to a NumPy array. NumPy is already installed along with Albumentations). from PIL import Image import numpy as np Read an image with Pillow and convert it to a NumPy array. pillow_image = Image . open ( \"image.jpg\" ) image = np . array ( pillow_image )","title":"Pillow"},{"location":"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images","text":"To pass an image to the augmentation pipeline you need to call the transform function created by a call to A.Compose at Step 2. In the image argument to that function, you need to pass an image that you want to augment. transformed = transform ( image = image ) transform will return a dictionary with a single key image . Value at that key will contain an augmented image. transformed_image = transformed [ \"image\" ] To augment the next image, you need to call transform again and pass a new image as the image argument: another_transformed_image = transform ( image = another_image )[ \"image\" ] Each augmentation will change the input image with the probability set by the parameter p . Also, many augmentations have parameters that control the magnitude of changes that will be applied to an image. For example, A.RandomBrightnessContrast has two parameters: brightness_limit that controls the magnitude of adjusting brightness and contrast_limit that controls the magnitude of adjusting contrast. The bigger the value, the more the augmentation will change an image. During augmentation, a magnitude of the transformation is sampled from a uniform distribution limited by brightness_limit and contrast_limit . That means that if you make multiple calls to transform with the same input image, you will get a different output image each time. transform = A . Compose ([ A . RandomBrightnessContrast ( brightness_limit = 1 , contrast_limit = 1 , p = 1.0 ), ]) transformed_image_1 = transform ( image = image )[ 'image' ] transformed_image_2 = transform ( image = image )[ 'image' ] transformed_image_3 = transform ( image = image )[ 'image' ]","title":"Step 4. Pass images to the augmentation pipeline and receive augmented images."},{"location":"getting_started/installation/","text":"Installation Albumentations requires Python 3.5 or higher. Install the latest stable version from PyPI pip install -U albumentations Install the latest version from the master's branch on GitHub pip install -U git+https://github.com/albumentations-team/albumentations","title":"Installation"},{"location":"getting_started/installation/#installation","text":"Albumentations requires Python 3.5 or higher.","title":"Installation"},{"location":"getting_started/installation/#install-the-latest-stable-version-from-pypi","text":"pip install -U albumentations","title":"Install the latest stable version from PyPI"},{"location":"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github","text":"pip install -U git+https://github.com/albumentations-team/albumentations","title":"Install the latest version from the master's branch on GitHub"},{"location":"getting_started/mask_augmentation/","text":"Mask augmentation for segmentation For instance and semantic segmentation tasks, you need to augment both the input image and one or more output masks. Albumentations ensures that the input image and the output mask will receive the same set of augmentations with the same parameters. The process of augmenting images and masks looks very similar to the regular image-only augmentation . You import the required libraries. You define an augmentation pipeline. You read images and masks from the disk. You pass an image and one or more masks to the augmentation pipeline and receive augmented images and masks. Steps 1 and 2. Import the required libraries and define an augmentation pipeline. Image augmentation for classification described Steps 1 and 2 in great detail. These are the same steps for the simultaneous augmentation of images and masks. import albumentations as A import cv2 transform = A . Compose ([ A . RandomCrop ( width = 256 , height = 256 ), A . HorizontalFlip ( p = 0.5 ), A . RandomBrightnessContrast ( p = 0.2 ), ]) Step 3. Read images and masks from the disk. Reading an image image = cv2 . imread ( \"/path/to/image.jpg\" ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) For semantic segmentation, you usually read one mask per image. Albumentations expects the mask to be a NumPy array. The height and width of the mask should have the same values as the height and width of the image. mask = cv2 . imread ( \"/path/to/mask.png\" ) For instance segmentation, you sometimes need to read multiple masks per image. Then you create a list that contains all the masks. mask_1 = cv2 . imread ( \"/path/to/mask_1.png\" ) mask_2 = cv2 . imread ( \"/path/to/mask_2.png\" ) mask_3 = cv2 . imread ( \"/path/to/mask_3.png\" ) masks = [ mask_1 , mask_2 , mask_3 ] Some datasets use other formats to store masks. For example, they can use Run-Length Encoding or Polygon coordinates. In that case, you need to convert a mask to a NumPy before augmenting it with Albumentations. Often dataset authors provide special libraries and tools to simplify the conversion. Step 4. Pass image and masks to the augmentation pipeline and receive augmented images and masks. If the image has one associated mask, you need to call transform with two arguments: image and mask . In image you should pass the input image, in mask you should pass the output mask. transform will return a dictionary with two keys: image will contain the augmented image, and mask will contain the augmented mask. transformed = transform ( image = image , mask = mask ) transformed_image = transformed [ 'image' ] transformed_mask = transformed [ 'mask' ] An image and a mask before and after augmentation. Inria Aerial Image Labeling dataset contains aerial photos as well as their segmentation masks. Each pixel of the mask is marked as 1 if the pixel belongs to the class building and 0 otherwise. If the image has multiple associated masks, you should use the masks argument instead of mask . In masks you should pass a list of masks. transformed = transform ( image = image , masks = masks ) transformed_image = transformed [ 'image' ] transformed_masks = transformed [ 'masks' ]","title":"Mask augmentation for segmentation"},{"location":"getting_started/mask_augmentation/#mask-augmentation-for-segmentation","text":"For instance and semantic segmentation tasks, you need to augment both the input image and one or more output masks. Albumentations ensures that the input image and the output mask will receive the same set of augmentations with the same parameters. The process of augmenting images and masks looks very similar to the regular image-only augmentation . You import the required libraries. You define an augmentation pipeline. You read images and masks from the disk. You pass an image and one or more masks to the augmentation pipeline and receive augmented images and masks.","title":"Mask augmentation for segmentation"},{"location":"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline","text":"Image augmentation for classification described Steps 1 and 2 in great detail. These are the same steps for the simultaneous augmentation of images and masks. import albumentations as A import cv2 transform = A . Compose ([ A . RandomCrop ( width = 256 , height = 256 ), A . HorizontalFlip ( p = 0.5 ), A . RandomBrightnessContrast ( p = 0.2 ), ])","title":"Steps 1 and 2. Import the required libraries and define an augmentation pipeline."},{"location":"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk","text":"Reading an image image = cv2 . imread ( \"/path/to/image.jpg\" ) image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2RGB ) For semantic segmentation, you usually read one mask per image. Albumentations expects the mask to be a NumPy array. The height and width of the mask should have the same values as the height and width of the image. mask = cv2 . imread ( \"/path/to/mask.png\" ) For instance segmentation, you sometimes need to read multiple masks per image. Then you create a list that contains all the masks. mask_1 = cv2 . imread ( \"/path/to/mask_1.png\" ) mask_2 = cv2 . imread ( \"/path/to/mask_2.png\" ) mask_3 = cv2 . imread ( \"/path/to/mask_3.png\" ) masks = [ mask_1 , mask_2 , mask_3 ] Some datasets use other formats to store masks. For example, they can use Run-Length Encoding or Polygon coordinates. In that case, you need to convert a mask to a NumPy before augmenting it with Albumentations. Often dataset authors provide special libraries and tools to simplify the conversion.","title":"Step 3. Read images and masks from the disk."},{"location":"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks","text":"If the image has one associated mask, you need to call transform with two arguments: image and mask . In image you should pass the input image, in mask you should pass the output mask. transform will return a dictionary with two keys: image will contain the augmented image, and mask will contain the augmented mask. transformed = transform ( image = image , mask = mask ) transformed_image = transformed [ 'image' ] transformed_mask = transformed [ 'mask' ] An image and a mask before and after augmentation. Inria Aerial Image Labeling dataset contains aerial photos as well as their segmentation masks. Each pixel of the mask is marked as 1 if the pixel belongs to the class building and 0 otherwise. If the image has multiple associated masks, you should use the masks argument instead of mask . In masks you should pass a list of masks. transformed = transform ( image = image , masks = masks ) transformed_image = transformed [ 'image' ] transformed_masks = transformed [ 'masks' ]","title":"Step 4. Pass image and masks to the augmentation pipeline and receive augmented images and masks."},{"location":"introduction/image_augmentation/","text":"What is image augmentation and how it can improve the performance of deep neural networks Deep neural networks require a lot of training data to obtain good results and prevent overfitting. However, it often very difficult to get enough training samples. Multiple reasons could make it very hard or even impossible to gather enough data: To make a training dataset, you need to obtain images and then label them. For example, you need to assign correct class labels if you have an image classification task. For an object detection task, you need to draw bounding boxes around objects. For a semantic segmentation task, you need to assign a correct class to each input image pixel. This process requires manual labor, and sometimes it could be very costly to label the training data. For example, to correctly label medical images, you need expensive domain experts. Sometimes even collecting training images could be hard. There are many legal restrictions for working with healthcare data, and obtaining it requires a lot of effort. Sometimes getting the training images is more feasible, but it will cost a lot of money. For example, to get satellite images, you need to pay a satellite operator to take those photos. To get images for road scene recognition, you need an operator that will drive a car and collect the required data. Image augmentation to the rescue Image augmentation is a process of creating new training examples from the existing ones. To make a new sample, you slightly change the original image. For instance, you could make a new image a little brighter; you could cut a piece from the original image; you could make a new image by mirroring the original one, etc. Here are some examples of transformations of the original image that will create a new training sample. By applying those transformations to the original training dataset, you could create an almost infinite amount of new training samples. How much does image augmentation improves the quality and performance of deep neural networks Basic augmentations techniques were used almost in all papers that describe the state-of-the-art models for image recognition. AlexNet was the first model that demonstrated exceptional capabilities of using deep neural networks for image recognition. For training, the authors used a set of basic image augmentation techniques. They resized original images to the fixed size of 256 by 256 pixels, and then they cropped patches of size 224 by 224 pixels as well as their horizontal reflections from those resized images. Also, they altered the intensities of the RGB channels in images. Successive state-of-the-art models such as Inception , ResNet , and EfficientNet also used image augmentation techniques for training. In 2018 Google published a paper about AutoAugment - an algorithm that automatically discovers the best set of augmentations for the dataset. They showed that a custom set of augmentations improves the performance of the model. Here is a comparison between a model that used only the base set of augmentations and a model that used a specific set of augmentations discovered by AutoAugment. The table shows Top-1 accuracy (%) on the ImageNet validation set; higher is better. Model Base augmentations AutoAugment augmentations ResNet-50 76.3 77.6 ResNet-200 78.5 80.0 AmoebaNet-B (6,190) 82.2 82.8 AmoebaNet-C (6,228) 83.1 83.5 The table demonstrates that a diverse set of image augmentations improves the performance of neural networks compared to a base set with only a few most popular transformation techniques. Augmentations help to fight overfitting and improve the performance of deep neural networks for computer vision tasks such as classification, segmentation, and object detection. The best part is that image augmentations libraries such as Albumentations make it possible to add image augmentations to any computer vision pipeline with minimal effort.","title":"What is image augmentation and how it can improve the performance of deep neural networks"},{"location":"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks","text":"Deep neural networks require a lot of training data to obtain good results and prevent overfitting. However, it often very difficult to get enough training samples. Multiple reasons could make it very hard or even impossible to gather enough data: To make a training dataset, you need to obtain images and then label them. For example, you need to assign correct class labels if you have an image classification task. For an object detection task, you need to draw bounding boxes around objects. For a semantic segmentation task, you need to assign a correct class to each input image pixel. This process requires manual labor, and sometimes it could be very costly to label the training data. For example, to correctly label medical images, you need expensive domain experts. Sometimes even collecting training images could be hard. There are many legal restrictions for working with healthcare data, and obtaining it requires a lot of effort. Sometimes getting the training images is more feasible, but it will cost a lot of money. For example, to get satellite images, you need to pay a satellite operator to take those photos. To get images for road scene recognition, you need an operator that will drive a car and collect the required data.","title":"What is image augmentation and how it can improve the performance of deep neural networks"},{"location":"introduction/image_augmentation/#image-augmentation-to-the-rescue","text":"Image augmentation is a process of creating new training examples from the existing ones. To make a new sample, you slightly change the original image. For instance, you could make a new image a little brighter; you could cut a piece from the original image; you could make a new image by mirroring the original one, etc. Here are some examples of transformations of the original image that will create a new training sample. By applying those transformations to the original training dataset, you could create an almost infinite amount of new training samples.","title":"Image augmentation to the rescue"},{"location":"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks","text":"Basic augmentations techniques were used almost in all papers that describe the state-of-the-art models for image recognition. AlexNet was the first model that demonstrated exceptional capabilities of using deep neural networks for image recognition. For training, the authors used a set of basic image augmentation techniques. They resized original images to the fixed size of 256 by 256 pixels, and then they cropped patches of size 224 by 224 pixels as well as their horizontal reflections from those resized images. Also, they altered the intensities of the RGB channels in images. Successive state-of-the-art models such as Inception , ResNet , and EfficientNet also used image augmentation techniques for training. In 2018 Google published a paper about AutoAugment - an algorithm that automatically discovers the best set of augmentations for the dataset. They showed that a custom set of augmentations improves the performance of the model. Here is a comparison between a model that used only the base set of augmentations and a model that used a specific set of augmentations discovered by AutoAugment. The table shows Top-1 accuracy (%) on the ImageNet validation set; higher is better. Model Base augmentations AutoAugment augmentations ResNet-50 76.3 77.6 ResNet-200 78.5 80.0 AmoebaNet-B (6,190) 82.2 82.8 AmoebaNet-C (6,228) 83.1 83.5 The table demonstrates that a diverse set of image augmentations improves the performance of neural networks compared to a base set with only a few most popular transformation techniques. Augmentations help to fight overfitting and improve the performance of deep neural networks for computer vision tasks such as classification, segmentation, and object detection. The best part is that image augmentations libraries such as Albumentations make it possible to add image augmentations to any computer vision pipeline with minimal effort.","title":"How much does image augmentation improves the quality and performance of deep neural networks"},{"location":"introduction/why_albumentations/","text":"Why Albumentations A single interface to work with images, masks, bounding boxes, and key points. Albumentations provides a single interface to work with different computer vision tasks such as classification, semantic segmentation, instance segmentation, object detection, pose estimation, etc. Battle-tested The library is widely used in industry , deep learning research , machine learning competitions , and open source projects . High performance Albumentations optimized for maximum speed and performance. Under the hood, the library uses highly optimized functions from OpenCV and NumPy for data processing. We have a regularly updated benchmark that compares the speed of popular image augmentations libraries for the most common image transformations. Albumentations demonstrates the best performance in most cases. Diverse set of supported augmentations Albumentations supports more than 60 different image augmentations. Extensibility Albumentations allows to easily add new augmentations and use them in computer vision pipelines through a single interface along with built-in transformations. Rigorous testing Bugs in the augmentation pipeline could silently corrupt the input data. They can easily go unnoticed, but the performance of the models trained with incorrect data will degrade. Albumentations has an extensive test suite that helps to discover bugs during development. It is open source and MIT licensed You can find the source code on GitHub .","title":"Why Albumentations"},{"location":"introduction/why_albumentations/#why-albumentations","text":"","title":"Why Albumentations"},{"location":"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points","text":"Albumentations provides a single interface to work with different computer vision tasks such as classification, semantic segmentation, instance segmentation, object detection, pose estimation, etc.","title":"A single interface to work with images, masks, bounding boxes, and key points."},{"location":"introduction/why_albumentations/#battle-tested","text":"The library is widely used in industry , deep learning research , machine learning competitions , and open source projects .","title":"Battle-tested"},{"location":"introduction/why_albumentations/#high-performance","text":"Albumentations optimized for maximum speed and performance. Under the hood, the library uses highly optimized functions from OpenCV and NumPy for data processing. We have a regularly updated benchmark that compares the speed of popular image augmentations libraries for the most common image transformations. Albumentations demonstrates the best performance in most cases.","title":"High performance"},{"location":"introduction/why_albumentations/#diverse-set-of-supported-augmentations","text":"Albumentations supports more than 60 different image augmentations.","title":"Diverse set of supported augmentations"},{"location":"introduction/why_albumentations/#extensibility","text":"Albumentations allows to easily add new augmentations and use them in computer vision pipelines through a single interface along with built-in transformations.","title":"Extensibility"},{"location":"introduction/why_albumentations/#rigorous-testing","text":"Bugs in the augmentation pipeline could silently corrupt the input data. They can easily go unnoticed, but the performance of the models trained with incorrect data will degrade. Albumentations has an extensive test suite that helps to discover bugs during development.","title":"Rigorous testing"},{"location":"introduction/why_albumentations/#it-is-open-source-and-mit-licensed","text":"You can find the source code on GitHub .","title":"It is open source and MIT licensed"},{"location":"introduction/why_you_need_a_dedicated_library_for_image_augmentation/","text":"Why you need a dedicated library for image augmentation At first glance, image augmentations look very simple; you apply basic transformations to an image: mirroring, cropping, changing brightness and contrast, etc. There are a lot of libraries that could do such image transformations. Here is an example of how you could use Pillow , a popular image processing library for Python, to make simple augmentations. from PIL import Image , ImageEnhance image = Image . open ( \"parrot.jpg\" ) mirrored_image = image . transpose ( Image . FLIP_LEFT_RIGHT ) rotated_image = image . rotate ( 45 ) brightness_enhancer = ImageEnhance . Brightness ( image ) brighter_image = brightness_enhancer . enhance ( factor = 1.5 ) However, this approach has many limitations, and it doesn't handle all cases with image augmentation. An image augmentation library such as Albumentations gives you a lot of advantages. Here is a list of few pitfalls that augmentation libraries can handle very well. The need to apply the same transform to an image and for labels for segmentation, object detection, and keypoint detection tasks. For image classification, you need to modify only an input image and keep output labels intact because output labels are invariant to image modifications. Note There are some exceptions to this rule. For example, an image could contain a cat and have an assigned label cat . During image augmentation, if you crop a part of an image that doesn't have a cat on it, then the output label cat becomes wrong and misleading. Usually, you deal with those situations by deciding which augmentations you could apply to a dataset without risking to have problems with incorrect labels. For segmentation, you need to apply some transformations both to an input image and an output mask. You also have to use the same parameters both for the image transformation and the mask transformation. Let's look at an example of a semantic segmentation task from Inria Aerial Image Labeling Dataset. The dataset contains aerial photos as well as masks for those photos. Each pixel of the mask is marked either as 1 if the pixel belongs to the class building and 0 otherwise. There are two types of image augmentations: pixel-level augmentations and spatial-level augmentations. Pixel-level augmentations change the values of pixels of the original image, but they don't change the output mask. Image transformations such as changing brightness or contrast of adjusting values of the RGB-palette of the image are pixel-level augmentations. We modify the input image by adjusting its brightness, but we keep the output mask intact. On the contrary, spatial-level augmentations change both the image and the mask. When you apply image transformations such as mirroring or rotation or cropping a part of the input image, you also need to apply the same transformation to the output label to preserve its correctness. We rotate both the input image and the output mask. We use the same set of transformations with the same parameters, both for the image and the mask. The same is true for object detection tasks. For pixel-level augmentations, you only need to change the input image. With spatial-level augmentations, you need to apply the same transformation not only to the image but for bounding boxes coordinates as well. After applying spatial-level augmentations, you need to update coordinates of bounding boxes to represent the correct locations of objects on the augmented image. Pixel-level augmentations such as brightness adjustment change only the input image but not the coordinates of bounding boxes. Spatial-level augmentations such as mirroring and cropping a part of the image change both the input image and the bounding boxes' coordinates. Albumentations knows how to correctly apply transformation both to the input data as well as the output labels. Working with probabilities During training, you usually want to apply augmentations with a probability of less than 100% since you also need to have the original images in your training pipeline. Also, it is beneficial to be able to control the magnitude of image augmentation, how much does the augmentation change the original image. If the original dataset is large, you could apply only the basic augmentations with probability around 10-30% and with a small magnitude of changes. If the dataset is small, you need to act more aggressively with augmentations to prevent overfitting of neural networks, so you usually need to increase the probability of applying each augmentation to 40-50% and increase the magnitude of changes the augmentation makes to the image. Image augmentation libraries allow you to set the required probabilities and the magnitude of values for each transformation. Declarative definition of the augmentation pipeline and unified interface Usually, you want to apply not a single augmentation, but a set of augmentations with specific parameters such as probability and magnitude of changes. Augmentation libraries allow you to declare such a pipeline in a single place and then use it for image transformation through a unified interface. Some libraries can store and load transformation parameters to formats such as JSON, YAML, etc. Here is an example definition of an augmentation pipeline. This pipeline will first crop a random 512px x 512px part of the input image. Then with probability 30%, it will randomly change brightness and contrast of that crop. Finally, with probability 30%, it will horizontally flip the resulting image. import albumentations as A transform = A . Compose ([ A . RandomCrop ( 512 , 512 ), A . RandomBrightnessContrast ( p = 0.3 ), A . HorizontalFlip ( p = 0.5 ), ]) Rigorous testing A bug in the augmentation pipeline could easily go unnoticed. A buggy pipeline could silently corrupt input data. There won't be any exceptions and code failures, but the performance of trained neural networks will degrade because they received a garbage input during training. Augmentation libraries usually have large test suites that capture regressions during development. Also large user base helps to find unnoticed bugs and report them to developers.","title":"Why you need a dedicated library for image augmentation"},{"location":"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation","text":"At first glance, image augmentations look very simple; you apply basic transformations to an image: mirroring, cropping, changing brightness and contrast, etc. There are a lot of libraries that could do such image transformations. Here is an example of how you could use Pillow , a popular image processing library for Python, to make simple augmentations. from PIL import Image , ImageEnhance image = Image . open ( \"parrot.jpg\" ) mirrored_image = image . transpose ( Image . FLIP_LEFT_RIGHT ) rotated_image = image . rotate ( 45 ) brightness_enhancer = ImageEnhance . Brightness ( image ) brighter_image = brightness_enhancer . enhance ( factor = 1.5 ) However, this approach has many limitations, and it doesn't handle all cases with image augmentation. An image augmentation library such as Albumentations gives you a lot of advantages. Here is a list of few pitfalls that augmentation libraries can handle very well.","title":"Why you need a dedicated library for image augmentation"},{"location":"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks","text":"For image classification, you need to modify only an input image and keep output labels intact because output labels are invariant to image modifications. Note There are some exceptions to this rule. For example, an image could contain a cat and have an assigned label cat . During image augmentation, if you crop a part of an image that doesn't have a cat on it, then the output label cat becomes wrong and misleading. Usually, you deal with those situations by deciding which augmentations you could apply to a dataset without risking to have problems with incorrect labels. For segmentation, you need to apply some transformations both to an input image and an output mask. You also have to use the same parameters both for the image transformation and the mask transformation. Let's look at an example of a semantic segmentation task from Inria Aerial Image Labeling Dataset. The dataset contains aerial photos as well as masks for those photos. Each pixel of the mask is marked either as 1 if the pixel belongs to the class building and 0 otherwise. There are two types of image augmentations: pixel-level augmentations and spatial-level augmentations. Pixel-level augmentations change the values of pixels of the original image, but they don't change the output mask. Image transformations such as changing brightness or contrast of adjusting values of the RGB-palette of the image are pixel-level augmentations. We modify the input image by adjusting its brightness, but we keep the output mask intact. On the contrary, spatial-level augmentations change both the image and the mask. When you apply image transformations such as mirroring or rotation or cropping a part of the input image, you also need to apply the same transformation to the output label to preserve its correctness. We rotate both the input image and the output mask. We use the same set of transformations with the same parameters, both for the image and the mask. The same is true for object detection tasks. For pixel-level augmentations, you only need to change the input image. With spatial-level augmentations, you need to apply the same transformation not only to the image but for bounding boxes coordinates as well. After applying spatial-level augmentations, you need to update coordinates of bounding boxes to represent the correct locations of objects on the augmented image. Pixel-level augmentations such as brightness adjustment change only the input image but not the coordinates of bounding boxes. Spatial-level augmentations such as mirroring and cropping a part of the image change both the input image and the bounding boxes' coordinates. Albumentations knows how to correctly apply transformation both to the input data as well as the output labels.","title":"The need to apply the same transform to an image and for labels for segmentation, object detection, and keypoint detection tasks."},{"location":"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities","text":"During training, you usually want to apply augmentations with a probability of less than 100% since you also need to have the original images in your training pipeline. Also, it is beneficial to be able to control the magnitude of image augmentation, how much does the augmentation change the original image. If the original dataset is large, you could apply only the basic augmentations with probability around 10-30% and with a small magnitude of changes. If the dataset is small, you need to act more aggressively with augmentations to prevent overfitting of neural networks, so you usually need to increase the probability of applying each augmentation to 40-50% and increase the magnitude of changes the augmentation makes to the image. Image augmentation libraries allow you to set the required probabilities and the magnitude of values for each transformation.","title":"Working with probabilities"},{"location":"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface","text":"Usually, you want to apply not a single augmentation, but a set of augmentations with specific parameters such as probability and magnitude of changes. Augmentation libraries allow you to declare such a pipeline in a single place and then use it for image transformation through a unified interface. Some libraries can store and load transformation parameters to formats such as JSON, YAML, etc. Here is an example definition of an augmentation pipeline. This pipeline will first crop a random 512px x 512px part of the input image. Then with probability 30%, it will randomly change brightness and contrast of that crop. Finally, with probability 30%, it will horizontally flip the resulting image. import albumentations as A transform = A . Compose ([ A . RandomCrop ( 512 , 512 ), A . RandomBrightnessContrast ( p = 0.3 ), A . HorizontalFlip ( p = 0.5 ), ])","title":"Declarative definition of the augmentation pipeline and unified interface"},{"location":"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing","text":"A bug in the augmentation pipeline could easily go unnoticed. A buggy pipeline could silently corrupt input data. There won't be any exceptions and code failures, but the performance of trained neural networks will degrade because they received a garbage input during training. Augmentation libraries usually have large test suites that capture regressions during development. Also large user base helps to find unnoticed bugs and report them to developers.","title":"Rigorous testing"}],"index":{"fieldVectors":[["title/",[0,3.524,1,1.287,2,2.786]],["text/",[0,3.964,1,2.853,2,3.134,3,3.729,4,3.729,5,0.509,6,2.231,7,2.822,8,3.729,9,1.828,10,3.729,11,4.168,12,5.232,13,3.729,14,3.729,15,3.729,16,2.773,17,2.773,18,3.729,19,2.634,20,5.08,21,6.004,22,5.562,23,6.004,24,2.701,25,4.279,26,3.307,27,3.376,28,3.119,29,4.969,30,3.134,31,2.701,32,2.851,33,3.029,34,2.634,35,3.307,36,2.851,37,3.672,38,2.357,39,2.955,40,3.696,41,4.27,42,4,43,2.406,44,2.406,45,1.85,46,3.251,47,2.143,48,3.541,49,2.571,50,1.313,51,1.209,52,1.267,53,4.279,54,3.541,55,3.251,56,3.964,57,3.964,58,3.964,59,3.964,60,4.12,61,3.964,62,3.964,63,3.964]],["title/#welcome-to-albumentations-documentation",[0,3.524,1,1.287,2,2.786]],["text/#welcome-to-albumentations-documentation",[1,2.785,3,4.638,4,4.638,5,0.497,6,2.049,7,2.912,8,4.638,9,2.045,10,4.638,11,4.184,12,6.067,13,4.638,14,4.638,15,4.638,16,3.449,17,3.449,18,4.638,19,3.276,20,5.098,21,6.962,22,4.931,23,6.962,24,3.359,25,5.322,26,2.931,27,2.993,28,2.765,29,4.405,30,3.898,31,3.359,32,3.546,33,3.768,34,3.276,35,2.931,36,3.546,37,3.686,38,2.931,39,2.619,40,3.276,41,3.276,42,3.546,43,2.993,44,2.993,45,2.302]],["title/#introduction-to-image-augmentation",[5,0.221,6,0.947,22,3.524]],["text/#introduction-to-image-augmentation",[1,2.398,5,0.483,6,2.07,7,2.659,11,4.258,26,3.902,27,3.984,28,3.681,46,5.383,47,3.549,48,5.863]],["title/#getting-started-with-albumentations",[1,1.287,20,2.786,29,3.148]],["text/#getting-started-with-albumentations",[5,0.415,6,2.203,35,3.928,37,3.776,39,3.509,40,4.39,49,4.286,50,2.188,51,2.015,52,2.111]],["title/#other-topics",[53,5.755]],["text/#other-topics",[54,6.359]],["title/#api-reference",[41,2.82,42,3.052]],["text/#api-reference",[6,1.776,41,4.39,55,5.418,56,6.607,57,6.607,58,6.607,59,6.607,60,5.727,61,6.607,62,6.607,63,6.607]],["title/contributing/",[54,4.762]],["text/contributing/",[1,1.709,7,1.896,49,5.045,54,4.18,64,5.32,65,5.051,66,3.699,67,7.561,68,5.861,69,3.466,70,3.996,71,5.051,72,7.561,73,4.18,74,5.051,75,5.051,76,4.14,77,6.725,78,6.725,79,5.861,80,5.051,81,5.051,82,8.395,83,8.395,84,5.861,85,5.051,86,6.725,87,5.531,88,5.051,89,6.725,90,5.051,91,5.11,92,4.18,93,1.398,94,3.699,95,5.051,96,4.762,97,2.902,98,2.674,99,5.051,100,5.051,101,5.051]],["title/contributing/#contributing",[54,4.762]],["text/contributing/#contributing",[1,1.717,7,1.905,49,5.053,64,5.337,65,5.075,66,3.717,67,7.578,68,5.879,69,3.482,70,4.014,71,5.075,72,7.578,73,4.2,74,5.075,75,5.075,76,4.153,77,6.746,78,6.746,79,5.879,80,5.075,81,5.075,82,8.408,83,8.408,84,5.879,85,5.075,86,6.746,87,5.542,88,5.075,89,6.746,90,5.075,91,5.125,92,4.2,93,1.401,94,3.717,95,5.075,96,4.777,97,2.915,98,2.687,99,5.075,100,5.075,101,5.075]],["title/api_reference/",[55,4.372]],["text/api_reference/",[6,1.501,41,5.064,51,1.703,52,1.785,56,5.585,57,5.585,58,5.585,59,5.585,60,5.914,61,5.585,62,5.585,63,5.585,102,4.989,103,5.585,104,4.016,105,5.585,106,1.504,107,3.906,108,5.585,109,5.585,110,4.273,111,5.585,112,4.07,113,5.585,114,2.232,115,5.585,116,5.585,117,5.585]],["title/api_reference/augmentations/",[55,4.372]],["text/api_reference/augmentations/",[51,1.963,52,2.057,60,5.64,106,1.393,109,6.438,110,4.548,111,6.438,112,4.438,113,6.438,114,2.574,115,6.438]],["title/api_reference/augmentations/bbox_utils/",[51,0.712,52,0.747,60,1.73,110,1.31,112,1.361,118,2.336]],["text/api_reference/augmentations/bbox_utils/",[1,1.436,5,0.436,9,0.908,51,2.392,52,2.574,60,0.652,93,1.606,97,0.545,106,0.406,110,0.493,112,0.513,118,0.88,119,0.95,120,2.6,121,3.032,122,3.23,123,1.436,124,3.155,125,1.181,126,0.598,127,0.631,128,0.897,129,0.932,130,0.753,131,2.503,132,3.117,133,3.117,134,3.079,135,3.079,136,0.886,137,1.683,138,2.396,139,2.396,140,1.8,141,1.608,142,2.44,143,1.436,144,1.196,145,1.311,146,1.11,147,1.972,148,1.608,149,0.919,150,0.95,151,3.986,152,3.698,153,3.108,154,1.538,155,2.981,156,1.598,157,1.44,158,0.937,159,2.55,160,2.678,161,2.964,162,1.475,163,1.896,164,1.019,165,2.273,166,2.912,167,2.45,168,2.45,169,1.436,170,1.318,171,1.436,172,1.436,173,1.537,174,1.537,175,1.229,176,1.068,177,1.156,178,1.608,179,1.7,180,2.365,181,1.664,182,0.95,183,3.193,184,2.572,185,1.949,186,0.721,187,0.652,188,0.652,189,0.672,190,0.652,191,0.827,192,0.95,193,0.95,194,0.95,195,0.306,196,0.695,197,0.661,198,0.95,199,0.452,200,0.95,201,1.759,202,4.247,203,0.95,204,1.608,205,3.203,206,0.695,207,0.827,208,0.751,209,0.88,210,0.95,211,1.513,212,1.125,213,0.95,214,2.741,215,4.239,216,1.755,217,1.436,218,0.751,219,0.95,220,1.972,221,0.937,222,1.983,223,0.751,224,2.656,225,0.825,226,0.825,227,0.751,228,0.467,229,0.944,230,0.751,231,0.827,232,0.95,233,1.735,234,1.735,235,1.436,236,1.318,237,0.585,238,0.695,239,1.271,240,1.095,241,1.271,242,0.997,243,1.608,244,0.615,245,0.95,246,1.512,247,0.95,248,1.735,249,0.652,250,0.444,251,0.95,252,1.512,253,0.95,254,0.95]],["title/api_reference/augmentations/bbox_utils/#helper-functions-for-working-with-bounding-boxes-augmentationsbbox_utils",[51,0.712,52,0.747,60,1.73,110,1.31,112,1.361,118,2.336]],["text/api_reference/augmentations/bbox_utils/#helper-functions-for-working-with-bounding-boxes-augmentationsbbox_utils",[]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils",[113,5.331]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils",[]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area",[119,5.755]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area",[5,0.441,51,2.335,52,2.448,93,1.057,120,2.115,121,2.676,122,2.851,123,5.044,124,4.919,125,2.601,126,0.678,127,0.715,128,0.926,129,0.963,130,0.793,131,2.636,132,2.676,133,2.676,134,2.718,135,2.718,136,0.907,137,2.082,138,2.115,139,2.115,140,1.963]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox",[141,5.331]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox",[120,2.524,142,5.15,143,6.02,144,2.524,145,2.767,146,2.342,147,4.846,148,6.739,149,3.851]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes",[141,5.331]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes",[120,2.524,142,5.15,143,6.02,144,2.524,145,2.767,146,2.342,147,4.846,148,6.739,149,3.851]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations",[150,5.755]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations",[1,2.015,5,0.346,9,1.115,51,2.374,52,2.583,93,1.458,120,1.468,121,1.857,122,1.978,126,0.471,127,0.496,128,0.841,129,0.874,130,0.55,131,2.575,132,3.026,133,3.026,134,2.655,135,2.655,136,0.866,137,1.5,138,2.392,139,2.392,140,1.362,142,2.994,151,6.006,152,3.685,153,3.097,154,2.197,155,3.647,156,2.283,157,2.542,158,2.283,159,4.142,160,4.35,161,4.466,162,2.603,163,3.345,164,2.484,165,4.048,166,4.729,167,4.928,168,4.928,169,3.5,170,3.213,171,3.5,172,3.5,173,1.886,174,1.886,175,2.994,176,2.603,177,2.818,178,3.918,179,2.429,180,2.902,181,2.378]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations",[182,5.755]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations",[1,1.252,5,0.372,9,0.975,51,2.339,52,2.576,93,1.436,120,1.284,121,1.624,122,1.73,126,0.411,127,0.434,128,0.78,129,0.811,130,0.481,131,2.765,132,3.089,133,3.089,134,2.851,135,2.851,136,0.772,137,1.362,138,2.441,139,2.441,140,1.191,142,2.619,144,1.284,145,1.407,146,1.742,151,3.223,152,3.223,153,2.709,154,1.921,155,3.601,156,1.997,157,2.223,159,3.843,160,4.036,161,4.559,162,2.277,163,2.926,164,2.172,165,3.755,166,4.827,167,4.476,168,4.476,169,3.061,170,2.81,171,3.061,172,3.061,173,2.412,174,2.412,175,2.619,176,2.277,177,2.464,178,3.426,179,2.125,180,3.711,181,2.08,183,5.011,184,3.041,185,2.304,186,2.81,187,2.538,188,2.538,189,2.619,190,2.538,191,3.223,192,3.698,193,3.698,194,3.698,195,1.191,196,2.709,197,1.021,198,3.698,199,1.759]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations",[200,5.755]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations",[1,2.363,5,0.406,9,1.41,51,2.329,52,2.597,93,1.211,120,1.856,121,2.348,122,2.502,126,0.595,127,0.628,128,0.852,129,0.886,130,0.696,132,2.348,133,2.348,134,2.385,135,2.385,136,0.939,137,1.759,138,1.856,139,1.856,140,1.722,142,3.787,151,6.086,152,4.661,153,3.917,154,2.778,155,3.468,156,2.887,157,3.214,158,2.887,159,3.214,160,3.376,161,3.466,162,3.292,163,4.231,201,2.665,202,5.306]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations",[203,5.755]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations",[1,2.445,9,1.905,51,2.041,52,2.139,154,3.754,155,3.75,156,3.901,183,6.694,201,2.476]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox",[204,5.331]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox",[5,0.478,51,2.186,52,2.291,93,1.342,120,1.838,121,3.047,122,3.246,126,0.589,127,0.622,128,0.945,129,0.982,130,0.689,131,3.001,132,3.047,133,3.047,134,3.094,135,3.094,136,0.85,137,1.748,138,2.408,139,2.408,140,1.706,173,2.362,174,2.362,179,3.043,180,3.634,181,2.978,184,2.978,185,3.297,205,5.743,206,3.879,207,4.616,208,4.19,209,4.907,210,5.296,211,3.343,212,3.432]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes",[204,5.331]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes",[5,0.435,51,2.312,52,2.423,93,1.298,120,2.069,121,2.618,122,2.789,126,0.663,127,0.7,128,0.914,129,0.95,130,0.776,132,3.287,133,3.287,134,3.338,135,3.338,136,0.898,137,1.886,138,2.069,139,2.069,140,1.92,184,3.352,201,2.043,202,5.688,205,6.196]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes",[213,5.755]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes",[1,1.619,5,0.428,51,2.401,52,2.618,93,1.125,120,1.661,121,2.101,122,2.239,124,5.342,125,2.222,126,0.532,127,0.562,128,0.792,129,0.823,130,0.957,132,2.101,133,2.101,134,2.134,135,2.134,136,0.808,137,1.633,138,1.661,139,1.661,140,1.541,147,4.321,197,1.321,201,2.521,202,4.927,211,3.021,214,4.592,215,5.776,216,4.75,217,5.367,218,3.785,219,4.785,220,4.321,221,2.583,222,5.367,223,3.785,224,3.284,225,2.276,226,2.276,227,3.785,228,2.355,229,1.443,230,3.785,231,4.17]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility",[232,5.755]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility",[5,0.374,51,2.318,52,2.506,93,1.423,106,1.238,120,1.639,124,4.166,125,1.619,126,0.526,127,0.554,128,0.785,129,0.815,130,0.614,131,2.78,132,3.209,133,3.209,134,3.258,135,3.258,136,0.861,138,2.231,139,2.231,140,2.07,144,1.639,197,1.304,202,5.552,214,4.552,215,5.352,220,4.283,221,2.55,222,3.909,224,5.382,229,1.43,233,4.723,234,4.723,235,3.909,236,4.884,237,2.907,238,3.459,239,4.708,240,4.058,241,4.708,242,2.713]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox",[243,5.331]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox",[5,0.482,51,2.213,52,2.319,93,1.223,120,1.884,121,3.096,122,3.299,126,0.604,127,0.637,128,0.956,129,0.993,130,0.706,131,3.049,132,3.096,133,3.096,134,3.144,135,3.144,136,0.86,137,1.776,138,2.447,139,2.447,140,1.748,173,2.42,174,2.42,179,3.118,180,3.725,181,3.052,184,3.965,185,3.337,205,4.492,211,3.426,212,3.518,244,3.518]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes",[243,5.331]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes",[5,0.435,51,2.312,52,2.423,93,1.298,120,2.069,121,2.618,122,2.789,126,0.663,127,0.7,128,0.914,129,0.95,130,0.776,132,3.287,133,3.287,134,3.338,135,3.338,136,0.898,137,1.886,138,2.069,139,2.069,140,1.92,184,4.21,201,2.043,202,5.688,205,4.934]],["title/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes",[245,5.755]],["text/api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes",[5,0.402,9,1.389,51,2.316,52,2.427,93,1.2,97,3.028,120,2.401,123,4.362,126,0.586,127,0.619,128,0.844,129,0.877,130,0.686,131,2.279,132,3.037,133,3.037,134,3.084,135,3.084,136,0.848,138,2.401,139,2.401,140,1.697,144,1.829,145,2.631,146,1.697,155,2.35,201,1.806,202,4.005,215,3.86,225,2.507,226,2.507,229,1.718,242,3.028,246,4.593,247,5.271,248,6.917,249,3.617,250,2.466,251,5.271,252,6.028,253,5.271,254,5.271]],["title/api_reference/augmentations/functional/",[106,0.645,110,1.976,255,3.524]],["text/api_reference/augmentations/functional/",[2,1.338,5,0.458,6,0.701,7,0.82,9,0.742,11,0.318,20,1.338,24,0.634,26,0.791,27,0.565,28,0.275,30,0.387,35,0.291,42,0.67,44,0.297,50,0.561,51,1.593,52,1.731,69,0.363,93,1.636,94,0.736,106,0.17,110,0.275,114,2.739,120,1.642,121,3.045,122,3.244,125,0.861,126,0.699,127,0.738,128,0.958,129,0.996,130,0.818,131,2.951,132,2.207,133,2.207,134,2.241,135,2.241,136,0.951,137,1.977,138,1.642,139,1.586,140,2.024,144,0.349,145,1.604,146,1.619,153,0.387,154,0.275,157,0.318,158,0.285,162,0.326,173,2.515,174,2.562,176,0.619,177,0.67,179,1.05,180,1.254,181,1.582,185,0.612,186,0.763,187,0.689,188,0.689,189,0.711,190,0.689,195,0.462,196,0.387,197,1.052,201,0.492,206,1.84,209,0.931,224,0.985,225,0.478,226,2.683,229,0.745,238,0.736,241,0.736,249,0.363,250,0.247,255,0.49,256,0.529,257,3.723,258,1.005,259,0.876,260,1.005,261,0.843,262,0.876,263,1.416,264,1.345,265,3.684,266,2.138,267,1.547,268,0.529,269,1.005,270,0.876,271,0.876,272,0.876,273,0.876,274,0.876,275,1.005,276,0.876,277,0.461,278,0.461,279,0.461,280,0.352,281,0.461,282,0.529,283,1.005,284,0.461,285,0.529,286,1.005,287,0.876,288,0.461,289,0.374,290,0.529,291,0.461,292,1.41,293,0.363,294,0.343,295,0.529,296,1.005,297,1.005,298,0.876,299,0.876,300,0.832,301,0.461,302,0.461,303,0.529,304,0.529,305,2.559,306,2.062,307,1.674,308,1.443,309,0.634,310,0.711,311,0.529,312,1.098,313,2.475,314,0.529,315,1.413,316,1.968,317,0.763,318,1.217,319,1.693,320,1.254,321,1.693,322,0.542,323,0.791,324,0.529,325,3.564,326,0.529,327,0.402,328,0.326,329,0.795,330,0.529,331,0.529,332,0.529,333,0.529,334,1.693,335,2.452,336,2.559,337,0.763,338,0.931,339,0.931,340,0.931,341,0.931,342,0.529,343,2.876,344,0.529,345,0.529,346,0.876,347,0.931,348,0.986,349,1.338,350,1.125,351,2.108,352,1.827,353,0.49,354,0.832,355,0.832,356,0.832,357,0.763,358,0.689,359,0.832,360,0.832,361,0.832,362,0.832,363,0.832,364,0.711,365,0.832,366,1.091,367,0.338,368,0.763,369,1.66,370,0.832,371,0.736,372,0.832,373,0.736,374,0.832,375,0.529,376,0.461,377,1.251,378,0.876,379,1.016,380,0.438,381,0.843,382,0.461,383,0.418,384,0.402,385,0.438,386,0.461,387,1.49,388,1.125,389,0.387,390,0.719,391,0.374,392,0.374,393,0.461,394,0.363,395,0.461,396,0.529,397,0.461,398,0.461,399,0.418,400,0.461,401,0.67,402,0.529,403,0.529,404,0.374,405,0.374,406,0.461,407,0.461,408,0.461,409,0.461,410,0.418,411,0.529,412,0.529,413,0.529,414,0.49,415,0.49,416,0.588,417,0.588,418,0.529,419,0.374,420,1.693,421,0.529,422,0.529,423,0.876,424,0.763,425,0.876,426,0.529,427,1.6,428,0.402,429,0.461,430,0.461,431,0.281,432,0.529,433,0.153,434,0.343,435,0.311,436,0.529,437,0.529,438,0.461,439,0.832,440,0.529,441,1.33,442,1.33,443,0.529,444,0.529,445,0.529,446,0.275,447,0.529,448,0.832,449,0.529,450,0.529,451,0.529,452,1.436,453,1.436,454,0.529,455,0.529,456,0.529,457,0.588,458,0.588,459,0.588,460,1.005,461,1.005,462,0.529,463,0.529,464,0.529,465,0.529,466,0.529,467,0.529,468,0.529,469,0.529,470,0.832,471,1.592,472,0.876,473,0.67,474,0.418,475,0.438,476,0.529,477,0.832,478,0.529,479,0.529,480,0.529,481,0.529,482,0.438,483,0.529,484,0.334,485,0.334,486,1.136,487,0.876,488,0.795,489,0.529,490,0.529,491,1.436,492,0.438,493,1.251,494,0.529,495,0.529,496,0.529,497,0.529,498,0.529,499,0.529]],["title/api_reference/augmentations/functional/#functional-transforms-augmentationsfunctional",[106,0.645,110,1.976,255,3.524]],["text/api_reference/augmentations/functional/#functional-transforms-augmentationsfunctional",[]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional",[111,5.331]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional",[]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog",[256,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog",[5,0.486,6,1.553,7,2.34,126,0.694,127,0.732,128,0.94,129,0.976,130,0.811,136,0.957,140,2.008,201,2.137,229,1.713,257,4.04,258,6.235,259,5.433,260,6.235,261,3.662,262,6.709,263,4.04,264,3.838,265,5.129,266,5.849,267,4.414]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain",[268,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain",[5,0.435,6,1.485,7,2.238,126,0.663,127,0.7,128,0.914,129,0.95,130,0.776,136,1.017,137,1.886,140,1.92,229,1.326,257,3.864,263,3.864,264,3.67,265,4.988,269,5.962,270,5.196,271,5.196,272,5.196,273,5.196,274,5.196,275,5.962,276,6.525,277,5.196,278,5.196,279,5.196,280,3.972,281,5.196]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow",[282,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow",[5,0.389,6,1.667,7,2.512,126,0.745,127,0.786,128,0.981,129,1.02,130,0.871,136,0.882,140,2.156,201,2.294,257,4.338,261,3.931,263,4.338,264,4.121,265,5.356,283,6.694,284,5.833]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow",[285,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow",[5,0.451,6,1.571,7,2.367,30,4.619,125,2.161,126,0.702,127,0.74,128,0.946,129,0.983,130,0.82,136,0.921,140,2.031,257,4.087,263,4.087,264,3.882,265,5.166,266,4.792,286,6.307,287,5.496,288,5.496,289,4.466,290,6.307,291,5.496,292,3.159,293,4.327,294,4.087]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare",[295,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare",[6,1.544,7,2.327,126,0.69,127,0.728,128,0.936,129,0.973,130,0.806,136,1,137,2.098,140,1.996,201,2.124,229,1.707,257,4.017,261,3.641,263,4.017,264,3.816,265,5.111,296,6.199,297,6.199,298,5.402,299,5.402,300,5.13,301,5.402,302,5.402]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop",[303,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop",[5,0.421,51,2.256,52,2.364,93,1.255,120,1.962,121,3.178,122,3.386,126,0.629,127,0.663,128,0.883,129,0.918,130,0.735,131,3.13,132,3.506,133,3.506,134,3.561,135,3.561,136,0.994,137,2.242,140,1.821,226,3.443]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip",[304,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip",[5,0.413,51,2.223,52,2.33,93,1.365,120,1.903,121,3.116,122,3.32,126,0.61,127,0.643,128,0.96,129,0.998,130,0.713,131,3.069,132,3.116,133,3.116,134,3.165,135,3.165,136,0.914,137,1.982,140,1.766,145,2.086,146,2.286,179,3.15,180,3.762,197,1.959,305,6.513,306,3.15,307,3.653,308,3.15,309,3.461,310,3.882]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip",[311,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip",[5,0.434,51,2.306,52,2.417,93,1.294,120,2.058,121,3.276,122,3.49,126,0.66,127,0.696,128,0.911,129,0.946,130,0.771,131,3.227,132,3.276,133,3.276,134,3.327,135,3.327,136,0.896,137,1.879,140,1.91,174,2.644,306,3.406,308,3.406,312,3.564,313,3.65]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90",[314,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90",[5,0.414,51,2.229,52,2.336,120,1.912,121,3.126,122,3.331,126,0.613,127,0.647,128,0.869,129,0.903,130,0.717,131,3.606,132,3.126,133,3.126,134,3.175,135,3.175,136,0.915,137,1.987,140,1.775,145,2.096,146,1.775,225,2.621,292,2.76,315,3.098,316,4.182,317,4.187,318,3.671,319,6.597,320,4.886,321,6.597,322,2.975,323,3.035]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate",[324,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate",[5,0.429,51,2.289,52,2.399,93,1.281,120,2.025,121,3.243,122,3.455,126,0.649,127,0.685,128,0.901,129,0.937,130,0.759,131,2.523,132,3.243,133,3.243,134,3.293,135,3.293,136,0.935,137,2.041,140,1.879,316,4.338,318,4.921,325,4.655]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose",[326,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose",[5,0.41,51,2.213,52,2.319,93,1.223,120,1.884,121,3.096,122,3.299,126,0.604,127,0.637,128,0.956,129,0.993,130,0.706,131,3.387,132,3.096,133,3.096,134,3.144,135,3.144,136,0.91,137,1.973,140,1.748,145,2.682,146,2.271,179,3.118,180,3.725,181,3.052,313,5.29,327,4.124,328,3.341,329,4.294,330,5.428,331,5.428]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip",[332,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip",[5,0.434,51,2.306,52,2.417,93,1.294,120,2.058,121,3.276,122,3.49,126,0.66,127,0.696,128,0.911,129,0.946,130,0.771,131,3.227,132,3.276,133,3.276,134,3.327,135,3.327,136,0.896,137,1.879,140,1.91,173,2.644,306,3.406,307,3.951,312,3.564,313,3.65]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords",[333,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords",[5,0.398,9,1.37,51,1.936,52,2.27,93,1.33,120,1.803,121,3.009,122,3.205,125,1.78,126,0.578,127,0.61,128,0.836,129,0.869,130,0.676,131,3.316,132,3.009,133,3.009,134,3.055,135,3.055,136,0.974,137,2.053,138,1.803,139,1.803,140,1.673,185,2.919,186,3.947,187,3.565,188,3.565,189,3.679,190,3.565,226,4.03,334,4.813,335,4.528,336,4.3,337,3.947,338,4.813,339,4.813,340,4.813,341,4.813]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords",[342,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords",[5,0.397,9,1.363,52,1.531,93,1.327,114,3.013,121,2.27,122,2.419,125,1.772,126,0.575,127,0.607,128,0.834,129,0.866,130,0.673,131,2.954,136,0.973,137,2.049,138,2.824,139,2.655,140,1.665,173,3.046,174,3.046,185,2.203,186,3.929,187,3.548,188,3.548,189,3.661,190,3.548,226,4.133,325,3.924,334,4.79,336,4.279,337,3.929,338,4.79,339,4.79,340,4.79,341,4.79,343,3.484,344,5.171]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform",[345,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform",[2,5.739,5,0.373,24,4.051,26,3.535,27,3.609,93,1.113,354,5.311,355,5.311,356,5.311,357,4.876,358,4.404,359,5.311,360,5.311,361,5.311,362,5.311,363,5.311,364,4.544,365,5.311,366,4.876,367,1.51,368,4.876,369,5.954,370,5.311,371,4.7,372,5.311,373,4.7,374,5.311]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx",[375,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx",[2,5.719,5,0.371,24,4.027,26,3.514,27,3.588,93,1.107,354,5.28,355,5.28,356,5.28,357,4.848,358,4.378,359,5.28,360,5.28,361,5.28,362,5.28,363,5.28,364,4.518,365,5.28,366,4.848,367,1.502,368,4.848,369,5.932,370,5.28,371,4.673,372,5.28,373,4.673,374,5.28,376,5.56]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize",[181,3.236]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize",[5,0.479,9,2.05,44,3.007,50,2.386,94,3.917,125,1.833,126,0.595,127,0.628,128,0.852,129,0.886,130,0.696,136,0.587,140,1.722,146,1.722,154,2.778,157,3.214,162,3.292,174,2.385,181,4.809,257,3.466,265,5.181,323,2.946,329,4.231,351,3.141,369,4.063,377,6.086,378,4.661,379,4.945,380,4.426,381,3.141,382,4.661,383,4.231,384,4.063,385,4.426,386,4.661,387,4.365,388,3.292,389,3.917,390,2.679,391,3.787,392,3.787,393,4.661,394,3.67]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca",[395,5.015]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca",[5,0.337,6,1.445,9,1.53,11,3.488,26,3.197,28,3.015,35,3.197,126,0.646,127,0.681,128,0.898,129,0.934,130,0.755,136,0.637,137,1.462,140,1.869,145,2.208,146,1.869,176,3.573,229,1.291,241,4.25,249,3.982,257,3.761,267,4.109,366,4.409,381,3.409,388,4.531,396,5.804,397,5.058,398,5.058,399,4.591,400,5.058,401,4.904,402,5.804,403,5.804,404,4.109,405,4.109,406,5.058,407,5.058,408,5.058,409,5.058,410,4.591,411,5.804,412,5.804]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.grid_distortion",[413,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.grid_distortion",[42,4.979,418,7.473,419,5.291,420,6.923,421,7.473]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise",[422,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise",[5,0.508,93,0.991,126,0.636,127,0.67,128,0.889,129,0.924,130,0.743,136,0.627,140,1.84,177,3.806,195,2.347,197,2.011,229,1.621,265,4.855,315,3.212,351,3.355,352,5.712,367,1.344,381,3.355,423,4.978,424,4.34,425,4.978,426,5.712,427,6.394,428,4.34,429,4.978,430,4.978,431,1.595,432,5.712,433,1.652,434,3.702,435,3.355,436,5.712,437,5.712,438,4.978,439,4.727]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop",[440,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop",[5,0.411,20,5.181,93,1.227,114,3.076,121,2.395,122,2.552,126,0.607,127,0.64,128,0.863,129,0.897,130,0.71,131,3.059,136,0.985,137,2.221,138,2.725,139,2.725,140,1.757,173,3.154,174,3.154,196,3.995,226,4.093,325,4.064,335,4.754,336,4.515,343,3.608,441,5.054,442,5.054]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip",[443,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip",[5,0.393,93,1.501,114,2.997,121,2.239,122,2.385,126,0.567,127,0.598,128,0.927,129,0.963,130,0.663,131,2.926,136,0.888,137,1.913,138,1.769,139,1.769,140,1.642,145,2.889,146,2.788,173,3.018,174,3.018,179,2.929,180,3.498,197,1.868,292,2.554,305,6.286,306,4.837,307,5.061,308,4.363,309,3.218,310,3.61,325,3.887,343,3.451]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip",[444,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip",[5,0.438,93,1.307,114,3.192,121,2.647,122,2.82,126,0.671,127,0.707,128,0.92,129,0.956,130,0.784,131,3.26,136,0.903,137,1.899,138,2.092,139,2.092,140,1.941,173,3.362,174,3.668,306,3.463,308,3.463,312,3.623,313,3.711,325,4.331,343,3.845]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop",[445,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop",[5,0.413,20,5.198,93,1.231,114,3.082,121,2.407,122,2.565,126,0.61,127,0.643,128,0.866,129,0.9,130,0.713,131,2.371,136,0.987,137,2.224,138,2.731,139,2.731,140,1.766,173,3.165,174,3.165,226,4.1,325,4.077,335,4.778,336,4.537,343,3.619,441,5.079,442,5.079,446,2.848]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90",[447,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90",[5,0.409,93,1.219,114,3.065,121,2.372,122,2.527,126,0.601,127,0.634,128,0.954,129,0.991,130,0.703,131,3.04,136,0.908,137,1.968,138,1.875,139,1.875,140,1.739,144,1.875,145,2.055,146,1.739,173,3.134,174,3.134,179,3.103,180,3.706,225,2.569,292,2.705,315,3.952,316,4.128,317,4.104,318,3.599,319,6.512,320,4.823,321,6.512,322,2.916,323,2.975,325,4.038,343,3.585,449,5.401]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate",[450,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate",[5,0.435,93,1.298,114,3.179,121,2.618,122,2.789,126,0.663,127,0.7,128,0.914,129,0.95,130,0.776,131,3.238,136,0.942,137,1.886,138,2.069,139,2.069,140,1.92,173,3.338,174,3.338,229,1.326,316,4.397,325,5.08,343,3.818]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale",[451,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale",[93,1.303,114,3.186,126,0.667,127,0.704,128,0.917,129,0.953,130,0.78,131,2.592,136,0.901,137,1.892,140,1.931,173,3.659,174,3.659,266,5.708,313,4.625,325,4.316,343,4.518,452,7.513,453,7.513]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose",[454,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose",[93,1.369,114,3.276,126,0.723,127,0.762,128,0.963,129,1.001,130,0.845,131,3.413,136,0.713,140,2.091,173,3.52,174,3.52,316,3.814,325,4.885,343,4.025]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip",[455,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip",[5,0.438,93,1.307,114,3.192,121,2.647,122,2.82,126,0.671,127,0.707,128,0.92,129,0.956,130,0.784,131,3.26,136,0.903,137,1.899,138,2.092,139,2.092,140,1.941,173,3.668,174,3.362,306,3.463,307,4.016,312,3.623,313,3.711,325,4.331,343,3.845]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply",[206,4.214]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply",[5,0.467,126,0.745,127,0.786,128,0.981,129,1.02,130,0.871,136,0.882,140,2.156,206,6.545,257,4.338,265,5.74,266,6.107]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion",[456,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion",[6,1.617,9,1.712,42,4.327,69,4.456,93,1.572,106,1.101,390,3.953,420,7.878,460,7.893,461,7.893,462,6.495,463,6.495,464,6.495,465,6.495,466,6.495,467,6.495,468,6.495,469,6.495]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize",[470,4.762]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize",[5,0.449,126,0.698,127,0.736,128,0.943,129,0.98,130,0.816,136,0.848,137,1.579,140,2.019,144,2.176,145,2.385,250,2.933,257,4.064,265,5.147,292,3.869,387,4.09,470,5.189,471,7.297,472,6.733,473,5.147,474,4.96,475,5.189]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_channel_dim",[476,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_channel_dim",[387,3.984,477,6.227,478,7.525,479,7.525]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_shape",[480,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_shape",[5,0.441,241,5.549,477,6.271]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.py3round",[481,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.py3round",[482,6.227,483,7.525,484,4.75,485,4.75]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize",[486,4.552]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize",[5,0.456,125,2.685,126,0.714,127,0.753,128,0.956,129,0.994,130,0.835,136,0.704,137,1.616,140,2.067,197,1.771,224,5.377,238,5.739,257,4.159,265,5.221,439,5.311,486,6.199,487,5.593,488,6.199,489,6.418]],["title/api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image",[490,5.755]],["text/api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image",[5,0.511,126,0.71,127,0.749,128,0.953,129,0.99,130,0.83,131,2.759,136,0.857,140,2.055,158,3.445,388,3.928,431,1.782,491,7.809,492,5.28,493,7.353,494,6.381,495,6.381,496,6.381,497,6.381,498,6.381,499,6.381]],["title/api_reference/augmentations/keypoints_utils/",[60,1.95,110,1.476,112,1.534,114,1.052,500,2.632]],["text/api_reference/augmentations/keypoints_utils/",[5,0.449,60,4.303,93,1.622,110,3.257,112,3.385,114,3.237,121,3.392,122,3.614,142,5.47,143,5.189,185,2.671,211,4.876,241,5.658,500,5.809,501,7.157,502,6.971]],["title/api_reference/augmentations/keypoints_utils/#helper-functions-for-working-with-keypoints-augmentationskeypoints_utils",[60,1.95,110,1.476,112,1.534,114,1.052,500,2.632]],["text/api_reference/augmentations/keypoints_utils/#helper-functions-for-working-with-keypoints-augmentationskeypoints_utils",[]],["title/api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils",[115,5.331]],["text/api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils",[]],["title/api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoint",[501,5.331]],["text/api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoint",[5,0.432,114,2.749,142,5.255,185,3.162,211,4.685,241,5.436]],["title/api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoints",[501,5.331]],["text/api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoints",[5,0.432,114,2.749,142,5.255,143,6.143,211,4.685,241,5.436]],["title/api_reference/augmentations/transforms/",[106,0.776,503,4.243]],["text/api_reference/augmentations/transforms/",[2,0.367,3,0.437,4,0.224,5,0.496,6,0.388,7,0.437,9,1.23,11,0.301,20,0.367,24,0.162,26,0.404,27,0.282,28,0.133,31,0.162,32,0.171,35,0.276,38,0.141,39,0.126,42,0.636,44,1.175,45,0.317,50,1.765,51,0.44,87,0.176,92,0.415,93,1.326,94,0.699,97,0.148,98,1.503,106,1.014,110,0.906,112,0.139,114,1.362,120,1.348,121,0.113,124,0.166,125,1.296,126,0.713,127,0.748,128,0.962,129,0.808,130,1.077,131,0.317,132,0.322,133,0.322,134,0.327,135,0.327,136,0.942,137,1.988,138,1.313,139,1.239,144,2.334,145,1.958,146,1.595,147,1.039,149,1.948,153,1.142,154,0.26,156,1.674,157,0.441,158,0.629,162,0.588,164,0.151,166,0.344,173,0.52,174,0.609,175,0.182,176,0.451,177,0.636,181,1.175,184,0.144,185,0.664,187,0.344,189,0.355,195,1.452,197,1.779,199,0.122,201,1.572,206,1.277,207,0.224,208,0.203,211,0.162,212,1.13,215,0.188,218,0.58,221,0.27,224,1.07,225,0.829,226,1.982,228,2.095,229,1.845,230,0.203,236,0.725,238,0.188,239,0.367,240,0.316,242,1.002,244,0.475,246,0.224,249,0.176,250,0.446,252,0.224,257,0.325,259,0.224,261,0.151,262,0.832,263,0.755,264,0.717,266,0.381,267,0.519,270,0.224,271,0.224,272,0.224,273,0.224,274,0.224,276,0.437,277,0.224,278,0.224,279,0.224,280,0.171,281,0.224,284,1.016,287,0.224,288,0.224,289,1.104,291,0.832,292,1.843,294,0.619,298,0.224,299,0.224,300,0.607,301,0.224,302,1.016,305,0.415,306,1.002,307,1.039,308,0.896,309,0.463,312,0.301,313,0.308,315,1.175,316,0.916,317,0.725,318,0.636,320,0.344,322,0.396,323,1.24,325,0.548,327,0.381,329,0.396,343,0.795,346,0.437,347,0.679,348,2.25,349,2.361,350,0.308,351,2.097,353,0.238,354,0.213,355,0.213,356,0.213,357,0.195,358,0.176,359,0.213,360,0.213,361,0.213,362,0.213,363,0.213,364,0.182,365,0.213,366,0.557,367,1.456,368,0.195,369,0.557,370,0.213,371,0.367,372,0.213,373,0.188,374,0.213,377,0.224,378,0.224,379,0.825,380,0.607,381,0.684,382,0.437,383,0.203,384,0.381,385,0.607,386,0.224,387,1.948,388,0.588,389,0.188,390,1.733,391,0.182,392,0.182,393,0.224,394,0.176,395,0.224,397,0.224,398,0.224,399,0.396,400,0.224,401,0.489,404,1.359,405,0.355,406,0.224,407,0.224,408,0.224,409,0.224,410,0.203,414,0.238,423,0.224,424,0.557,425,0.224,427,1.001,428,0.725,429,0.224,430,0.224,431,1.52,433,1.79,435,0.151,438,0.224,446,1.403,448,0.607,470,0.213,471,0.437,472,0.224,473,0.776,474,0.203,475,0.607,486,0.396,487,0.224,488,0.58,492,0.415,493,0.224,503,0.238,504,1.519,505,1.379,506,0.79,507,1.142,508,0.79,509,1.54,510,1.56,511,1.578,512,1.917,513,0.224,514,0.257,515,0.736,516,0.257,517,0.203,518,0.224,519,0.257,520,0.257,521,0.257,522,1.532,523,1.277,524,0.257,525,0.213,526,0.79,527,0.464,528,0.257,529,0.257,530,0.257,531,0.257,532,1.162,533,2.566,534,0.257,535,0.733,536,1.277,537,1.863,538,0.257,539,2.534,540,0.639,541,0.464,542,1.53,543,0.501,544,0.501,545,1.519,546,0.501,547,0.501,548,0.884,549,0.464,550,0.464,551,0.464,552,0.464,553,0.464,554,0.464,555,1.594,556,0.257,557,0.257,558,0.257,559,0.257,560,1.081,561,0.464,562,0.679,563,0.464,564,0.257,565,0.257,566,0.182,567,0.257,568,0.257,569,0.257,570,0.257,571,0.257,572,0.257,573,0.464,574,0.639,575,0.922,576,0.257,577,0.257,578,0.257,579,0.257,580,0.171,581,1.459,582,0.257,583,1.001,584,2.872,585,1.255,586,1.39,587,2.322,588,1.392,589,1.392,590,1.392,591,0.922,592,2.355,593,0.922,594,0.922,595,0.922,596,1.652,597,1.942,598,1.038,599,0.639,600,0.464,601,0.257,602,0.257,603,0.257,604,0.224,605,0.257,606,0.224,607,0.257,608,0.257,609,0.213,610,1.266,611,0.415,612,0.396,613,0.257,614,0.464,615,0.257,616,0.655,617,0.367,618,0.257,619,0.257,620,0.257,621,0.257,622,0.257,623,0.257,624,0.257,625,0.257,626,0.464,627,0.954,628,0.733,629,0.396,630,0.257,631,0.257,632,0.257,633,0.166,634,1.266,635,0.257,636,0.7,637,0.884,638,0.464,639,0.464,640,0.655,641,0.257,642,0.885,643,0.195,644,0.501,645,0.437,646,0.257,647,0.257,648,0.257,649,0.257,650,0.464,651,0.257,652,0.733,653,0.464,654,0.257,655,0.257,656,0.96,657,0.257,658,0.257,659,0.195,660,0.213,661,0.257,662,0.58,663,0.224,664,0.257,665,0.257,666,0.257,667,0.257,668,0.257,669,0.257,670,0.257,671,0.257,672,0.464,673,1.131,674,1.615,675,0.437,676,0.464,677,0.464,678,0.257,679,1.277,680,0.257,681,0.26,682,1.165,683,0.257,684,1.92,685,0.501,686,0.679,687,0.733,688,0.733,689,0.501,690,0.257,691,0.257,692,0.257,693,0.257,694,0.257,695,0.224,696,0.501,697,0.639,698,0.501,699,0.501,700,0.257,701,0.257,702,0.501,703,0.257,704,0.257,705,0.257,706,0.257,707,0.679,708,0.257,709,0.257,710,0.171,711,0.257,712,0.884,713,0.501,714,0.954,715,2.136,716,0.954,717,0.415,718,0.954,719,0.257,720,1.266,721,0.733,722,0.464,723,0.464,724,1.142,725,0.464,726,0.257,727,0.464,728,0.501,729,0.257,730,0.257,731,0.257,732,0.464,733,0.257,734,0.257,735,0.257,736,0.257,737,0.257,738,0.182,739,0.224,740,0.257,741,0.257,742,0.213,743,0.224,744,0.154,745,0.519,746,0.257,747,0.171,748,0.257,749,0.257,750,0.922,751,0.884,752,0.381,753,0.964,754,0.257,755,0.257,756,0.257,757,0.257,758,0.257,759,0.257,760,0.257,761,0.257,762,0.501,763,0.501,764,0.176,765,0.257,766,0.224,767,0.954,768,0.257,769,0.257,770,0.257,771,0.257,772,0.257,773,0.501,774,0.501,775,0.257,776,0.257,777,0.257,778,0.257,779,0.257,780,0.464,781,0.464,782,0.257,783,0.257,784,0.257,785,0.257,786,0.257,787,0.257,788,0.639,789,0.257,790,0.257,791,1.615,792,0.257,793,0.679,794,0.257,795,0.501,796,0.954,797,0.464,798,0.464,799,0.415,800,0.501,801,0.257,802,0.257,803,0.257,804,0.257,805,0.257,806,1.024,807,0.166,808,0.224,809,0.224,810,0.257,811,0.396,812,0.257,813,0.171,814,0.257,815,0.639,816,0.257,817,0.257,818,0.257,819,0.257,820,0.257,821,0.257,822,0.257,823,0.954,824,0.224,825,0.257,826,0.257,827,0.257,828,0.257,829,0.257,830,0.257,831,0.257,832,0.257,833,0.501,834,0.257,835,0.257,836,0.257,837,0.257,838,0.257,839,0.257,840,0.257,841,0.257,842,0.257,843,0.257,844,0.257,845,1.279,846,0.257,847,0.415,848,0.257,849,1.615,850,0.257,851,0.257,852,0.464,853,0.501,854,0.501,855,0.257,856,0.224,857,0.257,858,0.203,859,0.257,860,0.257,861,0.182,862,0.257,863,0.257,864,0.257,865,0.257,866,0.257,867,0.257,868,0.437,869,0.257,870,0.257,871,0.257,872,0.257,873,0.257,874,0.257,875,0.501,876,0.501,877,0.501,878,0.501,879,0.257,880,0.954,881,0.224,882,0.954,883,0.224,884,0.954,885,0.224,886,0.224,887,0.501,888,0.257,889,0.213,890,0.257,891,0.257,892,0.501,893,0.954,894,0.437,895,0.257,896,0.257,897,0.257,898,0.257,899,0.257,900,0.257,901,0.257,902,0.257,903,0.257,904,0.257,905,0.224,906,0.257]],["title/api_reference/augmentations/transforms/#transforms-augmentationstransforms",[106,0.776,503,4.243]],["text/api_reference/augmentations/transforms/#transforms-augmentationstransforms",[]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms",[109,5.331]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms",[]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur",[504,4.552]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur",[5,0.498,9,1.563,106,1.005,126,0.66,127,0.696,128,0.911,129,0.752,130,1.062,136,0.819,137,2.056,144,2.058,149,3.139,195,1.91,228,3.672,229,1.319,323,4.11,367,1.396,431,2.083,433,1.715,446,3.08,504,5.902,505,5.902,506,4.907,507,4.343,508,4.907,509,1.695,510,1.756,511,1.477,512,1.886]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop",[513,5.015]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop",[5,0.461,9,1.467,28,2.892,50,1.708,93,1.243,106,0.943,114,2.062,120,1.932,126,0.619,127,0.653,128,0.875,129,0.706,130,0.932,136,0.919,137,1.805,138,2.487,139,2.487,146,1.793,164,3.269,208,4.403,226,3.77,229,1.238,367,1.31,371,4.077,431,2.001,433,2.292,509,1.591,510,1.648,511,1.386,512,2.522,514,5.567,515,3.514,516,5.567,517,4.403,518,4.851,519,5.567,520,5.567]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout",[521,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout",[5,0.475,106,1.005,125,2.032,126,0.66,127,0.696,128,0.911,129,0.752,130,0.971,136,0.896,137,2.056,144,2.058,195,1.91,197,1.637,229,1.66,292,2.97,367,1.396,387,4.322,431,1.656,433,1.715,509,1.695,510,1.756,511,1.477,512,1.886,522,3.201,523,5.979,524,5.93,525,4.907,526,4.907,527,5.493,528,5.93]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle",[529,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle",[5,0.497,106,1.114,126,0.731,127,0.771,128,0.97,129,0.834,130,1.034,136,0.721,195,2.117,229,1.462,367,1.547,381,3.86,387,3.48,431,1.835,433,1.901,509,1.879,510,1.946,511,1.637,512,2.091,522,3.548,530,6.573]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE",[531,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE",[5,0.459,106,0.934,126,0.613,127,0.647,128,0.869,129,0.699,130,1.085,136,0.866,137,1.793,144,1.912,146,2.293,181,4.004,195,1.775,197,1.965,224,3.781,228,2.712,229,1.921,350,3.392,367,1.676,380,5.893,431,1.539,433,1.593,475,5.893,509,1.575,510,1.631,511,1.372,532,4.744,533,4.383,534,5.51,535,7.889,536,4.036,537,2.578,538,5.51,539,4.036]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout",[540,5.015]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout",[5,0.413,42,2.979,93,1.58,125,1.532,126,0.498,127,0.525,128,0.756,129,0.567,130,1.047,136,0.937,137,2.191,138,2.149,139,2.149,147,4.731,149,3.76,197,1.234,201,1.532,212,4.012,225,3.377,229,1.377,289,4.384,292,3.101,351,5.013,433,1.293,511,1.113,512,1.423,523,3.275,526,3.701,540,3.897,541,4.143,542,5.201,543,6.191,544,6.191,545,6.68,546,6.191,547,6.191,548,6.579,549,4.143,550,4.143,551,4.143,552,4.143,553,4.143,554,4.143]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop",[226,2.737]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop",[5,0.468,50,1.762,114,2.127,120,1.993,126,0.639,127,0.674,128,0.892,129,0.728,130,0.747,132,2.521,133,2.521,134,2.561,135,2.561,136,0.93,137,2.133,147,4.871,149,3.871,173,3.26,174,3.26,185,3.608,187,5.017,189,5.177,226,2.731,433,1.661,511,1.43,512,1.827,536,5.355,542,4.206,555,5.177]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists",[556,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists",[5,0.389,50,2.568,97,2.875,106,0.848,114,1.854,120,1.737,124,3.243,125,2.291,126,0.557,127,0.587,128,0.816,129,0.635,130,0.87,136,0.919,137,2.023,138,1.737,139,1.737,145,1.904,166,4.586,197,2.077,201,2.291,225,3.179,226,3.82,228,3.289,229,1.113,242,2.875,307,3.335,308,2.875,367,1.178,387,3.539,433,1.447,446,2.6,509,1.43,510,1.482,511,1.246,512,1.592,557,5.005,558,5.005,559,5.005,560,6.62,561,4.637,562,6.192,563,4.637,564,5.005,565,5.005,566,3.544,567,5.005]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout",[568,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout",[5,0.463,42,3.747,93,1.381,125,1.927,126,0.626,127,0.66,128,0.881,129,0.713,130,0.732,136,0.922,137,2.188,138,1.952,139,1.952,149,3.82,197,1.552,201,1.927,212,3.645,229,1.605,289,3.982,292,2.817,433,1.626,511,1.4,512,1.789,523,4.119,526,4.654,540,4.901,542,5.284,545,6.287,550,5.21,551,5.21,552,5.21,553,5.21,554,5.21,569,5.624,570,5.624,571,5.624,572,5.624]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale",[573,5.331]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale",[5,0.515,44,3.371,51,2.122,93,1.303,126,0.667,127,0.704,128,0.917,129,0.76,130,0.977,136,0.901,146,1.931,229,1.671,343,3.831,348,4.056,433,1.734,511,1.493,512,1.907,555,5.319,573,5.554,574,5.224,575,4.742,576,5.995,577,5.995,578,5.995,579,5.995,580,3.994,581,3.885]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform",[582,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform",[2,4.157,5,0.422,9,1.496,24,2.495,26,2.177,27,2.223,44,2.223,50,1.741,93,0.984,125,1.355,126,0.632,127,0.464,128,0.693,129,0.501,130,0.864,136,0.925,137,1.828,144,1.372,156,3.064,197,1.833,201,2.487,228,1.945,229,1.833,236,3.003,267,2.799,346,3.445,347,6.152,348,3.064,349,4.863,353,3.662,354,3.271,355,3.271,356,3.271,357,3.003,358,2.712,359,3.271,360,3.271,361,3.271,362,3.271,363,3.271,364,2.799,365,3.271,366,3.003,367,1.336,368,3.003,369,4.312,370,3.271,371,2.895,372,3.271,373,2.895,374,3.271,383,3.127,390,2.843,433,1.143,505,3.127,511,0.984,512,1.258,581,2.562,583,2.895,584,4.467,585,2.376,586,2.655,587,3.583,588,2.634,589,2.634,590,2.634,591,3.127,592,5.045,593,3.127,594,3.127,595,3.127,596,4.49,597,4.312,598,3.003,599,3.445,600,3.662,601,3.953,602,3.953,603,3.953,604,3.445,605,3.953,606,3.445,607,3.953,608,3.953,609,3.271]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize",[181,3.236]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize",[5,0.493,9,2.026,44,2.935,50,2.358,94,3.823,110,3.571,125,1.789,126,0.581,127,0.613,128,0.839,129,0.662,130,0.679,136,0.896,146,1.681,154,2.712,157,4.131,162,3.214,174,2.328,181,4.592,201,1.789,323,2.875,329,4.13,369,3.966,377,4.549,378,4.549,379,3.696,380,4.32,384,3.966,385,5.689,386,4.549,387,4.324,388,3.214,389,3.823,390,2.615,391,3.696,392,3.696,393,4.549,394,3.582,433,1.51,448,4.32,493,4.549,511,1.3,610,6.368,611,4.32,612,2.818,613,5.22]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA",[614,5.331]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA",[5,0.503,6,1.379,9,1.46,11,4.293,26,3.935,27,3.114,35,3.935,126,0.616,127,0.65,128,0.872,129,0.702,130,0.72,136,0.608,229,1.232,249,3.8,267,3.921,323,3.05,343,2.824,366,5.427,381,3.253,387,2.932,395,4.827,397,4.827,398,4.827,399,5.651,400,4.827,406,4.827,407,4.827,408,4.827,409,4.827,410,4.381,433,1.602,511,1.379,583,4.056,614,5.131,615,5.538,616,3.8,617,4.056,618,5.538,619,5.538,620,5.538,621,5.538,622,5.538,623,5.538,624,5.538,625,5.538]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA.__init__",[626,5.331]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA.__init__",[]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip",[306,3.306]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip",[5,0.456,50,1.969,106,1.088,114,2.377,120,2.227,126,0.714,127,0.753,128,0.956,129,0.814,130,1.019,136,0.704,195,2.067,229,1.428,306,3.687,307,5.221,308,4.502,309,4.051,367,1.51,431,1.792,433,1.856,509,1.834,510,1.9,511,1.598,512,2.042]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply",[367,1.354]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply",[87,4.43,126,0.718,127,0.758,128,0.788,129,0.819,130,0.84,137,1.626,145,2.992,146,2.533,156,3.485,305,5.343,306,5.071,307,5.24,308,4.518,309,4.075,316,3.792,318,4.301,431,2.196,630,6.456,631,6.456]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat",[632,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat",[5,0.379,45,2.088,93,1.282,106,1.252,126,0.537,127,0.567,128,1.081,129,0.612,130,1.03,136,0.811,144,1.675,145,1.836,149,3.454,156,2.606,158,2.606,197,2.185,206,3.536,207,4.207,218,3.819,229,1.452,242,3.748,320,3.313,351,3.832,367,1.136,388,2.972,401,4.924,431,1.822,509,1.38,510,1.429,511,1.202,512,1.536,527,4.472,612,2.606,633,3.129,634,6.846,635,4.828,636,2.901,637,6.846,638,4.472,639,4.472,640,4.451,641,4.828,642,3.668,643,3.668,644,6.524,645,5.686,646,4.828,647,4.828,648,4.828]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur",[649,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur",[5,0.494,9,1.94,106,0.984,126,0.646,127,0.681,128,0.898,129,0.736,130,1.052,136,0.808,137,1.462,144,2.014,149,3.073,195,1.869,212,3.761,228,3.622,229,1.291,236,4.409,323,4.054,367,1.366,431,2.055,433,1.678,446,3.015,504,5.823,505,5.823,506,4.803,507,4.25,508,4.803,509,1.659,510,1.718,511,1.445,512,1.846,583,5.391,650,5.377]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise",[651,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise",[5,0.469,106,0.978,126,0.642,127,0.677,128,0.895,129,0.732,130,1.104,136,0.885,144,2.546,145,2.791,195,1.859,229,1.992,367,1.726,427,5.906,431,1.612,433,1.669,509,1.65,510,1.709,511,1.438,512,1.837,537,2.7,583,4.228,652,8.064,653,5.348,654,5.773,655,5.773,656,4.516]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur",[657,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur",[3,6.067,5,0.451,32,3.546,42,3.546,93,1.207,94,5.098,106,0.902,125,1.824,126,0.592,127,0.625,128,0.85,129,0.675,130,1.07,136,0.937,137,1.753,144,1.847,146,1.714,157,3.199,195,1.714,229,1.549,292,2.666,322,2.873,346,4.638,367,1.638,404,3.768,427,3.898,431,1.486,433,1.539,492,4.405,505,4.21,507,3.898,509,1.521,510,1.576,511,1.325,512,1.693,583,3.898,658,5.322,659,4.044,660,4.405,661,5.322,662,4.21,663,4.638,664,5.322,665,5.322,666,5.322,667,5.322,668,5.322,669,5.322]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion",[670,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion",[5,0.366,9,1.66,44,2.578,50,1.932,93,1.092,125,1.571,126,0.51,127,0.538,128,0.769,129,0.581,130,1.008,136,0.921,137,2.045,144,1.591,156,3.4,197,1.986,201,2.655,229,1.947,250,2.144,348,3.4,349,5.27,367,1.079,390,3.155,414,4.247,433,1.326,511,1.142,512,1.458,537,2.144,539,3.357,581,2.971,584,4.769,585,2.755,586,2.946,587,3.976,588,3.054,589,3.054,590,3.054,591,3.626,592,5.466,593,3.626,594,3.626,595,3.626,596,4.982,597,4.785,598,3.483,671,4.584,672,4.247,673,3.794,674,7.177,675,5.489]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout",[676,5.331]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout",[5,0.456,9,1.241,20,3.448,42,2.048,50,2.122,93,1.359,125,1.613,126,0.342,127,0.361,128,0.575,129,0.39,130,1.066,136,0.9,137,1.973,138,1.986,139,1.634,145,2.889,146,1.843,147,2.048,149,1.627,153,2.251,173,2.099,174,2.099,181,1.728,185,2.006,195,0.99,197,1.3,225,2.722,228,3.157,229,0.684,289,2.176,292,2.358,307,2.048,308,1.765,322,2.542,351,4.717,367,0.723,379,2.176,404,5.547,433,0.889,511,0.765,512,0.978,522,2.542,523,4.191,526,2.543,539,6.451,541,2.847,542,2.251,545,4.103,560,2.431,599,2.678,676,2.847,677,2.847,678,3.073,679,3.448,680,3.073,681,1.597,682,6.916,683,3.073,684,8.031,685,4.708,686,4.362,687,5.723,688,5.723,689,4.708,690,3.073,691,3.073,692,3.073,693,3.073,694,3.073,695,2.678,696,4.708,697,4.987,698,4.708,699,4.708,700,3.073,701,3.073,702,4.708,703,3.073,704,3.073,705,3.073,706,3.073,707,2.847,708,3.073,709,3.073]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip",[710,3.834]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip",[5,0.457,50,1.981,106,1.094,114,2.391,120,2.241,126,0.718,127,0.758,128,0.96,129,0.819,130,1.023,136,0.709,174,2.879,195,2.079,229,1.436,306,3.709,308,3.709,312,3.88,313,3.974,367,1.519,431,1.803,433,1.867,509,1.845,510,1.911,511,1.608,512,2.054]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue",[711,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue",[5,0.432,93,1.482,98,4.206,106,0.825,126,0.542,127,0.572,128,0.801,129,0.618,130,1.079,136,0.872,137,2.327,144,2.965,195,1.569,197,1.812,229,1.084,367,1.146,431,1.36,433,1.408,509,1.392,510,1.442,511,1.213,512,1.55,522,2.629,537,3.473,712,6.081,713,6.564,714,7.944,715,6.284,716,7.944,717,5.432,718,7.944]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression",[719,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression",[5,0.507,51,2.052,126,0.632,127,0.667,128,0.886,129,0.721,130,0.945,136,0.879,144,2.521,145,2.763,146,2.339,229,1.616,433,1.643,511,1.415,512,1.808,536,4.162,555,4.024,574,4.952,575,5.745,720,7.416,721,8.005,722,5.265,723,5.265,724,6.178,725,5.265,726,5.683,727,5.265,728,7.263,729,5.683]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression.ImageCompressionType",[727,5.331]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression.ImageCompressionType",[730,7.684]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg",[731,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg",[5,0.497,106,1.114,125,2.252,126,0.731,127,0.771,128,0.97,129,0.834,130,1.034,136,0.721,195,2.117,197,1.814,229,1.462,367,1.547,405,4.654,431,1.835,433,1.901,488,5.199,509,1.879,510,1.946,511,1.637,732,6.089]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise",[733,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise",[5,0.424,98,3.024,106,0.968,126,0.636,127,0.67,128,0.889,129,0.725,130,0.948,136,0.881,144,1.983,195,1.84,229,1.942,230,4.519,315,3.212,318,3.806,325,3.281,367,1.715,423,4.978,424,4.34,427,5.337,429,4.978,430,4.978,433,1.652,435,3.355,473,4.855,509,1.633,510,1.691,511,1.422,653,5.292,712,6.751,734,5.712,735,5.712,736,5.712,737,5.712,738,4.045,739,4.978,740,5.712]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression",[741,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression",[5,0.484,51,2.167,126,0.69,127,0.728,128,0.936,129,0.786,130,0.806,136,0.842,144,2.662,145,2.918,229,1.707,433,1.793,511,1.544,512,1.972,536,4.54,555,4.389,574,5.402,575,6.068,720,7.718,722,5.743,723,5.743,724,5.618,725,5.743]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda",[742,4.762]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda",[4,4.422,5,0.489,9,1.338,44,2.853,45,2.195,50,2.325,106,1.518,110,4.491,114,2.807,120,2.63,126,0.565,127,0.596,128,0.823,129,0.644,130,0.878,136,0.949,162,3.124,228,2.497,229,1.129,242,2.915,348,2.74,367,1.588,385,4.2,425,4.422,438,4.422,509,1.45,510,1.502,511,1.68,561,4.701,600,4.701,610,7.482,611,4.2,612,2.74,628,5.075,743,4.422,744,3.05,745,3.593,746,5.075,747,3.381,748,5.075]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize",[749,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize",[5,0.509,44,3.246,50,1.771,92,4.777,106,1.243,114,2.138,120,2.004,126,0.642,127,0.677,128,0.895,129,0.732,130,1.049,136,0.885,137,1.454,146,1.859,149,3.884,181,3.246,228,2.841,229,1.284,348,3.96,367,1.359,390,2.891,433,1.669,509,1.65,510,1.709,511,1.438,512,1.837,584,3.554,587,3.644,673,4.777,679,4.228,750,4.567,751,6.796,752,4.386,753,4.777]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout",[754,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout",[5,0.51,6,1.58,38,3.494,39,3.122,50,2.692,93,1.1,197,1.751,212,5.042,289,4.492,292,3.177,387,4.119,522,3.425,537,2.967,542,4.646,562,5.877,677,5.877,755,6.344,756,6.344,757,6.344,758,6.344,759,6.344,760,6.344,761,6.344]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__",[626,5.331]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__",[5,0.496,9,1.953,50,2.274,112,3.167,126,0.653,127,0.688,128,0.904,129,0.744,130,0.763,131,2.537,145,2.819,146,1.889,149,3.106,197,2.045,199,2.79,212,3.801,289,4.153,292,2.938,323,3.231,367,1.381,433,1.696,511,1.461,512,1.866,662,4.64,707,5.434,762,5.866,763,5.866,764,4.025,765,5.866,766,5.112,767,8.534,768,5.866,769,5.866,770,5.866]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur",[771,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur",[5,0.494,9,1.94,106,0.984,126,0.646,127,0.681,128,0.898,129,0.736,130,1.052,136,0.808,137,1.462,144,2.014,149,3.073,195,1.869,228,3.622,229,1.291,236,4.409,323,4.054,367,1.366,431,2.055,433,1.678,446,3.015,504,5.823,506,4.803,507,4.25,508,4.803,509,1.659,510,1.718,511,1.445,512,1.846,650,5.377,772,5.804,773,7.361,774,7.361]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur",[775,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur",[5,0.498,9,1.563,106,1.005,126,0.66,127,0.696,128,0.911,129,0.752,130,1.062,136,0.819,137,1.493,144,2.058,149,3.139,195,1.91,228,3.672,229,1.319,323,4.11,367,1.756,431,2.083,433,1.715,446,3.08,504,5.902,505,5.902,506,4.907,507,4.343,508,4.907,509,1.695,510,1.756,511,1.477,512,1.886,776,5.93]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise",[777,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise",[5,0.503,9,1.778,93,1.17,125,2.312,126,0.565,127,0.596,128,0.823,129,0.644,130,0.986,131,2.917,136,0.832,144,1.761,153,5.915,162,4.153,197,2.229,206,6.461,229,1.797,250,2.374,292,3.796,379,4.777,387,3.572,388,3.124,446,3.505,511,1.264,522,2.74,537,2.374,616,5.2,681,2.636,778,5.075,779,5.075,780,4.701,781,4.701,782,5.075,783,5.075,784,5.075,785,5.075,786,5.075]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize",[184,3.236]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize",[5,0.428,93,1.006,125,2.522,126,0.646,127,0.681,128,0.898,129,0.736,130,0.755,136,0.887,146,1.869,149,3.073,197,2.346,201,2.522,229,1.952,244,4.77,387,3.897,405,4.109,433,1.678,511,1.445,512,1.846,642,4.409,656,4.976,732,5.377,745,5.212,787,5.804,788,7.045,789,5.804]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion",[790,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion",[5,0.358,9,1.623,44,2.494,50,1.889,93,1.325,125,1.52,126,0.493,127,0.521,128,0.751,129,0.563,130,1.044,136,0.912,137,1.924,144,2.137,156,3.323,177,5.089,197,1.952,201,2.617,229,2.024,348,3.323,349,5.178,367,1.044,390,3.083,433,1.283,511,1.104,512,1.411,537,2.88,581,2.874,584,4.702,585,2.665,586,2.88,587,3.886,588,2.955,589,2.955,590,2.955,591,3.508,592,5.372,593,3.508,594,3.508,595,3.508,596,4.87,597,4.677,598,3.37,674,7.076,791,7.076]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded",[792,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded",[5,0.487,50,2.051,93,0.868,94,3.665,106,0.848,114,1.854,120,1.737,126,0.557,127,0.587,128,0.816,129,0.635,130,0.87,136,0.945,137,2.169,138,1.737,139,1.737,197,2.077,201,2.291,211,3.159,229,1.862,239,4.895,242,2.875,292,2.507,349,5.512,367,1.178,390,3.348,433,1.447,509,1.43,510,1.482,511,1.246,512,1.592,548,4.637,549,4.637,584,3.081,592,5.078,597,5.718,598,3.802,636,4.017,662,3.959,673,5.532,793,4.637,794,5.005,795,6.684]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize",[470,4.762]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize",[5,0.415,106,0.939,126,0.616,127,0.65,128,0.872,129,0.702,130,1.029,136,0.784,137,2.178,144,2.479,145,2.107,195,1.784,197,1.529,201,2.448,229,1.232,250,2.591,292,3.578,350,3.409,367,1.303,387,2.932,433,1.602,471,6.226,472,4.827,473,3.69,474,4.381,475,4.583,509,1.583,510,1.64,511,1.379,537,2.591,796,8.355,797,5.131,798,5.131,799,4.583,800,7.144,801,5.538,802,5.538,803,5.538,804,5.538]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness",[805,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness",[5,0.474,93,1.29,98,3.937,106,0.999,126,0.656,127,0.692,128,0.908,129,0.748,130,1.059,136,0.816,144,2.581,195,1.899,229,1.961,294,4.819,315,3.316,367,1.388,431,1.647,433,1.705,509,1.686,510,1.746,511,1.469,512,1.876,522,3.184,533,5.264,537,2.759,806,4.367]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast",[807,3.729]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast",[5,0.486,93,1.39,98,3.975,106,0.844,126,0.554,127,0.585,128,0.813,129,0.632,130,1.043,136,0.88,144,2.782,149,2.638,195,1.604,229,2.01,294,4.318,315,3.747,367,1.172,379,3.528,431,1.391,433,1.441,509,1.424,510,1.475,511,1.241,512,1.585,522,2.69,532,5.341,533,5.293,537,3.117,599,4.342,637,4.615,656,3.067,806,4.709,808,4.342,809,4.342,810,4.982,811,5.271]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast",[812,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast",[5,0.474,93,1.29,98,3.937,106,0.999,126,0.656,127,0.692,128,0.908,129,0.748,130,1.059,136,0.816,144,2.581,195,1.899,229,1.961,315,3.316,367,1.388,431,1.647,433,1.705,509,1.686,510,1.746,511,1.469,512,1.876,522,3.184,532,4.954,533,5.264,537,2.759,806,4.367]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop",[813,3.834]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop",[5,0.444,50,1.891,106,1.045,114,2.283,120,2.139,126,0.686,127,0.723,128,0.933,129,0.782,130,0.994,136,0.912,137,1.925,138,2.653,139,2.653,146,1.985,226,3.952,229,1.371,367,1.451,431,1.721,433,1.783,446,3.202,509,1.762,510,1.825,511,1.535,512,1.961,515,3.891]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox",[814,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox",[5,0.48,50,1.86,106,1.027,114,2.245,120,2.625,126,0.674,127,0.711,128,0.923,129,0.769,130,1.073,136,0.83,144,2.104,146,1.952,175,4.292,185,2.582,197,1.673,215,4.439,226,2.883,229,1.835,242,3.482,367,1.427,433,1.753,446,3.149,509,1.732,510,1.795,511,1.509,512,1.928,815,5.282,816,6.062,817,6.062]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog",[818,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog",[5,0.468,6,1.43,7,2.155,126,0.639,127,0.674,128,0.892,129,0.728,130,0.747,136,0.883,144,2.792,145,3.06,146,2.59,229,1.79,259,5.004,262,7.38,263,3.721,264,3.535,266,5.555,300,4.752,424,5.555,428,4.363,433,1.661,511,1.43,512,1.827,533,4.501,536,4.206,555,4.066,819,5.743,820,5.743,821,5.743]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma",[822,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma",[5,0.454,93,1.107,126,0.71,127,0.749,128,0.953,129,0.809,130,1.016,136,0.857,144,2.214,197,1.761,229,1.956,433,1.845,511,1.589,512,2.03,537,2.985,823,8.792,824,5.56,825,6.381,826,6.381,827,6.381]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle",[828,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle",[5,0.516,50,2.017,126,0.731,127,0.771,128,0.97,129,0.834,130,0.855,136,0.721,137,2.002,228,3.235,433,1.901,446,3.414,511,1.637,512,2.091,539,5.823,672,6.089,829,6.573,830,6.573,831,6.573]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain",[832,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain",[5,0.395,6,1.276,7,1.923,93,1.177,126,0.57,127,0.601,128,0.828,129,0.65,130,0.666,136,0.985,137,1.29,144,2.927,145,2.582,146,2.186,201,1.755,229,1.14,261,3.008,263,3.319,264,3.153,270,4.464,271,4.464,272,4.464,273,4.464,274,4.464,276,5.916,277,4.464,278,4.464,279,4.464,280,3.413,281,4.464,351,3.008,433,1.481,473,3.413,511,1.276,512,1.63,563,4.745,586,2.396,715,6.412,724,3.751,797,4.745,798,4.745,799,4.239,833,6.788,834,5.122,835,5.122,836,5.122,837,5.122,838,5.122,839,5.122,840,5.122,841,5.122]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop",[842,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop",[5,0.386,9,1.307,50,1.522,106,0.84,114,1.837,120,1.721,126,0.552,127,0.582,128,0.811,129,0.629,130,0.975,136,0.943,137,1.673,138,2.306,139,2.306,144,2.306,146,1.597,156,2.677,226,3.968,228,3.687,229,1.856,240,4.193,343,2.529,348,3.586,367,1.167,390,2.484,431,1.385,433,1.434,446,2.576,509,1.417,510,1.468,511,1.235,512,1.578,515,3.13,581,3.214,584,4.09,585,2.981,586,2.32,587,4.193,588,3.304,589,3.304,590,3.304,679,5.487,750,3.923,753,5.498,843,4.959,844,4.959,845,4.426]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90",[846,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90",[5,0.454,50,1.958,106,1.081,114,2.363,120,2.214,126,0.71,127,0.749,128,0.953,129,0.809,130,1.016,136,0.7,195,2.055,212,4.135,221,3.445,229,1.42,316,3.747,317,4.848,318,4.251,367,1.502,431,1.782,433,1.845,509,1.824,510,1.889,511,1.589,512,2.03,522,3.445,847,5.28]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply",[367,1.354]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply",[126,0.783,127,0.826,128,0.859,129,0.893,130,0.916,137,1.773,145,2.678,292,3.526,315,3.958,316,4.134,317,5.348,318,4.69,431,1.966,847,5.826]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale",[848,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale",[5,0.473,9,1.363,31,3.264,50,1.587,93,0.897,106,0.876,114,1.915,120,1.795,126,0.575,127,0.607,128,0.834,129,0.656,130,1.058,136,0.84,144,2.371,146,2.2,156,2.791,158,2.791,195,1.665,197,1.427,228,3.361,229,1.882,315,2.908,343,2.637,348,3.688,367,1.217,390,2.59,431,1.907,433,1.495,509,1.478,510,1.531,511,1.288,512,1.645,522,2.791,537,2.419,581,3.351,584,4.205,585,3.108,586,2.419,587,4.312,588,3.445,589,3.445,590,3.445,780,4.79,781,4.79,845,3.445,849,7.538]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow",[850,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow",[5,0.475,6,1.3,7,1.959,93,1.333,126,0.581,127,0.613,128,0.839,129,0.662,130,0.679,132,2.292,133,2.292,134,2.328,135,2.328,136,0.896,137,1.936,144,2.667,145,2.615,146,1.681,197,1.441,229,1.817,263,3.383,264,3.214,284,7.396,292,3.849,428,3.966,433,1.51,507,3.823,511,1.3,512,1.661,533,4.231,542,3.823,555,4.867,642,5.222,686,4.836,851,5.22,852,4.836,853,6.874,854,6.874,855,5.22,856,4.549]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop",[857,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop",[5,0.445,9,1.363,50,1.587,106,0.876,120,2.371,126,0.575,127,0.607,128,0.834,129,0.656,130,0.995,136,0.929,137,1.72,138,2.655,139,2.371,146,1.665,156,2.791,226,3.87,228,2.545,229,1.52,246,4.506,252,4.506,348,3.688,367,1.608,390,2.59,431,1.907,433,1.495,446,2.686,509,1.478,510,1.531,511,1.288,512,1.645,515,3.264,581,3.351,584,4.205,585,3.108,586,2.419,587,4.312,588,3.445,589,3.445,590,3.445,750,4.09,845,4.551,858,4.09,859,5.171,860,5.171,861,3.661]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop",[862,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop",[5,0.397,9,1.363,50,1.587,106,0.876,114,1.915,120,1.795,126,0.575,127,0.607,128,0.834,129,0.656,130,0.995,136,0.954,137,2.049,138,2.371,139,2.371,146,1.665,156,2.791,226,4.024,228,3.361,229,1.52,348,3.688,367,1.217,390,2.59,431,1.444,433,1.495,446,2.686,509,1.478,510,1.531,511,1.288,512,1.645,515,3.264,533,3.183,581,3.351,584,4.205,585,3.108,586,2.419,587,4.312,588,3.445,589,3.445,590,3.445,679,3.787,750,4.09,753,4.279,845,4.551,863,5.171,864,5.171]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow",[865,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow",[5,0.467,6,1.422,7,2.144,93,0.991,125,1.958,126,0.636,127,0.67,128,0.889,129,0.725,130,0.743,136,0.881,144,2.529,145,3.052,146,2.347,197,1.577,221,3.084,229,1.785,263,3.702,264,3.516,287,4.978,288,4.978,289,4.045,291,7.365,292,2.861,428,4.34,433,1.652,511,1.422,512,1.817,866,5.712,867,5.712,868,6.35,869,5.712,870,5.712,871,5.712,872,5.712]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare",[873,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare",[5,0.459,6,1.192,7,1.796,93,1.474,126,0.532,127,0.562,128,0.792,129,0.607,130,0.623,132,2.101,133,2.101,134,2.134,135,2.134,136,0.954,137,2.14,144,2.861,145,2.799,146,2.089,197,1.321,229,1.891,263,3.101,264,2.946,292,3.248,298,4.17,299,4.17,300,5.367,301,4.17,302,7.183,428,3.636,433,1.384,473,3.188,507,3.505,511,1.192,512,1.522,533,3.992,536,3.505,542,3.505,555,3.388,852,4.433,874,4.785,875,6.486,876,6.486,877,6.486,878,6.486]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize",[845,3.834]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize",[5,0.415,9,1.46,50,1.699,106,0.939,114,2.051,120,1.922,126,0.616,127,0.65,128,0.872,129,0.702,130,1.029,136,0.917,137,1.799,138,2.744,139,2.744,146,1.784,156,2.99,158,3.857,229,1.232,329,4.381,348,3.857,367,1.303,390,2.774,431,1.546,433,1.602,509,1.583,510,1.64,511,1.379,512,1.762,581,3.589,584,4.398,585,3.329,586,2.591,587,4.509,588,3.69,589,3.69,590,3.69,793,6.618,845,3.69]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift",[879,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift",[5,0.425,93,1.468,98,3.869,106,0.8,126,0.526,127,0.554,128,0.785,129,0.599,130,1.067,136,0.861,137,2.316,144,2.938,195,1.521,197,2.165,229,1.051,250,2.209,367,1.112,381,2.774,387,4.153,431,1.319,433,1.366,509,1.35,510,1.398,511,1.176,512,1.503,522,2.55,537,3.418,715,6.697,815,4.116,880,7.844,881,4.116,882,7.844,883,4.116,884,7.844,885,4.116]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate",[316,3.38]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate",[5,0.352,9,1.596,44,2.434,50,1.857,93,1.05,106,0.734,114,1.603,120,1.503,125,1.484,126,0.482,127,0.508,128,0.739,129,0.549,130,1.035,136,0.905,137,2.174,144,1.503,156,3.268,195,1.394,197,1.927,201,2.59,229,1.77,316,2.543,317,4.599,325,4.01,348,3.268,349,5.112,367,1.425,384,3.289,390,3.032,431,1.209,433,1.252,446,2.249,509,1.237,510,1.282,511,1.078,512,1.377,522,2.337,533,4.653,537,2.025,581,2.806,584,4.653,585,2.602,586,2.832,587,3.821,588,2.885,589,2.885,590,2.885,591,3.425,592,5.303,593,3.425,594,3.425,595,3.425,596,4.789,597,4.599,598,3.289,617,3.171,886,3.773,887,6.054]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate",[888,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate",[5,0.309,9,1.401,44,2.031,50,1.631,51,1.021,93,1.345,106,0.901,114,1.338,125,1.238,126,0.402,127,0.424,128,0.649,129,0.458,130,1.043,136,0.903,137,2.072,138,1.254,139,1.254,144,2.782,145,1.374,146,1.163,156,2.87,176,3.273,195,1.163,197,2.213,201,2.384,218,2.858,229,1.968,309,2.28,315,2.989,316,3.122,343,2.711,348,2.87,349,4.62,367,1.484,390,2.663,431,1.009,433,1.045,509,1.033,510,1.07,511,0.9,512,1.149,522,1.95,536,2.646,537,2.951,555,2.558,581,2.341,584,4.282,585,2.171,586,2.487,587,3.356,588,2.407,589,2.407,590,2.407,591,2.858,592,4.792,593,2.858,594,2.858,595,2.858,596,4.205,597,4.039,598,2.745,791,6.444,815,3.148,849,6.444,889,2.99,890,3.613,891,3.613,892,5.316,893,6.956,894,4.633]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize",[895,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize",[5,0.508,44,3.212,50,1.753,92,4.727,106,1.235,114,2.116,120,1.983,126,0.636,127,0.67,128,0.889,129,0.725,130,1.044,136,0.881,137,1.439,146,1.84,147,3.806,149,3.024,181,3.212,228,2.811,229,1.271,348,3.934,367,1.344,390,2.861,433,1.652,509,1.633,510,1.691,511,1.422,512,1.817,584,3.516,587,3.606,673,6.03,679,4.184,750,4.519,751,6.751,752,4.34,753,4.727,896,5.712]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize",[486,4.552]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize",[5,0.435,106,1.01,125,2.043,126,0.663,127,0.7,128,0.914,129,0.756,130,1.065,136,0.898,137,2.061,144,2.598,195,1.92,197,2.067,224,6.193,229,1.91,238,4.367,367,1.403,486,4.716,487,5.196,488,4.716,509,1.704,510,1.765,511,1.485,537,2.789]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat",[897,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat",[5,0.462,45,2.42,106,1.219,125,1.917,126,0.623,127,0.657,128,1.024,129,0.71,130,1.034,136,0.789,144,1.942,145,2.128,149,3.807,158,3.021,197,2.315,218,4.426,229,1.6,242,4.131,244,3.626,320,3.839,351,4.223,367,1.317,388,3.444,431,2.008,509,1.599,510,1.657,511,1.393,512,1.78,634,7.362,638,5.184,639,5.184,640,3.146,642,4.251,898,5.595,899,5.595]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray",[900,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray",[5,0.52,106,1.051,125,2.124,126,0.69,127,0.728,128,0.936,129,0.786,130,0.998,136,0.68,154,3.22,195,1.996,197,1.711,229,1.379,367,1.459,381,3.641,382,6.685,431,1.731,433,1.793,488,4.904,509,1.772,510,1.835,511,1.544,512,1.972,636,4.61,656,3.816,901,6.199,902,6.199]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia",[903,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia",[5,0.497,106,1.114,126,0.731,127,0.771,128,0.97,129,0.834,130,1.034,136,0.721,195,2.117,229,1.462,236,4.994,367,1.871,381,3.86,431,1.835,433,1.901,509,1.879,510,1.946,511,1.637,512,2.091,904,6.573]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose",[327,4.372]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose",[5,0.459,50,1.993,106,1.101,114,2.405,120,2.254,121,2.852,126,0.723,127,0.762,128,0.963,129,0.824,130,1.027,136,0.713,195,2.091,229,1.445,327,4.934,367,1.528,431,1.813,433,1.878,492,5.375,509,1.856,510,1.923,511,1.617,512,2.066,905,5.66]],["title/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip",[906,5.755]],["text/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip",[5,0.457,50,1.981,106,1.094,114,2.391,120,2.241,126,0.718,127,0.758,128,0.96,129,0.819,130,1.023,136,0.709,173,2.879,195,2.079,229,1.436,306,3.709,307,4.301,312,3.88,313,3.974,367,1.519,431,1.803,433,1.867,509,1.845,510,1.911,511,1.608,512,2.054]],["title/api_reference/core/",[55,4.372]],["text/api_reference/core/",[41,5.197,102,6.02,103,6.739,104,4.846,105,6.739,106,1.233,107,4.714,108,6.739]],["title/api_reference/core/composition/",[41,2.342,102,3.148,907,3.524]],["text/api_reference/core/composition/",[1,1.32,5,0.141,19,1.489,41,1.489,51,1.958,52,2.263,93,1.202,102,2.002,106,1.438,114,2.671,120,1.354,124,3.176,125,0.829,126,0.829,127,0.814,128,0.846,129,0.782,130,1.017,132,2.152,133,2.152,134,1.739,135,1.739,136,0.939,138,1.951,139,1.951,147,2.599,155,3.216,157,2.344,159,2.344,160,3.093,161,2.528,162,2.401,166,4.522,167,3.228,168,3.228,169,2.002,170,1.838,171,2.002,172,2.002,173,2.507,174,2.507,175,2.762,176,1.489,184,2.756,185,1.662,195,1.578,196,1.772,197,1.077,199,1.855,201,2.773,211,1.527,214,1.713,215,2.856,216,1.772,217,3.228,220,1.612,222,2.002,229,1.372,230,1.914,231,2.108,242,1.39,293,1.66,310,1.713,318,2.599,325,1.39,343,1.234,351,2.291,367,1.697,384,2.963,387,2.594,509,1.401,510,1.451,511,0.971,586,1.132,681,2.026,745,1.713,806,2.291,907,2.241,908,3.085,909,2.419,910,3.9,911,2.963,912,3.228,913,3.228,914,3.705,915,2.108,916,2.419,917,2.002,918,2.419,919,3.613,920,2.108,921,2.762,922,1.454,923,2.108,924,2.108,925,2.108,926,3.9,927,2.419,928,5.621,929,3.9,930,2.419,931,2.419,932,3.9,933,2.419,934,2.419,935,2.419,936,2.419,937,2.419,938,2.419,939,1.113]],["title/api_reference/core/composition/#composition-api-corecomposition",[41,2.342,102,3.148,907,3.524]],["text/api_reference/core/composition/#composition-api-corecomposition",[]],["title/api_reference/core/composition/#albumentations.core.composition",[103,5.331]],["text/api_reference/core/composition/#albumentations.core.composition",[]],["title/api_reference/core/composition/#albumentations.core.composition.BboxParams",[908,4.552]],["text/api_reference/core/composition/#albumentations.core.composition.BboxParams",[1,1.967,51,2.199,52,2.518,93,1.443,120,2.017,124,4.383,125,1.4,126,0.647,127,0.48,128,0.709,129,0.518,130,0.88,132,2.97,133,2.97,134,2.592,135,2.592,136,0.809,138,2.557,139,2.557,147,3.872,155,3.607,157,2.456,159,3.493,160,4.269,161,3.766,166,5.341,167,4.81,168,4.81,169,3.382,170,3.105,171,3.382,172,3.382,173,2.592,174,2.592,175,4.115,176,2.515,184,3.803,195,1.316,196,2.993,197,1.128,199,1.943,201,2.318,211,2.579,214,2.893,215,4.256,216,2.993,217,3.382,220,2.723,222,3.382,229,1.293,230,3.232,231,3.561,681,2.123,806,3.413,909,4.086,910,5.812,911,3.105,912,3.382,913,3.382]],["title/api_reference/core/composition/#albumentations.core.composition.Compose",[914,3.458]],["text/api_reference/core/composition/#albumentations.core.composition.Compose",[5,0.324,19,3.427,51,2.025,52,2.122,106,1.529,114,2.062,126,0.882,127,0.93,128,0.679,129,0.706,130,0.932,136,0.951,197,1.536,201,2.716,229,1.238,242,3.198,367,1.31,509,1.591,510,1.648,511,1.785,908,4.403,914,4.307,915,4.851,916,5.567,917,4.607,918,5.567,919,5.157,920,4.851,921,5.075,922,3.346,923,4.851,924,4.851,925,4.851]],["title/api_reference/core/composition/#albumentations.core.composition.KeypointParams",[919,5.331]],["text/api_reference/core/composition/#albumentations.core.composition.KeypointParams",[106,0.911,114,3.313,126,0.78,127,0.631,128,0.855,129,0.682,130,0.699,136,0.907,155,3.124,157,3.23,162,4.313,166,3.688,173,3.124,174,3.124,185,2.985,199,2.556,201,2.401,217,4.448,293,3.688,310,3.806,318,4.668,325,3.087,343,2.741,681,2.792,911,4.083,912,4.448,913,4.448,926,7.006,927,5.375,928,8.26,929,7.006,930,5.375,931,5.375,932,7.006,933,5.375,934,5.375,935,5.375,936,5.375]],["title/api_reference/core/composition/#albumentations.core.composition.OneOf",[937,5.755]],["text/api_reference/core/composition/#albumentations.core.composition.OneOf",[106,1.508,126,0.736,127,0.776,128,0.807,129,0.839,130,1.038,136,0.876,195,2.13,201,2.735,229,1.471,367,1.878,384,6.063,509,1.89,510,1.958,586,3.093,914,3.974]],["title/api_reference/core/composition/#albumentations.core.composition.PerChannel",[938,5.755]],["text/api_reference/core/composition/#albumentations.core.composition.PerChannel",[106,1.516,126,0.69,127,0.728,128,0.757,129,0.786,130,1.084,136,0.914,195,1.996,201,2.855,229,1.379,351,4.505,367,2.105,387,4.41,509,1.772,510,1.835,745,4.389,914,3.726,939,2.853]],["title/api_reference/core/serialization/",[41,2.342,104,2.535,940,3.524]],["text/api_reference/core/serialization/",[9,1.55,19,1.611,24,1.651,38,2.287,39,2.044,41,1.611,43,3.306,44,2.335,45,2.542,73,3.437,76,1.611,93,1.573,104,5.499,106,1.524,126,0.759,127,0.919,128,0.783,129,0.746,130,0.765,136,0.815,140,0.843,154,1.359,155,2.302,157,3.853,179,1.503,181,2.335,201,0.897,229,0.582,320,1.795,351,3.453,358,1.795,394,1.795,484,1.651,485,1.651,560,3.285,611,2.165,612,2.787,629,2.07,633,2.691,640,1.471,643,1.988,659,1.988,681,2.157,742,6.141,921,3.656,922,2.496,940,2.424,941,2.616,942,2.616,943,2.616,944,2.616,945,2.616,946,2.616,947,2.616,948,3.439,949,2.07,950,2.616,951,2.909,952,2.909,953,2.909,954,2.616,955,2.616,956,2.616,957,2.909,958,5.446,959,5.435,960,3.847,961,3.437,962,3.437,963,6.322,964,5.446,965,5.638,966,4.466,967,2.616,968,3.847,969,1.537,970,4.783,971,5.94,972,6.626,973,2.616,974,3.041,975,3.847,976,4.5,977,4.783,978,3.437,979,2.616,980,2.165]],["title/api_reference/core/serialization/#serialization-api-coreserialization",[41,2.342,104,2.535,940,3.524]],["text/api_reference/core/serialization/#serialization-api-coreserialization",[]],["title/api_reference/core/serialization/#albumentations.core.serialization",[105,5.331]],["text/api_reference/core/serialization/#albumentations.core.serialization",[]],["title/api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta",[941,5.755]],["text/api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta",[9,2.183,45,3.582,106,1.193,127,0.826,942,7.039,943,7.039,944,7.039,945,7.039,946,7.039,947,7.039,948,3.091,949,5.568]],["title/api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__",[950,5.755]],["text/api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__",[19,4.508,39,3.604,76,4.508,140,2.358,320,5.025,611,6.06,954,7.323,955,7.323]],["title/api_reference/core/serialization/#albumentations.core.serialization.from_dict",[956,5.755]],["text/api_reference/core/serialization/#albumentations.core.serialization.from_dict",[38,3.32,43,4.239,45,2.607,104,5.023,106,1.504,126,0.671,127,0.965,128,0.736,129,0.765,130,0.784,136,0.827,351,3.54,612,3.254,681,3.131,742,7.133,921,5.338,922,3.623,948,3.612,958,5.585,959,6.312,960,5.585,961,4.989]],["title/api_reference/core/serialization/#albumentations.core.serialization.load",[962,4.762]],["text/api_reference/core/serialization/#albumentations.core.serialization.load",[38,3.005,43,3.978,45,2.359,73,4.515,104,5.535,106,1.495,126,0.607,127,0.921,128,0.666,129,0.692,130,0.71,136,0.862,155,2.433,157,4.252,351,3.204,612,2.945,681,2.834,742,6.875,921,3.863,922,3.279,948,3.647,958,5.054,959,5.75,960,5.054,961,4.515,962,4.515,963,6.554,964,5.054,965,5.965,966,5.375,967,5.455,968,5.054,969,3.204]],["title/api_reference/core/serialization/#albumentations.core.serialization.save",[970,5.331]],["text/api_reference/core/serialization/#albumentations.core.serialization.save",[9,1.483,24,3.55,44,3.162,73,4.654,104,5.599,106,1.473,126,0.803,127,0.66,128,0.686,129,0.713,130,0.732,136,0.792,155,3.217,157,4.787,179,3.231,485,3.55,560,4.449,612,3.036,633,3.645,948,2.469,963,6.684,964,5.21,965,6.052,966,5.481,968,5.21,970,6.684,971,5.21,972,7.38,973,5.624,974,4.119,975,5.21,976,4.901,977,5.21,978,4.654]],["title/api_reference/core/serialization/#albumentations.core.serialization.to_dict",[976,5.015]],["text/api_reference/core/serialization/#albumentations.core.serialization.to_dict",[9,1.555,39,2.902,44,3.316,104,4.954,106,1.494,126,0.827,127,0.692,128,0.908,129,0.748,130,0.767,136,0.647,154,3.064,181,4.181,201,2.021,229,1.312,394,4.047,484,3.723,560,4.665,633,3.822,640,3.316,643,4.481,659,4.481,948,2.589,959,4.319,971,6.889,972,6.889,974,4.319,975,5.464,976,5.14,977,6.889,978,4.881,979,5.898,980,4.881]],["title/api_reference/core/transforms_interface/",[106,0.645,107,2.465,981,3.524]],["text/api_reference/core/transforms_interface/",[5,0.433,19,2.573,34,2.573,37,2.213,39,2.057,50,1.812,93,1.562,106,1.261,107,2.709,126,0.465,127,0.804,128,0.51,129,0.53,130,0.544,131,3.219,136,0.459,140,1.902,154,2.172,197,2.401,201,1.433,250,1.955,261,2.455,315,2.351,322,2.257,351,4.371,367,0.984,383,3.307,431,1.649,448,4.888,511,1.853,586,2.763,612,3.188,627,4.18,662,3.307,681,2.172,697,6.486,766,3.643,920,5.147,921,2.96,922,3.55,923,3.643,924,5.968,925,3.643,939,1.924,981,3.873,982,4.18,983,4.18,984,4.888,985,3.643,986,4.18,987,4.18,988,4.18,989,4.18,990,4.18,991,4.18,992,4.18,993,4.18,994,4.18,995,5.906,996,5.906,997,5.906,998,5.668,999,4.18,1000,4.18,1001,3.643]],["title/api_reference/core/transforms_interface/#transforms-interface-coretransforms_interface",[106,0.645,107,2.465,981,3.524]],["text/api_reference/core/transforms_interface/#transforms-interface-coretransforms_interface",[]],["title/api_reference/core/transforms_interface/#albumentations.core.transforms_interface",[108,5.331]],["text/api_reference/core/transforms_interface/#albumentations.core.transforms_interface",[]],["title/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform",[982,5.755]],["text/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform",[]],["title/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets",[983,5.755]],["text/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets",[5,0.483,19,3.795,39,3.034,50,2.345,93,1.069,106,1.045,127,0.897,197,1.701,261,3.62,511,2.163,586,3.576,681,3.202,920,5.372,921,4.365,922,4.594,923,5.372,924,7.241,925,5.372,984,6.326,985,5.372,986,6.164,987,6.164,988,6.164,989,6.164]],["title/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.DualTransform",[990,5.755]],["text/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.DualTransform",[34,4.664,37,4.012,106,1.284]],["title/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.ImageOnlyTransform",[991,5.755]],["text/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.ImageOnlyTransform",[5,0.441,106,1.284,367,1.783]],["title/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.NoOp",[992,5.755]],["text/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.NoOp",[993,7.684]],["title/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple",[994,5.755]],["text/api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple",[93,1.255,126,0.629,127,0.663,128,0.69,129,0.717,130,0.735,131,3.641,136,0.621,140,2.331,154,2.937,197,2.53,201,1.937,250,2.645,315,3.179,322,3.052,351,4.251,383,4.472,431,2.021,448,4.678,612,3.908,662,4.472,697,7.337,766,4.927,939,2.602,995,5.653,996,5.653,997,7.239,998,6.608,999,5.653,1000,5.653,1001,4.927]],["title/api_reference/imgaug/",[55,4.372]],["text/api_reference/imgaug/",[106,1.293,116,7.069]],["title/api_reference/imgaug/transforms/",[106,0.776,1002,4.243]],["text/api_reference/imgaug/transforms/",[5,0.484,9,0.92,28,1.096,45,1.929,50,1.896,93,0.605,106,1.298,121,0.927,124,2.261,125,0.723,126,0.728,127,0.768,128,0.798,129,0.83,130,1.143,136,0.922,137,1.305,144,1.991,145,1.697,164,2.619,176,2.148,177,2.971,184,2.508,190,2.394,195,2.353,197,1.231,220,3.823,229,1.911,240,3.27,242,2.562,250,0.987,261,1.239,267,2.47,292,2.234,293,4.693,312,2.097,315,1.187,343,2.274,348,2.408,350,2.148,367,1.539,394,1.448,405,2.47,419,3.668,427,3.266,431,1.826,446,1.812,473,1.406,485,2.815,509,1.869,510,2.025,511,1.703,522,1.883,525,3.691,539,3.794,583,1.546,585,1.268,616,1.448,617,3.266,636,2.097,656,1.299,659,2.651,660,2.887,663,1.839,675,1.839,724,1.546,739,3.04,744,1.268,806,2.619,889,2.887,905,1.839,949,1.669,1002,1.955,1003,2.11,1004,2.11,1005,4.132,1006,2.11,1007,2.11,1008,2.887,1009,4.132,1010,3.232,1011,3.232,1012,3.887,1013,3.887,1014,3.887,1015,2.11,1016,5.181,1017,3.232,1018,2.11,1019,2.11,1020,2.11,1021,1.368,1022,2.11,1023,2.11,1024,2.11,1025,2.11,1026,2.11,1027,2.11,1028,2.11,1029,2.11,1030,2.11,1031,5.181,1032,3.489,1033,2.11,1034,2.11,1035,2.11,1036,5.181,1037,2.11,1038,2.11,1039,2.11,1040,2.11,1041,2.11,1042,2.11,1043,2.11,1044,2.11,1045,2.11,1046,2.11]],["title/api_reference/imgaug/transforms/#transforms-imgaugtransforms",[106,0.776,1002,4.243]],["text/api_reference/imgaug/transforms/#transforms-imgaugtransforms",[]],["title/api_reference/imgaug/transforms/#albumentations.imgaug.transforms",[116,5.331]],["text/api_reference/imgaug/transforms/#albumentations.imgaug.transforms",[]],["title/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise",[1003,5.755]],["text/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise",[5,0.428,93,1.277,106,0.984,126,0.646,127,0.681,128,0.708,129,0.736,130,1.106,136,0.887,137,1.462,145,2.208,177,3.867,184,4.139,195,1.869,229,1.798,261,3.409,343,2.96,367,1.366,405,5.212,427,5.92,431,1.621,509,1.659,510,1.718,511,1.445,583,4.25,617,5.391,656,3.573,659,4.409,660,4.803,1004,5.804,1005,6.819,1006,5.804]],["title/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine",[1007,5.755]],["text/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine",[5,0.356,45,2.651,50,2.337,106,1.291,126,0.682,127,0.719,128,0.748,129,0.777,130,0.991,136,0.673,164,3.6,195,1.974,197,1.692,229,1.364,293,5.227,312,3.684,348,3.309,367,1.443,419,4.34,431,1.712,509,1.752,510,1.815,511,1.526,522,3.309,539,4.489,889,5.073,1008,5.073,1009,5.679,1010,5.679,1011,5.679,1012,5.342,1013,5.342,1014,5.342]],["title/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss",[1015,5.755]],["text/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss",[5,0.506,106,0.958,126,0.629,127,0.663,128,0.69,129,0.717,130,1.095,136,0.876,144,2.512,145,2.15,195,2.331,220,4.823,229,1.936,240,4.569,242,3.247,267,4.003,367,1.33,431,1.579,485,3.568,509,1.616,510,1.674,511,1.408,525,4.678,636,3.398,739,6.308,806,4.251,1016,8.419,1017,5.237,1018,5.653,1019,5.653]],["title/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective",[1020,5.755]],["text/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective",[5,0.33,9,1.498,28,2.952,45,2.457,50,2.228,106,1.231,126,0.632,127,0.667,128,0.694,129,0.721,130,1.041,136,0.797,164,3.338,176,3.498,177,3.786,184,3.195,190,4.983,195,1.83,197,1.568,229,1.781,293,3.899,343,2.898,348,3.068,367,1.337,431,1.587,446,3.773,509,1.624,510,1.682,511,1.415,616,3.899,617,4.162,659,4.317,660,4.703,663,4.952,949,4.495,1012,4.952,1013,4.952,1014,4.952,1021,3.683,1022,5.683,1023,5.683,1024,5.683]],["title/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine",[1025,5.755]],["text/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine",[5,0.299,45,2.226,50,2.089,106,1.154,121,2.26,126,0.573,127,0.604,128,0.628,129,0.653,130,1.099,136,0.891,137,1.715,144,1.786,164,3.023,177,3.429,195,1.657,197,1.421,229,1.698,250,2.407,292,3.411,293,5.796,312,3.093,315,2.894,343,2.625,348,2.778,350,4.192,367,1.211,419,5.403,431,1.437,509,1.471,510,1.524,511,1.282,522,2.778,539,5.589,675,4.485,889,4.259,905,4.485,1008,4.259,1009,6.308,1010,4.768,1011,4.768,1012,4.485,1013,4.485,1014,4.485,1026,5.147,1027,5.147,1028,5.147,1029,5.147]],["title/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen",[1030,5.755]],["text/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen",[5,0.516,106,0.948,126,0.623,127,0.657,128,0.683,129,0.71,130,1.091,136,0.872,144,2.496,145,2.128,195,2.559,220,5.294,229,1.93,240,4.539,242,4.131,267,3.962,367,1.317,431,1.562,485,3.532,509,1.599,510,1.657,511,1.393,525,5.951,636,3.363,806,3.286,1017,5.184,1031,8.387,1032,7.191]],["title/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels",[1033,5.755]],["text/api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels",[5,0.417,9,1.467,106,1.215,124,4.645,125,1.908,126,0.619,127,0.653,128,0.679,129,0.706,130,1.089,136,0.87,137,1.402,176,3.427,195,1.793,229,1.595,292,2.788,367,1.31,394,3.82,431,1.554,473,3.709,485,3.514,509,1.591,510,2.122,511,1.785,585,3.346,724,4.077,744,3.346,1005,5.157,1034,5.567,1035,5.567,1036,8.371,1037,5.567,1038,5.567,1039,5.567,1040,5.567,1041,5.567,1042,5.567,1043,5.567,1044,5.567,1045,5.567,1046,5.567]],["title/api_reference/pytorch/",[55,4.372]],["text/api_reference/pytorch/",[106,1.293,117,7.069]],["title/api_reference/pytorch/transforms/",[106,0.776,1047,4.243]],["text/api_reference/pytorch/transforms/",[5,0.464,9,1.49,17,3.663,37,3.832,50,2.583,93,0.98,106,1.227,126,0.629,127,0.663,128,0.883,129,0.717,130,0.735,136,0.876,137,1.424,154,3.76,162,3.48,165,3.32,184,3.179,244,3.663,405,4.003,433,1.635,656,3.48,788,4.927,861,4.003,921,5.125,922,3.398,939,2.602,978,4.678,1047,5.237,1048,5.653,1049,6.706,1050,5.653,1051,5.653,1052,4.927,1053,5.653,1054,5.653,1055,5.653,1056,5.653,1057,5.653]],["title/api_reference/pytorch/transforms/#transforms-pytorchtransforms",[106,0.776,1047,4.243]],["text/api_reference/pytorch/transforms/#transforms-pytorchtransforms",[]],["title/api_reference/pytorch/transforms/#albumentations.pytorch.transforms",[117,5.331]],["text/api_reference/pytorch/transforms/#albumentations.pytorch.transforms",[]],["title/api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor",[1048,5.755]],["text/api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor",[5,0.434,9,1.563,17,3.843,37,3.95,50,2.505,106,1.005,126,0.66,127,0.696,128,0.911,129,0.752,130,0.771,136,0.896,137,1.493,154,3.08,162,3.65,165,3.483,184,3.334,244,3.843,405,4.199,433,1.715,656,3.65,788,5.168,861,4.199,921,5.283,922,3.564,939,2.729,978,4.907,1049,5.493,1050,5.93,1051,5.93,1052,5.168,1053,5.93,1054,5.93,1055,5.93,1056,5.93]],["title/api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensorV2",[1057,5.755]],["text/api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensorV2",[5,0.435,50,2.293,93,1.296,154,3.882,1049,6.923]],["title/getting_started/bounding_boxes_augmentation/",[6,0.708,39,1.398,40,1.749,51,0.803,52,0.841]],["text/getting_started/bounding_boxes_augmentation/",[1,1.856,5,0.433,6,1.807,7,0.601,9,1.332,16,0.387,17,0.387,30,0.437,31,1.011,38,0.621,39,1.661,40,0.368,43,2.438,45,2.479,47,1.209,50,0.346,51,2.439,52,2.578,76,0.986,87,0.41,93,1.659,97,0.343,98,0.597,104,0.398,106,1.009,110,0.586,112,0.864,120,1.573,123,0.494,124,1.314,125,1.249,126,0.268,127,0.283,128,0.247,129,0.076,132,1.213,133,1.213,134,1.076,135,1.076,136,0.176,138,1.505,139,1.505,140,0.516,145,0.609,146,0.653,155,2.787,156,0.322,158,0.609,159,2.836,160,1.946,161,1.564,164,0.94,165,1.191,173,1.374,174,1.374,176,0.368,184,1.357,185,2.923,186,0.857,187,1.391,188,1.391,189,0.798,190,1.391,195,0.516,196,0.826,197,1.549,199,2.973,201,1.676,212,0.387,214,2.58,216,2.472,220,0.751,221,0.864,224,0.41,225,1.605,226,0.284,227,0.472,228,0.555,235,1.325,237,2.243,238,0.437,239,0.437,244,0.731,250,1.579,261,0.351,309,0.377,310,0.798,313,1.248,320,0.41,322,1.492,323,0.621,328,1.701,350,0.986,367,0.794,371,0.437,392,1.956,394,0.41,404,0.423,431,0.315,434,0.731,435,1.417,484,0.712,509,0.79,513,1.396,515,0.377,523,1.767,537,0.279,566,0.423,580,1.351,586,0.948,612,1.822,633,0.731,636,0.359,640,1.733,643,0.857,656,0.368,679,0.437,681,0.31,695,1.396,710,1.067,738,0.423,744,0.962,745,0.423,747,0.398,806,0.94,807,1.038,813,1.067,845,0.398,858,0.472,861,0.423,908,1.267,911,1.833,912,0.494,913,0.494,914,1.852,917,1.678,939,2.172,948,1.059,961,0.494,965,0.454,966,0.454,969,1.417,974,0.437,980,1.325,984,0.933,998,0.933,1001,0.52,1021,2.361,1058,1.044,1059,0.597,1060,1.217,1061,0.472,1062,0.597,1063,1.173,1064,2.564,1065,2.773,1066,1.623,1067,0.857,1068,1.044,1069,2.58,1070,2.408,1071,1.767,1072,1.396,1073,1.396,1074,1.267,1075,1.127,1076,1.127,1077,1.127,1078,1.127,1079,1.044,1080,0.597,1081,0.597,1082,0.52,1083,1.127,1084,1.127,1085,1.678,1086,1.396,1087,1.396,1088,1.396,1089,0.52,1090,1.044,1091,0.597,1092,0.597,1093,0.597,1094,0.597,1095,0.398,1096,1.127,1097,1.127,1098,0.774,1099,0.597,1100,0.597,1101,0.597,1102,0.597,1103,0.597,1104,0.92,1105,0.597,1106,1.787,1107,1.165,1108,1.79,1109,0.986,1110,1.134,1111,2.023,1112,2.56,1113,1.767,1114,1.678,1115,2.028,1116,0.933,1117,0.857,1118,1.267,1119,0.472,1120,0.52,1121,0.597,1122,3.819,1123,0.52,1124,1.325,1125,0.892,1126,0.52,1127,0.597,1128,1.841,1129,0.597,1130,1.217,1131,0.597,1132,0.597,1133,0.52,1134,0.597,1135,0.597,1136,1.044,1137,1.485,1138,2.67,1139,2.286,1140,2.286,1141,2.883,1142,2.883,1143,2.883,1144,2.883,1145,2.883,1146,2.883,1147,2.883,1148,2.883,1149,2.883,1150,2.883,1151,4.232,1152,1.044,1153,1.044,1154,1.044,1155,2.408,1156,1.396,1157,0.597,1158,0.597,1159,0.472,1160,0.472,1161,0.472,1162,0.472,1163,0.892,1164,0.597,1165,0.597,1166,1.127,1167,0.597,1168,0.857,1169,1.127,1170,0.933,1171,1.601,1172,0.41,1173,0.41,1174,0.472,1175,0.597,1176,1.217,1177,1.127,1178,0.597,1179,1.127,1180,2.413,1181,0.597,1182,0.597]],["title/getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation-for-object-detection",[6,0.708,39,1.398,40,1.749,51,0.803,52,0.841]],["text/getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation-for-object-detection",[]],["title/getting_started/bounding_boxes_augmentation/#different-annotations-formats",[31,2.401,155,1.696,1058,3.524]],["text/getting_started/bounding_boxes_augmentation/#different-annotations-formats",[1,1.951,5,0.451,9,1.52,39,2.837,43,2.272,51,2.396,52,2.511,93,1.518,123,3.344,125,2.512,127,0.474,132,2.532,133,2.532,134,2.571,135,2.571,138,2.001,139,2.001,145,2.193,155,3.269,159,3.465,160,2.551,161,2.619,165,2.373,173,2.571,174,2.571,185,3.302,186,4.381,187,4.613,188,4.613,189,4.082,190,4.613,237,2.487,250,2.697,320,2.773,394,2.773,434,2.619,435,2.373,586,1.89,633,2.619,961,3.344,1021,2.619,1058,3.744,1059,4.041,1060,4.381,1061,3.197,1062,4.041,1063,2.959,1064,3.07,1065,2.789,1066,3.386,1067,3.07,1068,3.744,1069,2.861,1070,3.521,1071,3.521,1072,3.521,1073,3.521,1074,3.197,1075,5.766,1076,5.766,1077,5.766,1078,5.766,1079,3.744]],["title/getting_started/bounding_boxes_augmentation/#pascal_voc",[160,3.632]],["text/getting_started/bounding_boxes_augmentation/#pascal_voc",[9,1.53,51,2.402,52,2.517,93,1.402,125,1.989,132,3.232,133,3.232,134,3.282,135,3.282,155,3.282,160,3.663,173,2.588,174,2.588,185,3.622,197,1.602,313,4.531,1021,3.761,1065,2.807,1066,3.409,1080,5.804,1081,5.804,1082,5.058,1083,7.361,1084,7.361,1085,4.803,1086,5.058,1087,5.058,1088,5.058]],["title/getting_started/bounding_boxes_augmentation/#albumentations",[1,1.947]],["text/getting_started/bounding_boxes_augmentation/#albumentations",[1,2.576,5,0.395,6,1.276,9,2.137,16,3.319,51,2.29,52,2.4,93,1.533,112,2.765,125,1.755,132,2.249,133,2.249,134,2.284,135,2.284,138,1.778,139,1.778,155,3.395,160,4.285,173,2.284,174,2.284,184,3.817,185,3.243,197,2.101,244,3.319,313,3.153,371,3.751,1021,3.319,1064,5.157,1065,2.478,1066,3.008,1070,5.916,1071,5.916,1085,4.239,1086,4.464,1087,4.464,1088,4.464,1089,4.464,1090,4.745,1091,5.122,1092,5.122,1093,5.122,1094,5.122,1095,3.413]],["title/getting_started/bounding_boxes_augmentation/#coco",[159,3.458]],["text/getting_started/bounding_boxes_augmentation/#coco",[9,1.589,39,2.966,51,2.324,52,2.435,93,1.427,125,2.066,132,2.647,133,2.647,138,2.616,139,2.616,155,3.362,159,4.944,185,3.212,187,4.136,188,4.136,190,4.136,197,1.664,328,3.711,744,3.623,1021,3.906,1065,2.916,1066,3.54,1067,4.58,1068,5.585,1072,5.253,1073,5.253,1085,4.989,1087,5.253]],["title/getting_started/bounding_boxes_augmentation/#yolo",[161,3.729]],["text/getting_started/bounding_boxes_augmentation/#yolo",[5,0.376,31,3.007,51,2.398,52,2.513,93,1.585,97,2.737,125,1.633,138,2.732,139,2.732,155,2.883,161,3.088,173,3.273,174,3.273,184,4.127,185,3.354,196,4.736,197,2.173,244,3.088,313,2.933,322,3.491,633,3.088,1021,3.088,1060,3.62,1064,5.577,1065,2.305,1070,6.397,1071,4.152,1072,4.152,1073,4.152,1085,3.943,1086,4.152,1088,4.152,1096,6.466,1097,6.466,1098,3.269,1099,4.764,1100,4.764,1101,4.764,1102,4.764,1103,4.764]],["title/getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation",[6,0.947,51,1.075,52,1.126]],["text/getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation",[5,0.51,6,2.242,7,2.381,50,1.946,51,2.378,52,2.598,136,0.696,350,3.905,744,3.812,939,2.92,948,3.416,969,3.726,1104,3.644,1105,6.344,1106,3.358,1107,3.644,1108,4.111,1109,3.905]],["title/getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries",[7,1.066,136,0.312,146,0.915,1106,1.504,1107,1.632]],["text/getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries",[1,2.546,580,5.014,1107,4.946]],["title/getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline",[6,0.708,322,1.534,744,1.708,948,1.247,1106,1.504]],["text/getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline",[1,1.777,5,0.207,6,1.556,17,2.303,30,2.603,38,1.957,47,2.631,50,1.09,51,1.95,52,2.043,93,1.692,106,0.89,112,2.835,126,0.395,136,0.39,138,1.823,139,1.823,155,3.437,156,1.919,159,3.755,160,2.243,161,2.303,164,2.087,176,2.188,185,2.238,195,1.691,197,0.981,214,2.516,216,2.603,221,1.919,225,3.282,239,2.603,367,0.836,434,2.303,509,1.972,612,1.919,710,3.499,806,3.085,807,3.404,813,3.499,908,4.155,911,2.7,914,4.148,917,5.17,939,1.636,948,1.56,1065,2.541,1090,3.292,1110,3.719,1111,2.603,1112,6.394,1113,3.097,1114,2.941,1115,6.901,1116,2.941,1117,2.7,1118,2.811,1119,2.811,1120,3.097,1121,3.554,1122,3.292]],["title/getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility",[214,3.243,216,3.355]],["text/getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility",[1,2.25,5,0.485,6,2.272,9,1.309,43,4.011,51,2.589,52,2.734,93,1.3,98,2.629,124,4.309,125,1.13,126,0.665,140,1.599,145,1.254,146,1.061,155,1.47,159,1.981,185,1.404,197,1.371,201,1.702,212,2.136,214,5.508,216,5.49,220,2.196,224,2.262,225,1.568,226,1.568,227,2.607,228,2.444,367,1.831,404,2.334,513,5.206,515,2.081,523,4.375,566,2.334,586,2.323,636,1.981,679,2.414,681,1.712,695,5.206,738,2.334,845,2.196,858,2.607,861,2.334,974,2.414,1065,3.626,1079,3.054,1104,1.893,1110,2.334,1111,3.637,1113,4.327,1123,2.872,1124,4.109,1125,3.928,1126,2.872,1127,3.296,1128,4.43,1129,3.296,1130,2.504,1131,3.296,1132,3.296]],["title/getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes",[45,1.407,51,0.919,52,0.963,199,1.547]],["text/getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes",[5,0.409,39,3.845,45,2.336,51,2.424,52,2.54,93,1.525,155,2.408,159,4.224,185,2.994,199,3.343,237,3.325,250,2.527,323,2.975,939,2.486,984,4.47,1063,3.956,1065,3.4,1066,3.172,1069,3.824,1118,4.273,1128,3.599,1133,4.707,1134,5.401,1135,5.401,1136,5.004,1137,3.956,1138,4.273,1139,4.47,1140,4.47,1141,4.273,1142,4.273,1143,4.273,1144,4.273,1145,4.273,1146,4.273,1147,4.273,1148,4.273,1149,4.273,1150,4.273,1151,5.56]],["title/getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates",[51,0.426,52,0.446,146,0.485,185,1.116,197,0.416,199,0.716,201,0.516,328,0.927,939,0.693,1001,1.313,1114,1.247]],["text/getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates",[5,0.277,9,1.256,45,3.404,51,1.827,52,1.914,93,1.532,128,0.789,165,2.798,197,1.785,199,3.491,238,3.489,250,2.229,435,2.798,484,3.007,640,2.679,643,3.62,980,5.351,1065,3.128,1069,4.578,1074,3.769,1124,3.943,1138,5.115,1139,5.351,1140,5.351,1141,5.807,1142,5.807,1143,5.807,1144,5.807,1145,5.807,1146,5.807,1147,5.807,1148,5.807,1149,5.807,1150,5.807,1151,6.714,1152,4.414,1153,4.414,1154,4.414,1155,5.635,1156,4.152]],["title/getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list",[51,0.64,52,0.671,199,1.078,201,0.777,392,1.605,939,1.044,1157,2.267]],["text/getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list",[1,2.208,6,1.625,9,1.273,43,3.669,45,3.423,47,2.418,51,2.336,52,2.523,76,2.972,93,1.282,106,1.106,110,2.508,126,0.537,127,0.766,129,0.612,197,1.333,199,3.932,201,2.532,220,3.217,221,2.606,225,2.296,237,4.016,350,2.972,392,4.62,523,4.778,612,3.522,911,3.668,913,3.995,939,2.222,1065,2.335,1069,3.418,1098,3.313,1106,2.556,1116,3.995,1117,3.668,1130,3.668,1137,3.536,1138,3.819,1139,3.995,1140,3.995,1141,3.819,1142,3.819,1143,3.819,1144,3.819,1145,3.819,1146,3.819,1147,3.819,1148,3.819,1149,3.819,1150,3.819,1151,5.161,1152,4.472,1153,4.472,1154,4.472,1158,4.828]],["title/getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk",[5,0.132,51,0.64,52,0.671,323,1.249,969,1.332,1106,1.2,1108,1.469]],["text/getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk",[1,2.456,5,0.422,6,1.413,7,1.484,9,1.042,31,2.495,39,1.945,43,3.191,45,1.709,47,1.98,51,2.492,52,2.639,87,2.712,93,1.571,104,2.634,140,1.273,155,2.961,159,2.376,160,2.495,161,2.562,185,2.829,197,2.003,199,1.88,201,2.487,221,2.134,237,4.088,250,2.655,310,4.019,328,2.433,537,1.849,580,4.424,586,1.849,640,3.191,656,2.433,747,2.634,965,3.003,966,3.003,969,3.9,998,3.271,1021,4.303,1064,4.312,1104,2.271,1108,4.703,1114,3.271,1118,3.127,1136,3.662,1159,3.127,1160,3.127,1161,3.127,1162,3.127,1163,4.49,1164,3.953,1165,3.953,1166,5.676,1167,3.953,1168,3.003,1169,5.676,1170,4.697,1171,6.64,1172,2.712,1173,2.712,1174,3.127]],["title/getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes",[5,0.152,6,0.653,51,0.426,52,0.776,350,0.927,939,0.693,948,0.661,1106,0.798,1109,0.927]],["text/getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes",[45,3.084,51,2.015,52,2.111,185,3.038,199,3.392,322,3.85,328,4.39,939,3.282,984,5.902,1106,3.776,1128,4.751,1175,7.131]],["title/getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates",[45,1.091,146,0.812,185,1.074,199,1.199,328,1.552,939,1.161]],["text/getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates",[5,0.411,6,1.217,9,0.851,45,2.114,51,2.182,52,2.287,93,1.697,106,1.198,110,1.677,120,2.581,128,0.597,158,1.743,165,2.871,185,2.513,199,2.805,201,1.675,235,2.671,250,2.286,261,1.896,328,1.987,431,0.901,435,1.896,484,2.037,640,3.317,643,2.452,745,2.286,939,1.486,980,2.671,998,2.671,1021,2.092,1065,1.561,1069,3.461,1074,2.553,1109,1.987,1111,2.364,1113,2.813,1114,2.671,1130,2.452,1137,2.364,1138,3.866,1139,4.045,1140,4.045,1141,4.666,1142,4.666,1143,4.666,1144,4.666,1145,4.666,1146,4.666,1147,4.666,1148,4.666,1149,4.666,1150,4.666,1151,5.883,1155,4.259,1156,2.813,1176,2.452]],["title/getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform",[45,0.98,106,0.384,199,1.078,322,1.224,392,1.605,612,1.224,939,1.044]],["text/getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform",[5,0.404,6,0.681,9,1.133,38,1.506,43,2.418,45,2.833,47,1.37,51,1.85,52,1.939,76,2.647,93,1.7,106,1.414,120,2.525,127,0.505,138,0.949,139,0.949,155,1.219,158,1.476,159,1.643,164,2.525,185,1.165,195,0.881,199,3.308,201,1.474,225,2.045,235,3.559,237,2.647,309,1.726,322,1.476,392,3.045,431,0.764,435,2.525,509,1.229,612,3.252,640,1.538,710,1.822,806,1.606,807,1.772,813,1.822,908,2.163,911,4.037,912,2.263,914,3.194,917,2.263,939,2.446,1063,2.003,1065,1.323,1069,3.045,1106,1.448,1111,3.149,1112,3.984,1122,7.35,1137,2.003,1138,3.401,1141,2.163,1142,2.163,1143,2.163,1144,2.163,1145,2.163,1146,2.163,1147,2.163,1148,2.163,1149,2.163,1150,2.163,1151,3.401,1155,3.747,1156,2.383,1168,2.077,1176,3.267,1177,4.3,1178,2.734,1179,4.3,1180,6.55,1181,2.734,1182,2.734]],["title/getting_started/image_augmentation/",[5,0.221,6,0.947,35,2.095]],["text/getting_started/image_augmentation/",[1,1.923,5,0.537,6,2.111,7,2.132,9,1.188,16,1.597,17,0.91,19,0.864,28,0.729,31,0.886,32,0.936,33,0.994,35,0.773,38,1.357,41,0.864,43,0.79,45,1.424,47,2.846,49,2.708,66,1.028,69,0.963,76,2.437,79,1.224,91,1.067,93,1.634,97,0.807,98,2.096,106,1.287,110,1.711,125,0.481,126,0.632,127,0.165,136,0.27,138,0.855,139,0.855,140,0.794,146,1.061,154,1.711,155,2.009,158,0.758,164,0.825,165,0.825,166,0.963,191,1.224,195,0.452,197,0.68,201,1.128,221,0.758,223,1.111,225,0.668,228,0.691,242,0.807,244,0.91,250,1.153,294,1.597,306,0.807,308,0.807,310,0.994,322,1.33,323,0.773,328,1.517,350,0.864,367,0.775,368,1.067,381,1.934,387,1.305,388,2.437,389,1.028,390,3.117,391,3.787,401,3.564,419,0.994,431,1.386,434,2.134,435,0.825,446,0.729,473,1.642,484,0.886,485,0.886,509,1.529,510,1.469,532,1.642,533,0.864,537,0.657,580,3.002,586,1.153,612,1.778,616,0.963,617,1.028,629,1.111,633,0.91,636,0.844,645,1.224,656,2.027,681,0.729,710,0.936,715,1.111,738,2.803,744,1.979,752,1.067,764,0.963,806,0.825,807,1.597,808,2.87,809,2.87,811,1.949,813,0.936,824,1.224,847,1.162,881,2.148,883,2.148,885,2.148,886,1.224,914,2.982,922,1.481,939,2.864,948,2.831,949,1.111,959,1.028,969,3.507,1021,0.91,1052,1.224,1063,1.028,1065,2.4,1067,1.067,1074,1.949,1095,2.194,1104,2.274,1106,2.627,1107,3.703,1108,3.215,1109,3.498,1118,1.111,1120,2.148,1125,1.111,1128,1.642,1130,1.872,1137,1.805,1159,1.111,1160,1.111,1161,1.111,1162,1.111,1168,1.067,1173,0.963,1176,1.067,1183,1.872,1184,2.283,1185,1.949,1186,3.728,1187,3.132,1188,3.293,1189,3.959,1190,2.464,1191,1.404,1192,1.404,1193,1.111,1194,1.404,1195,1.404,1196,1.404,1197,1.404,1198,1.404,1199,1.224,1200,1.404,1201,1.949,1202,1.224,1203,1.404,1204,1.404,1205,1.111,1206,2.464,1207,1.949,1208,1.404,1209,1.224,1210,1.404,1211,1.404,1212,1.224,1213,1.404,1214,1.404,1215,2.464,1216,2.464,1217,1.404,1218,1.404,1219,1.404,1220,1.404,1221,1.404,1222,3.276,1223,1.404,1224,1.404,1225,1.404,1226,1.404,1227,1.404]],["title/getting_started/image_augmentation/#image-augmentation-for-classification",[5,0.221,6,0.947,35,2.095]],["text/getting_started/image_augmentation/#image-augmentation-for-classification",[1,2.198,5,0.527,6,2.203,7,2.437,166,4.456,244,4.209,390,3.253,744,3.903,939,2.989,948,3.466,969,4.636,1021,4.209,1104,3.731,1106,3.438,1107,3.731,1108,5.115,1109,3.998]],["title/getting_started/image_augmentation/#step-1-import-the-required-libraries",[7,1.066,136,0.312,146,0.915,1106,1.504,1107,1.632]],["text/getting_started/image_augmentation/#step-1-import-the-required-libraries",[1,2.855,5,0.454,7,2.931,9,1.682,16,4.135,17,4.135,32,4.251,33,4.518,49,3.835,93,1.107,155,2.845,310,4.518,390,4.226,434,4.135,580,4.251,969,3.747,1065,3.086,1107,5.051,1108,4.135,1183,4.848,1184,5.911]],["title/getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline",[6,0.708,322,1.534,744,1.708,948,1.247,1106,1.504]],["text/getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline",[5,0.482,6,2.194,28,1.672,38,2.686,41,1.981,45,2.546,47,2.443,66,2.357,69,2.208,76,3.624,79,2.805,93,1.622,98,1.704,106,1.259,110,1.672,125,1.103,126,0.785,127,0.378,136,0.353,138,1.692,139,1.692,140,1.036,165,1.89,195,1.036,201,2.018,228,1.584,294,2.086,306,1.849,308,1.849,367,1.148,368,2.445,431,1.644,434,2.086,446,1.672,485,2.031,509,2.017,510,2.09,532,2.144,586,2.281,612,1.737,629,2.546,633,2.086,636,1.934,645,2.805,656,3.002,710,2.144,715,2.546,738,2.279,744,1.934,752,2.445,764,2.208,806,1.89,807,2.086,813,2.144,824,2.805,914,4.242,939,3.023,948,2.884,949,2.546,1063,2.357,1065,3.177,1109,4.345,1120,4.25,1125,2.546,1128,2.144,1130,2.445,1137,2.357,1185,2.546,1186,2.663,1187,5.196,1188,5.888,1189,6.569,1190,4.877,1191,3.218,1192,3.218,1193,2.546,1194,3.218,1195,3.218,1196,3.218,1197,3.218,1198,3.218,1199,2.805,1200,3.218,1201,3.858,1202,2.805,1203,3.218,1204,3.218,1205,2.546]],["title/getting_started/image_augmentation/#step-3-read-images-from-the-disk",[5,0.165,323,1.565,969,1.669,1106,1.504,1108,1.841]],["text/getting_started/image_augmentation/#step-3-read-images-from-the-disk",[1,2.332,5,0.536,6,1.483,7,2.587,9,1.972,47,2.982,49,2.542,93,1.565,154,2.197,155,3.336,164,2.484,191,3.685,223,3.345,328,2.603,381,4.048,387,3.153,388,2.603,390,4.097,401,2.818,419,2.994,431,1.181,434,2.74,473,3.967,580,4.984,881,5.189,883,5.189,885,5.189,939,1.946,948,2.614,969,4.394,1052,3.685,1067,3.213,1074,4.71,1095,3.967,1104,3.421,1107,3.421,1108,3.859,1109,2.603,1118,3.345,1137,3.097,1159,3.345,1160,3.345,1161,3.345,1162,3.345,1168,3.213,1206,5.955,1207,4.71,1208,4.229,1209,3.685,1210,4.229,1211,4.229,1212,3.685,1213,4.229,1214,4.229]],["title/getting_started/image_augmentation/#pillow",[391,4.075]],["text/getting_started/image_augmentation/#pillow",[1,1.893,5,0.516,7,2.1,16,3.626,47,2.802,49,4.776,91,4.251,93,1.586,154,3.736,328,3.444,388,4.892,389,4.098,391,6.287,401,5.916,484,3.532,969,3.286,1095,3.728,1104,3.214,1107,4.565,1184,5.184,1215,7.191,1216,7.191,1217,5.595]],["title/getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images",[5,0.185,6,0.791,350,1.161,939,0.868,948,0.828,1106,0.999,1109,1.161]],["text/getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images",[5,0.545,6,2.008,19,2.079,31,2.132,43,1.899,47,3.036,76,2.079,93,1.666,97,1.94,98,3.21,106,1.48,110,2.627,126,0.675,140,1.088,146,1.629,158,1.824,197,1.396,221,1.824,225,1.607,242,1.94,250,2.366,294,2.189,322,1.824,367,0.795,431,1.412,435,1.984,509,1.445,510,1,532,2.251,533,2.079,537,1.58,612,2.73,616,2.318,617,2.474,656,2.079,681,1.755,738,4.292,807,2.189,808,5.283,809,5.283,811,4.001,847,2.795,886,2.944,914,2.03,922,3.039,939,2.79,948,1.483,959,2.474,1065,1.634,1106,1.788,1128,2.251,1130,2.566,1173,2.318,1176,2.566,1183,2.566,1185,2.672,1186,5.57,1218,3.378,1219,3.378,1220,3.378,1221,3.378,1222,5.57,1223,3.378,1224,3.378,1225,3.378,1226,3.378,1227,3.378]],["title/getting_started/installation/",[49,3.458]],["text/getting_started/installation/",[1,2.681,49,5.457,66,4.785,68,5.694,91,6.019,136,0.717,484,4.124,485,5,1228,6.533,1229,5.694,1230,7.339,1231,6.533,1232,6.533,1233,7.339,1234,6.533,1235,6.533,1236,6.533]],["title/getting_started/installation/#installation",[49,3.458]],["text/getting_started/installation/#installation",[1,2.529,136,0.82,484,4.717,1228,7.473,1229,6.513]],["title/getting_started/installation/#install-the-latest-stable-version-from-pypi",[49,1.708,485,1.793,1230,2.632,1231,2.841,1232,2.841]],["text/getting_started/installation/#install-the-latest-stable-version-from-pypi",[1,2.546,49,4.522,91,5.717,1233,6.971]],["title/getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github",[49,1.516,66,1.847,485,1.592,1230,2.336,1234,2.522,1235,2.522]],["text/getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github",[49,4.491,68,6.513,91,5.678,1233,6.923,1236,7.473]],["title/getting_started/mask_augmentation/",[6,0.947,37,2.014,50,1.167]],["text/getting_started/mask_augmentation/",[1,1.741,5,0.526,6,2.045,7,1.66,9,1.166,24,1.317,34,1.284,35,1.149,36,2.302,37,3.018,38,1.903,43,2.893,45,0.902,47,2.577,50,2.817,76,1.284,84,1.818,93,1.661,106,1.265,125,1.184,126,0.232,136,0.379,138,1.535,139,1.535,140,0.672,145,0.794,146,1.425,154,1.084,155,0.93,158,2.388,165,1.225,185,0.889,195,0.672,197,0.576,199,0.992,201,1.184,221,1.865,225,0.992,250,0.976,280,1.39,309,1.317,322,1.865,323,1.149,337,1.585,350,1.284,388,1.284,401,2.302,419,1.477,431,1.235,435,2.03,509,0.988,517,1.65,518,1.818,580,4.535,586,2.406,612,1.865,629,1.65,681,2.672,710,1.39,744,2.077,745,2.447,764,1.431,806,1.225,807,1.352,813,1.39,856,1.818,861,2.447,914,1.254,922,1.254,939,2.624,948,2.259,959,1.528,969,3.348,1060,1.585,1065,1.009,1066,2.598,1082,1.818,1089,1.818,1098,1.431,1104,1.198,1106,3.018,1107,2.955,1108,2.239,1109,2.723,1128,2.302,1133,3.011,1159,4.51,1160,1.65,1161,1.65,1162,1.65,1163,1.65,1168,1.585,1176,2.625,1186,1.726,1187,2.734,1237,2.086,1238,1.65,1239,2.086,1240,2.086,1241,2.086,1242,2.086,1243,1.818,1244,3.456,1245,2.086,1246,3.456,1247,2.086,1248,3.456,1249,2.086,1250,2.086,1251,1.818,1252,2.086,1253,2.086,1254,3.456,1255,1.818,1256,3.011,1257,1.65,1258,1.818,1259,1.818,1260,2.086]],["title/getting_started/mask_augmentation/#mask-augmentation-for-segmentation",[6,0.947,37,2.014,50,1.167]],["text/getting_started/mask_augmentation/#mask-augmentation-for-segmentation",[1,1.865,5,0.523,6,2.241,7,2.068,34,3.392,36,3.671,37,2.917,38,3.035,47,2.76,50,2.713,93,0.956,126,0.613,136,0.605,158,3.844,165,3.236,221,3.844,225,2.621,309,3.478,419,3.902,431,1.988,586,3.331,681,3.699,744,3.312,939,2.536,948,3.126,969,3.236,1089,4.802,1104,3.165,1107,3.165,1108,3.571,1109,4.383,1237,5.51,1238,4.359]],["title/getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline",[6,0.47,7,0.708,136,0.207,146,0.607,322,1.018,744,1.134,948,0.828,1106,0.999,1107,1.084]],["text/getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline",[1,1.933,5,0.424,6,1.815,24,3.606,35,3.146,50,1.753,93,1.674,106,0.968,138,1.983,139,1.983,146,1.84,195,1.84,322,3.084,509,2.083,580,3.806,681,2.968,710,3.806,806,3.355,807,3.702,813,3.806,914,3.433,1106,3.858,1107,4.186,1187,5.764,1239,5.712,1240,5.712,1241,5.712]],["title/getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk",[5,0.147,50,0.774,323,1.389,969,1.481,1106,1.335,1108,1.634]],["text/getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk",[1,1.972,5,0.484,6,1.021,7,1.539,9,1.536,36,2.733,37,3.085,38,2.259,43,2.306,47,2.919,50,2.658,76,2.525,84,3.574,93,1.667,138,2.022,139,2.022,154,2.131,155,1.829,185,1.747,197,1.132,201,1.406,280,2.733,337,3.116,388,2.525,401,3.883,435,2.409,518,3.574,580,5.551,586,1.919,629,3.245,681,2.131,745,4.126,764,2.814,856,3.574,861,2.904,969,3.981,1065,1.984,1066,3.423,1082,3.574,1159,6.166,1160,3.245,1161,3.245,1162,3.245,1163,3.245,1168,3.116,1242,4.102,1243,3.574,1244,5.827,1245,4.102,1246,5.827,1247,4.102,1248,5.827,1249,4.102,1250,4.102,1251,3.574,1252,4.102,1253,4.102]],["title/getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks",[5,0.162,6,0.693,50,0.854,350,0.994,939,0.743,948,0.709,1106,0.855,1109,0.994]],["text/getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks",[5,0.534,6,1.702,9,1.098,37,2.205,43,3.843,45,1.801,47,2.086,50,2.882,93,1.655,106,1.493,125,2.019,140,1.341,145,1.584,146,1.341,158,2.248,199,1.981,201,1.427,250,1.948,431,1.163,435,2.446,517,3.294,586,1.948,612,3.18,861,2.949,922,2.503,939,3.146,959,3.05,1060,3.164,1066,2.446,1098,2.857,1128,3.925,1133,5.133,1176,4.475,1186,3.446,1254,5.89,1255,3.629,1256,5.133,1257,3.294,1258,3.629,1259,3.629,1260,4.164]],["title/introduction/image_augmentation/",[5,0.132,6,0.565,11,1.363,26,1.249,27,1.275,28,1.178,46,1.723]],["text/introduction/image_augmentation/",[1,0.694,5,0.511,6,2.037,7,0.77,9,1.606,11,3.394,19,3.751,24,1.294,26,3.356,27,3.426,28,2.934,29,1.697,30,2.495,32,2.27,33,2.412,34,3.133,35,1.877,36,1.366,37,1.804,38,1.13,39,2.151,40,2.097,45,1.473,46,4.291,47,3.234,51,0.579,52,0.607,76,2.69,93,0.758,97,3.5,98,1.086,106,0.741,112,1.107,125,1.498,136,0.559,146,0.66,163,1.622,170,1.558,179,1.178,188,1.407,199,2.421,208,2.695,221,1.107,225,3.215,226,0.975,228,1.677,237,2.69,239,1.502,240,3.846,249,1.407,250,0.959,261,1.204,264,1.262,308,1.178,312,1.233,358,2.999,364,2.412,367,0.483,373,3.201,381,1.204,387,1.086,399,1.622,404,1.452,410,2.695,424,1.558,431,0.573,435,1.204,515,1.294,566,1.452,575,1.622,585,1.233,586,1.594,604,1.787,616,3.493,633,1.329,636,1.233,640,3.176,642,1.558,747,1.366,799,1.697,845,2.27,868,1.787,948,0.9,985,1.787,1061,1.622,1065,2.732,1066,2.567,1095,1.366,1098,1.407,1104,1.957,1110,2.412,1117,1.558,1119,1.622,1126,1.787,1172,2.999,1183,1.558,1187,2.695,1193,2.695,1199,1.787,1201,1.622,1207,3.457,1212,1.787,1229,1.787,1238,3.457,1243,3.809,1251,1.787,1257,1.622,1261,5.374,1262,4.37,1263,2.051,1264,1.787,1265,2.82,1266,2.051,1267,3.407,1268,3.407,1269,3.407,1270,2.051,1271,2.051,1272,2.969,1273,2.969,1274,2.051,1275,2.051,1276,2.051,1277,2.051,1278,2.051,1279,2.051,1280,2.051,1281,2.051,1282,3.407,1283,2.051,1284,2.051,1285,2.051,1286,3.156,1287,2.051,1288,2.051,1289,2.051,1290,3.407,1291,2.051,1292,2.051,1293,2.051,1294,2.051,1295,2.051,1296,2.051,1297,2.051,1298,2.051,1299,2.051,1300,1.697,1301,2.051,1302,2.82,1303,5.09,1304,3.407,1305,3.407,1306,5.627,1307,2.051,1308,2.051,1309,3.407,1310,2.051,1311,2.051,1312,2.051,1313,2.051,1314,4.37,1315,2.051,1316,2.051,1317,2.051,1318,2.051,1319,4.37,1320,2.051,1321,2.969,1322,2.051,1323,2.051,1324,3.407,1325,2.051,1326,2.051,1327,2.051,1328,2.051,1329,2.051,1330,2.051,1331,3.407,1332,2.051,1333,2.051,1334,2.051,1335,2.051,1336,2.051,1337,2.051,1338,2.051,1339,1.787,1340,1.787,1341,1.622,1342,2.051]],["title/introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks",[5,0.132,6,0.565,11,1.363,26,1.249,27,1.275,28,1.178,46,1.723]],["text/introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks",[5,0.494,11,2.438,26,2.234,27,2.281,29,3.357,34,4.147,35,2.234,36,2.702,37,2.147,39,2.845,40,2.497,45,2.5,47,4.159,51,1.146,52,1.201,97,3.321,112,2.19,125,1.39,136,0.806,199,3.492,208,4.573,221,2.19,237,2.497,250,1.897,264,2.497,312,2.438,373,2.97,431,1.133,435,2.382,616,2.783,633,2.628,636,2.438,640,4.364,1065,3.258,1066,2.382,1104,2.33,1117,3.081,1183,3.081,1207,5.329,1212,3.535,1238,5.329,1243,5.87,1257,3.208,1261,5.713,1262,6.736,1263,4.056,1264,3.535,1265,3.357,1266,4.056,1267,5.781,1268,5.781,1269,5.781,1270,4.056,1271,4.056,1272,5.038,1273,5.038,1274,4.056,1275,4.056,1276,4.056,1277,4.056,1278,4.056,1279,4.056,1280,4.056,1281,4.056,1282,5.781,1283,4.056,1284,4.056,1285,4.056,1286,3.758,1287,4.056,1288,4.056,1289,4.056,1290,5.781,1291,4.056,1292,4.056,1293,4.056,1294,4.056]],["title/introduction/image_augmentation/#image-augmentation-to-the-rescue",[5,0.221,6,0.947,1295,3.804]],["text/introduction/image_augmentation/#image-augmentation-to-the-rescue",[5,0.516,6,1.393,19,5.466,38,3.082,76,4.892,97,4.565,98,2.962,106,1.219,237,3.444,240,5.476,367,1.317,586,3.364,616,5.452,747,3.728,868,4.876,985,4.876,1065,3.478,1066,3.286,1104,3.214,1110,3.962,1126,4.876,1261,5.938,1296,5.595,1297,5.595,1298,5.595,1299,5.595,1300,4.63,1301,5.595]],["title/introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks",[5,0.11,6,0.47,11,1.134,26,1.039,27,1.061,28,0.98,46,1.433,249,1.294,575,1.492]],["text/introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks",[1,1.115,5,0.485,6,2.164,7,1.237,9,1.976,11,2.984,24,2.081,26,3.29,27,3.359,28,3.103,30,3.637,32,3.308,33,3.516,34,2.029,35,1.815,37,1.745,39,1.622,40,2.029,46,4.539,93,1.036,97,1.893,106,0.559,125,1.702,146,1.061,163,2.607,170,2.504,179,1.893,188,2.262,225,3.808,226,1.568,228,2.444,237,2.029,239,2.414,240,2.081,261,1.936,308,1.893,358,4.099,364,3.516,373,3.637,381,1.936,387,1.745,399,2.607,404,2.334,410,3.928,424,2.504,515,2.081,566,2.334,585,1.981,604,2.872,642,2.504,799,2.728,845,3.308,948,1.447,1061,2.607,1066,1.936,1095,2.196,1098,2.262,1110,2.334,1119,2.607,1172,4.099,1187,3.928,1193,3.928,1199,2.872,1201,2.607,1229,2.872,1251,2.872,1261,3.516,1265,2.728,1286,3.054,1302,4.109,1303,6.649,1304,4.965,1305,4.965,1306,6.779,1307,3.296,1308,3.296,1309,4.965,1310,3.296,1311,3.296,1312,3.296,1313,3.296,1314,5.974,1315,3.296,1316,3.296,1317,3.296,1318,3.296,1319,5.974,1320,3.296,1321,4.327,1322,3.296,1323,3.296,1324,4.965,1325,3.296,1326,3.296,1327,3.296,1328,3.296,1329,3.296,1330,3.296,1331,4.965,1332,3.296,1333,3.296,1334,3.296,1335,3.296,1336,3.296,1337,3.296,1338,3.296,1339,2.872,1340,2.872,1341,2.607,1342,3.296]],["title/introduction/why_albumentations/",[1,1.947]],["text/introduction/why_albumentations/",[1,2.75,5,0.413,6,1.879,7,2.428,8,3.29,9,1.705,10,3.29,11,2.269,12,4.784,13,3.29,14,3.29,15,3.29,16,3.558,17,4.193,18,3.29,19,2.324,28,3.69,31,3.465,32,3.658,33,3.887,34,2.324,35,2.079,36,2.515,37,2.907,38,2.079,39,1.858,40,2.324,50,1.158,51,1.066,52,1.118,64,2.986,66,2.765,69,2.59,70,4.343,87,2.59,93,1.309,96,4.581,106,0.93,107,4.193,110,1.961,112,2.964,149,1.999,221,2.038,223,2.986,225,1.796,261,2.217,293,2.59,328,2.324,337,2.868,364,2.673,376,4.784,390,1.891,401,2.515,431,1.054,434,3.558,474,2.986,537,3.026,640,3.638,747,2.515,764,2.59,922,2.269,948,2.411,1067,2.868,1095,2.515,1104,2.169,1172,2.59,1173,2.59,1174,2.986,1193,2.986,1205,2.986,1209,3.29,1261,2.673,1306,3.29,1321,3.29,1339,3.29,1340,3.29,1341,2.986,1343,3.775,1344,3.775,1345,3.775,1346,5.49,1347,3.775,1348,3.775,1349,3.775,1350,3.775,1351,5.086,1352,3.124,1353,4.543,1354,3.775,1355,3.29,1356,3.29,1357,3.29,1358,3.29,1359,3.29,1360,3.29,1361,3.29,1362,3.29,1363,3.775,1364,3.775]],["title/introduction/why_albumentations/#why-albumentations",[1,1.947]],["text/introduction/why_albumentations/#why-albumentations",[]],["title/introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points",[5,0.11,50,0.579,51,0.533,52,0.558,107,1.222,112,1.018,293,1.294,537,0.882,922,1.134]],["text/introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points",[1,2.293,31,4.278,32,4.515,33,4.798,34,4.172,35,3.733,36,4.515,37,4.287,38,3.733,39,3.335,40,4.172,107,4.392,112,3.658,337,5.149,537,3.17,747,4.515,1172,4.65,1343,6.777,1344,6.777]],["title/introduction/why_albumentations/#battle-tested",[96,3.243,1345,4.58]],["text/introduction/why_albumentations/#battle-tested",[7,2.592,8,6.018,9,1.82,10,6.018,11,4.15,12,7.137,13,6.018,14,6.018,15,6.018,16,4.475,17,4.475,18,6.018,93,1.566]],["title/introduction/why_albumentations/#high-performance",[28,2.379,474,3.623]],["text/introduction/why_albumentations/#high-performance",[1,2.614,5,0.449,6,1.561,7,2.9,9,1.653,28,4.013,106,1.063,110,3.257,149,3.32,223,4.96,364,4.44,376,6.733,390,3.141,401,4.178,640,3.526,764,4.303,1067,4.764,1095,4.178,1104,3.602,1174,4.96,1193,4.96,1209,5.465,1340,5.465,1346,7.726,1347,6.271,1348,6.271,1349,6.271]],["title/introduction/why_albumentations/#diverse-set-of-supported-augmentations",[6,0.81,225,1.547,434,2.108,1339,2.835]],["text/introduction/why_albumentations/#diverse-set-of-supported-augmentations",[1,2.495,5,0.429,6,1.836,31,4.653,221,3.98,434,4.777,1350,7.372]],["title/introduction/why_albumentations/#extensibility",[1351,5.331]],["text/introduction/why_albumentations/#extensibility",[1,2.352,6,1.731,9,1.832,19,4.278,32,4.63,33,4.921,106,1.178,107,4.504,261,4.082,328,4.278,537,3.251,948,3.051,1205,5.497,1352,5.751,1353,5.751,1354,6.95]],["title/introduction/why_albumentations/#rigorous-testing",[96,3.243,1355,3.992]],["text/introduction/why_albumentations/#rigorous-testing",[1,2.224,6,1.637,28,3.414,64,5.199,70,6.289,96,4.654,431,1.835,640,4.471,948,2.886,1173,4.51,1261,4.654,1306,5.728,1321,5.728,1341,5.199,1351,6.089,1353,5.439,1356,5.728,1357,5.728,1358,5.728,1359,5.728,1360,5.728,1361,5.728,1362,5.728]],["title/introduction/why_albumentations/#it-is-open-source-and-mit-licensed",[16,2.108,17,2.108,1363,3.253,1364,3.253]],["text/introduction/why_albumentations/#it-is-open-source-and-mit-licensed",[17,4.843,66,5.473,69,5.128,87,5.128,93,1.296]],["title/introduction/why_you_need_a_dedicated_library_for_image_augmentation/",[5,0.165,6,0.708,7,1.066,47,1.423,48,2.351]],["text/introduction/why_you_need_a_dedicated_library_for_image_augmentation/",[1,1.141,5,0.52,6,2.141,7,2.273,9,1.066,16,0.938,26,1.393,27,1.423,28,0.752,34,2.075,35,0.797,36,0.964,37,1.785,39,1.659,40,2.075,43,1.423,45,0.626,47,3.269,48,1.197,50,1.858,51,1.142,52,1.197,64,2.001,69,0.993,70,2.001,87,0.993,93,1.523,96,1.791,97,1.453,98,3.653,106,1.243,107,1.64,112,0.781,114,0.536,125,1.977,126,0.45,128,0.177,136,0.159,145,0.55,146,0.466,155,0.645,158,3.269,164,0.85,165,1.486,173,0.645,175,1.025,179,1.453,185,1.722,195,0.466,197,0.93,199,2.88,201,0.496,211,0.913,221,0.781,225,1.603,226,2.402,227,1.145,237,1.557,240,2.552,249,0.993,250,1.577,280,3.06,294,3.273,306,0.831,308,0.831,309,3.432,312,0.87,315,0.814,316,1.98,327,1.099,357,1.099,358,0.993,367,1.624,379,1.025,381,0.85,389,1.06,391,1.025,415,1.34,431,1.878,439,5.219,446,0.752,477,1.197,482,2.094,484,0.913,509,0.723,510,1.708,515,2.552,517,1.145,522,0.781,532,2.246,533,0.891,537,1.184,566,1.791,606,1.261,609,2.79,636,0.87,640,1.423,681,2.824,710,0.964,717,2.79,724,1.06,738,1.025,743,1.261,747,1.686,752,1.922,764,0.993,807,0.938,811,2.667,813,0.964,858,1.145,894,1.261,914,0.87,915,2.205,948,2.387,962,1.197,965,1.099,966,1.099,974,1.853,1008,1.197,1060,1.099,1061,1.145,1063,1.06,1064,1.099,1065,1.956,1066,2.697,1069,2.863,1095,0.964,1098,2.774,1104,0.831,1107,1.453,1109,0.891,1110,2.387,1111,1.853,1116,1.197,1117,1.099,1119,1.145,1123,4.002,1124,1.197,1125,1.145,1128,0.964,1163,1.145,1170,2.094,1172,4.155,1173,2.774,1174,1.145,1183,1.099,1185,2.001,1201,1.145,1202,2.205,1205,1.145,1207,2.001,1222,3.801,1238,2.001,1255,1.261,1256,2.205,1257,2.001,1258,1.261,1259,1.261,1261,2.863,1264,1.261,1265,1.197,1272,1.261,1273,2.205,1300,2.79,1302,2.094,1341,1.145,1352,2.094,1353,1.197,1355,1.261,1356,1.261,1357,1.261,1358,1.261,1359,2.205,1360,1.261,1361,1.261,1362,1.261,1365,1.447,1366,2.53,1367,2.53,1368,1.447,1369,1.447,1370,1.447,1371,1.447,1372,2.53,1373,1.447,1374,1.447,1375,1.447,1376,1.447,1377,1.447,1378,1.447,1379,2.53,1380,1.447,1381,1.447,1382,1.447,1383,1.447,1384,1.447,1385,1.447,1386,1.447,1387,1.447,1388,1.447,1389,1.447,1390,1.447,1391,1.447,1392,1.447,1393,1.447,1394,2.53,1395,1.447,1396,1.447,1397,2.53,1398,1.447,1399,2.53,1400,2.53,1401,1.447,1402,1.447,1403,1.447,1404,1.447,1405,1.447,1406,1.447]],["title/introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation",[5,0.165,6,0.708,7,1.066,47,1.423,48,2.351]],["text/introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation",[1,1.477,5,0.532,6,1.987,7,2.847,9,1.15,16,2.828,93,1.655,97,2.507,98,2.311,106,1.032,165,2.563,201,1.496,226,2.076,294,3.945,315,2.454,316,2.563,327,3.316,367,1.027,389,3.196,391,3.09,484,2.755,532,2.908,533,2.686,566,3.09,606,3.803,747,2.908,764,2.995,894,3.803,915,5.305,974,3.196,1065,2.111,1095,2.908,1098,2.995,1104,2.507,1107,2.507,1110,4.31,1119,3.452,1172,4.177,1183,3.316,1207,4.815,1238,4.815,1300,3.612,1302,3.612,1365,4.364,1366,6.088,1367,6.088,1368,4.364,1369,4.364,1370,4.364,1371,4.364,1372,6.088,1373,4.364,1374,4.364,1375,4.364,1376,4.364,1377,4.364,1378,4.364]],["title/introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks",[5,0.088,34,0.927,37,0.798,39,0.741,40,1.613,47,0.755,106,0.255,114,0.558,199,0.716,367,0.355,681,0.783]],["text/introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks",[1,0.914,5,0.527,6,2.097,9,1.122,34,2.621,35,1.487,36,1.799,37,2.254,39,2.095,40,1.662,43,2.394,45,1.168,47,3.465,50,2.369,51,1.69,52,1.771,93,0.468,98,3.834,106,1.309,125,2.571,126,0.474,128,0.33,145,1.027,146,0.87,158,4.169,164,1.586,165,1.586,179,1.551,185,2.549,197,1.175,199,3.569,225,1.284,226,2.507,237,2.621,240,1.705,250,1.263,280,1.799,294,3.416,309,4.57,316,2.501,357,2.052,367,1.704,379,1.912,381,1.586,431,2.156,439,6.542,477,2.235,515,3.327,517,2.136,532,1.799,640,1.519,681,3.594,752,3.235,811,4.17,858,2.136,974,1.978,1060,2.052,1063,1.978,1064,2.052,1065,2.06,1066,3.096,1069,4.237,1098,3.617,1116,2.235,1117,2.052,1123,5.674,1124,2.235,1128,1.799,1172,4.106,1173,1.853,1174,2.136,1202,3.711,1255,2.353,1256,3.711,1257,3.368,1258,2.353,1259,2.353,1272,2.353,1273,3.711,1300,3.524,1360,2.353,1379,4.258,1380,2.701,1381,2.701,1382,2.701,1383,2.701,1384,2.701,1385,2.701,1386,2.701,1387,2.701,1388,2.701,1389,2.701,1390,2.701,1391,2.701,1392,2.701]],["title/introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities",[112,2.473,510,1.356]],["text/introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities",[5,0.489,6,2.231,7,1.905,26,2.795,27,2.853,47,3.796,97,2.915,98,4.012,106,0.86,136,0.557,197,1.401,211,3.203,221,2.74,225,2.414,240,4.783,249,3.482,250,3.156,280,4.495,312,3.05,367,1.784,415,4.701,510,2.391,609,4.2,717,4.2,724,3.717,738,3.593,948,2.228,1066,3.962,1173,3.482,1185,4.014,1201,4.014,1222,6.684,1261,4.777,1264,4.422,1265,4.2,1302,4.2,1352,4.2,1393,5.075,1394,6.746,1395,5.075,1396,5.075,1397,6.746,1398,5.075]],["title/introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface",[6,0.628,107,1.634,482,2.087,948,1.107,1111,1.847,1170,2.087]],["text/introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface",[1,1.564,5,0.42,6,1.936,7,2.378,9,1.219,93,1.625,98,3.354,106,1.225,107,2.996,126,0.705,155,2.061,173,2.061,175,3.273,195,1.489,225,2.199,226,3.013,227,3.657,280,3.08,294,2.996,306,2.656,308,2.656,367,1.088,431,1.291,446,2.402,482,3.826,509,1.811,510,2.14,515,2.918,522,2.496,532,3.08,537,2.963,566,3.273,636,2.778,710,3.08,717,5.243,747,3.08,807,2.996,813,3.08,914,2.778,948,3.173,962,3.826,965,3.512,966,3.512,1008,3.826,1061,3.657,1065,2.236,1107,2.656,1110,3.273,1111,3.386,1163,3.657,1170,3.826,1172,4.959,1185,3.657,1205,3.657,1222,3.826,1352,3.826,1399,6.335,1400,6.335]],["title/introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing",[96,3.243,1355,3.992]],["text/introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing",[6,1.845,7,2.202,26,3.231,27,3.298,28,3.047,64,5.862,69,4.025,70,5.862,87,4.025,96,4.153,179,3.37,280,3.908,358,4.025,431,2.069,609,6.133,640,3.298,743,5.112,948,3.254,1109,3.611,1125,4.64,1173,5.085,1261,5.247,1341,4.64,1353,4.855,1356,5.112,1357,5.112,1358,5.112,1359,6.458,1361,5.112,1362,5.112,1401,5.866,1402,5.866,1403,5.866,1404,5.866,1405,5.866,1406,5.866]]],"fields":["title","text"],"invertedIndex":[["",{"_index":93,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/serialization/":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensorV2":{},"contributing/":{},"contributing/#contributing":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{},"introduction/why_albumentations/#it-is-open-source-and-mit-licensed":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["0",{"_index":145,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["0,0",{"_index":698,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["0.0",{"_index":215,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["0.01",{"_index":1006,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{}},"title":{}}],["0.03",{"_index":675,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["0.05",{"_index":177,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["0.0625",{"_index":892,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["0.07",{"_index":178,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{}},"title":{}}],["0.1",{"_index":176,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["0.15",{"_index":192,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{}},"title":{}}],["0.153125",{"_index":1091,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{}},"title":{}}],["0.2",{"_index":806,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}},"title":{}}],["0.24375",{"_index":1103,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["0.27",{"_index":193,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{}},"title":{}}],["0.3",{"_index":175,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["0.4",{"_index":910,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["0.4046875",{"_index":1100,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["0.5",{"_index":195,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["0.503125",{"_index":1102,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["0.64609375",{"_index":1101,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["0.65625",{"_index":1092,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{}},"title":{}}],["0.67",{"_index":194,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{}},"title":{}}],["0.7",{"_index":1019,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{}},"title":{}}],["0.71875",{"_index":1093,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{}},"title":{}}],["0.9",{"_index":780,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{}},"title":{}}],["0.9625",{"_index":1094,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{}},"title":{}}],["04",{"_index":624,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["0;1",{"_index":1014,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["0;3",{"_index":449,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{}},"title":{}}],["1",{"_index":146,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}}}],["1.0",{"_index":242,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["1.1",{"_index":781,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{}},"title":{}}],["1.5",{"_index":1375,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["10",{"_index":415,"text":{"api_reference/augmentations/functional/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["10.0",{"_index":654,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{}},"title":{}}],["100",{"_index":724,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["1024",{"_index":1121,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["117",{"_index":1073,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["12",{"_index":168,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["120",{"_index":825,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{}},"title":{}}],["127",{"_index":902,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{}},"title":{}}],["128",{"_index":487,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{}},"title":{}}],["150",{"_index":169,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["161",{"_index":1148,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["17",{"_index":1153,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{}},"title":{}}],["18",{"_index":1152,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{}},"title":{}}],["180",{"_index":631,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{}},"title":{}}],["2",{"_index":322,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}},"title":{"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}}}],["2**8",{"_index":787,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{}},"title":{}}],["2.you",{"_index":1157,"text":{"getting_started/bounding_boxes_augmentation/":{}},"title":{"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{}}}],["20",{"_index":715,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["200",{"_index":170,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["2003",{"_index":374,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["2018",{"_index":1316,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["212",{"_index":172,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["224",{"_index":1309,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["23",{"_index":1141,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["247",{"_index":171,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["252",{"_index":1147,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["255",{"_index":405,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["256",{"_index":1187,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["29",{"_index":625,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["294",{"_index":1146,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["295",{"_index":1143,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["2x",{"_index":607,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["3",{"_index":323,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/image_augmentation/":{},"getting_started/mask_augmentation/":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}}}],["3.5",{"_index":1228,"text":{"getting_started/installation/":{},"getting_started/installation/#installation":{}},"title":{}}],["30",{"_index":717,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["322",{"_index":1072,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["333",{"_index":1149,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["345",{"_index":1087,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{}},"title":{}}],["345px",{"_index":1076,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["360",{"_index":735,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}},"title":{}}],["365",{"_index":1099,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["37",{"_index":1154,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{}},"title":{}}],["377",{"_index":1145,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["388",{"_index":1144,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["4",{"_index":350,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/image_augmentation/":{},"getting_started/mask_augmentation/":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}}}],["40",{"_index":1398,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["420",{"_index":1086,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["420px",{"_index":1077,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["421",{"_index":1150,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["45",{"_index":894,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["450",{"_index":1112,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["462",{"_index":1088,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["462px",{"_index":1078,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["480",{"_index":1071,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["49",{"_index":1151,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["5",{"_index":563,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["50",{"_index":1201,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["50.0",{"_index":655,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{}},"title":{}}],["512",{"_index":1400,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["512px",{"_index":1399,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["6,190",{"_index":1332,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["6,228",{"_index":1336,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["60",{"_index":1350,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{}},"title":{}}],["640",{"_index":1070,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["7",{"_index":508,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{}},"title":{}}],["74",{"_index":1142,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["76.3",{"_index":1327,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["77.6",{"_index":1328,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["78.5",{"_index":1329,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["8",{"_index":475,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{}},"title":{}}],["80",{"_index":824,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["80.0",{"_index":1330,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["82.2",{"_index":1333,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["82.8",{"_index":1334,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["83.1",{"_index":1337,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["83.5",{"_index":1338,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["90",{"_index":317,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{}},"title":{}}],["97",{"_index":167,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["98",{"_index":1085,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["98px",{"_index":1075,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["_",{"_index":646,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{}},"title":{}}],["_'data",{"_index":647,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{}},"title":{}}],["__init__",{"_index":626,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{}}}],["__new__",{"_index":950,"text":{"api_reference/core/serialization/":{}},"title":{"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__":{}}}],["a.bboxparam",{"_index":1115,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["a.compos",{"_index":1218,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["a.horizontalflip",{"_index":1189,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["a.randombrighntesscontrast",{"_index":1190,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["a.randombrightnesscontrast",{"_index":1223,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["a.randomcrop",{"_index":1188,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["a.randomcrop(width=256",{"_index":1196,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["abov",{"_index":238,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{}},"title":{}}],["absolut",{"_index":891,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["accept",{"_index":438,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}},"title":{}}],["accur",{"_index":955,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__":{}},"title":{}}],["accuraci",{"_index":1325,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["act",{"_index":1395,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["actual",{"_index":1166,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{}}],["ad",{"_index":1001,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"getting_started/bounding_boxes_augmentation/":{}},"title":{"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{}}}],["adapt",{"_index":534,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{}},"title":{}}],["add",{"_index":261,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#extensibility":{}},"title":{}}],["add_fog",{"_index":256,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{}}}],["add_rain",{"_index":268,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{}}}],["add_shadow",{"_index":282,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{}}}],["add_snow",{"_index":285,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{}}}],["add_sun_flar",{"_index":295,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{}}}],["add_target",{"_index":983,"text":{"api_reference/core/transforms_interface/":{}},"title":{"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{}}}],["addit",{"_index":1114,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{}}}],["additional_target",{"_index":920,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{}},"title":{}}],["adjust",{"_index":811,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["advantag",{"_index":1377,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["aerial",{"_index":1256,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["affin",{"_index":889,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["again",{"_index":1219,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["aggress",{"_index":1396,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["albument",{"_index":1,"text":{"":{},"#introduction-to-image-augmentation":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"contributing/":{},"contributing/#contributing":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/installation/":{},"getting_started/installation/#install-the-latest-stable-version-from-pypi":{},"getting_started/installation/#installation":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{},"introduction/why_albumentations/#extensibility":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{"":{},"#getting-started-with-albumentations":{},"#welcome-to-albumentations-documentation":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#why-albumentations":{}}}],["albumentations.augment",{"_index":58,"text":{"":{},"#api-reference":{},"api_reference/":{}},"title":{}}],["albumentations.augmentations.bbox.normalize_bbox",{"_index":210,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{}},"title":{}}],["albumentations.augmentations.bbox_util",{"_index":113,"text":{"api_reference/":{},"api_reference/augmentations/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils":{}}}],["albumentations.augmentations.funct",{"_index":111,"text":{"api_reference/":{},"api_reference/augmentations/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional":{}}}],["albumentations.augmentations.keypoints_util",{"_index":115,"text":{"api_reference/":{},"api_reference/augmentations/":{}},"title":{"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils":{}}}],["albumentations.augmentations.transform",{"_index":109,"text":{"api_reference/":{},"api_reference/augmentations/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms":{}}}],["albumentations.augmentations.transforms.fromfloat",{"_index":899,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{}},"title":{}}],["albumentations.augmentations.transforms.tofloat",{"_index":641,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{}},"title":{}}],["albumentations.cor",{"_index":57,"text":{"":{},"#api-reference":{},"api_reference/":{}},"title":{}}],["albumentations.core.composit",{"_index":103,"text":{"api_reference/":{},"api_reference/core/":{}},"title":{"api_reference/core/composition/#albumentations.core.composition":{}}}],["albumentations.core.seri",{"_index":105,"text":{"api_reference/":{},"api_reference/core/":{}},"title":{"api_reference/core/serialization/#albumentations.core.serialization":{}}}],["albumentations.core.transforms_interfac",{"_index":108,"text":{"api_reference/":{},"api_reference/core/":{}},"title":{"api_reference/core/transforms_interface/#albumentations.core.transforms_interface":{}}}],["albumentations.imgaug",{"_index":61,"text":{"":{},"#api-reference":{},"api_reference/":{}},"title":{}}],["albumentations.imgaug.transform",{"_index":116,"text":{"api_reference/":{},"api_reference/imgaug/":{}},"title":{"api_reference/imgaug/transforms/#albumentations.imgaug.transforms":{}}}],["albumentations.pytorch",{"_index":63,"text":{"":{},"#api-reference":{},"api_reference/":{}},"title":{}}],["albumentations.pytorch.transform",{"_index":117,"text":{"api_reference/":{},"api_reference/pytorch/":{}},"title":{"api_reference/pytorch/transforms/#albumentations.pytorch.transforms":{}}}],["alexnet",{"_index":1307,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["algorithm",{"_index":585,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["allow",{"_index":1352,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#extensibility":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["along",{"_index":328,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#extensibility":{}},"title":{"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{}}}],["alpha",{"_index":267,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{}},"title":{}}],["alpha_affin",{"_index":347,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["alpha_coef",{"_index":259,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{}},"title":{}}],["alreadi",{"_index":1184,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{}},"title":{}}],["alter",{"_index":1311,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["alway",{"_index":561,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}},"title":{}}],["always_appli",{"_index":628,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}},"title":{}}],["amoebanet",{"_index":1331,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["amount",{"_index":868,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}},"title":{}}],["analysi",{"_index":369,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{}},"title":{}}],["angl",{"_index":325,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["angle_in_degre",{"_index":936,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["angle_low",{"_index":875,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["angle_upp",{"_index":876,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["anim",{"_index":1155,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["annot",{"_index":1058,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}}}],["another_imag",{"_index":1221,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["another_transformed_imag",{"_index":1220,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["apertur",{"_index":773,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{}},"title":{}}],["api",{"_index":41,"text":{"":{},"#api-reference":{},"#welcome-to-albumentations-documentation":{},"api_reference/":{},"api_reference/core/":{},"api_reference/core/composition/":{},"api_reference/core/serialization/":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{"#api-reference":{},"api_reference/core/composition/":{},"api_reference/core/composition/#composition-api-corecomposition":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#serialization-api-coreserialization":{}}}],["appear",{"_index":852,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["appli",{"_index":367,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.ImageOnlyTransform":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}}}],["approach",{"_index":1376,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["approxim",{"_index":353,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["area",{"_index":124,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["arg",{"_index":989,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{}},"title":{}}],["argument",{"_index":612,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}},"title":{"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}}}],["around",{"_index":312,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["array",{"_index":388,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["art",{"_index":1305,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["articl",{"_index":21,"text":{"":{},"#welcome-to-albumentations-documentation":{}},"title":{}}],["artifact",{"_index":1013,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["aspect",{"_index":753,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{}},"title":{}}],["assign",{"_index":1272,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["associ",{"_index":1133,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}},"title":{}}],["augment",{"_index":6,"text":{"":{},"#api-reference":{},"#getting-started-with-albumentations":{},"#introduction-to-image-augmentation":{},"#welcome-to-albumentations-documentation":{},"api_reference/":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{},"introduction/why_albumentations/#extensibility":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"#introduction-to-image-augmentation":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation-for-object-detection":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}}}],["augmentations.bbox_util",{"_index":118,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#helper-functions-for-working-with-bounding-boxes-augmentationsbbox_utils":{}}}],["augmentations.funct",{"_index":255,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#functional-transforms-augmentationsfunctional":{}}}],["augmentations.keypoints_util",{"_index":500,"text":{"api_reference/augmentations/keypoints_utils/":{}},"title":{"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#helper-functions-for-working-with-keypoints-augmentationskeypoints_utils":{}}}],["augmentations.transform",{"_index":503,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#transforms-augmentationstransforms":{}}}],["author",{"_index":1251,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["autoaug",{"_index":1319,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["automat",{"_index":1320,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["avail",{"_index":1120,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["averag",{"_index":1044,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["axi",{"_index":313,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["b",{"_index":799,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["b1",{"_index":803,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{}},"title":{}}],["b2",{"_index":804,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{}},"title":{}}],["b_shift_limit",{"_index":884,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{}},"title":{}}],["back",{"_index":577,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{}},"title":{}}],["background",{"_index":562,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{}},"title":{}}],["ball",{"_index":1140,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["barrel",{"_index":460,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["base",{"_index":358,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/core/serialization/":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["basic",{"_index":1302,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["basictransform",{"_index":982,"text":{"api_reference/core/transforms_interface/":{}},"title":{"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform":{}}}],["battl",{"_index":1345,"text":{"introduction/why_albumentations/":{}},"title":{"introduction/why_albumentations/#battle-tested":{}}}],["bbox",{"_index":120,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["bbox_crop",{"_index":303,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{}}}],["bbox_flip",{"_index":304,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{}}}],["bbox_hflip",{"_index":311,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{}}}],["bbox_param",{"_index":917,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["bbox_rot",{"_index":324,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{}}}],["bbox_rot90",{"_index":314,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{}}}],["bbox_transpos",{"_index":326,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{}}}],["bbox_vflip",{"_index":332,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{}}}],["bboxparam",{"_index":908,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}}}],["be",{"_index":1041,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["becam",{"_index":1131,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["becom",{"_index":1124,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["befor",{"_index":861,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}},"title":{}}],["begin",{"_index":1083,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{}},"title":{}}],["belong",{"_index":1258,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["below",{"_index":1132,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["benchmark",{"_index":1349,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["benefici",{"_index":1393,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["besid",{"_index":1118,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["best",{"_index":364,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["better",{"_index":1326,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["between",{"_index":404,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["bgr",{"_index":1213,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["bia",{"_index":996,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["bigger",{"_index":1224,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["bit",{"_index":471,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{}},"title":{}}],["black",{"_index":86,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["bleach",{"_index":288,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}},"title":{}}],["blue",{"_index":885,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["blur",{"_index":504,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{}}}],["blur_limit",{"_index":506,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{}},"title":{}}],["blur_valu",{"_index":273,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["blurri",{"_index":278,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["bool",{"_index":162,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["boolean",{"_index":599,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{}},"title":{}}],["boost",{"_index":25,"text":{"":{},"#welcome-to-albumentations-documentation":{}},"title":{}}],["border",{"_index":794,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{}},"title":{}}],["border_mod",{"_index":349,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["both",{"_index":309,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["bottom",{"_index":186,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["boun",{"_index":1062,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["bound",{"_index":51,"text":{"":{},"#getting-started-with-albumentations":{},"api_reference/":{},"api_reference/augmentations/":{},"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#helper-functions-for-working-with-bounding-boxes-augmentationsbbox_utils":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation-for-object-detection":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{}}}],["boundari",{"_index":143,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoints":{}},"title":{}}],["box",{"_index":52,"text":{"":{},"#getting-started-with-albumentations":{},"api_reference/":{},"api_reference/augmentations/":{},"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#helper-functions-for-working-with-bounding-boxes-augmentationsbbox_utils":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation-for-object-detection":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{}}}],["box'",{"_index":1079,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["branch",{"_index":1235,"text":{"getting_started/installation/":{}},"title":{"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{}}}],["bright",{"_index":294,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["brighter",{"_index":1298,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}},"title":{}}],["brighter_imag",{"_index":1373,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["brightness_by_max",{"_index":810,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{}},"title":{}}],["brightness_coeff",{"_index":287,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}},"title":{}}],["brightness_coeffici",{"_index":274,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["brightness_enhanc",{"_index":1372,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["brightness_limit",{"_index":808,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["broadcast",{"_index":999,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["bug",{"_index":70,"text":{"contributing/":{},"contributing/#contributing":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["buggi",{"_index":1401,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["build",{"_index":1259,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["built",{"_index":1354,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#extensibility":{}},"title":{}}],["by_channel",{"_index":378,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{}},"title":{}}],["c",{"_index":1335,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["c/create_c/make_imagenet_c.pi",{"_index":669,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}},"title":{}}],["calcul",{"_index":123,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["calculate_bbox_area",{"_index":119,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{}}}],["call",{"_index":1186,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}},"title":{}}],["callabl",{"_index":610,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}},"title":{}}],["camera",{"_index":429,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}},"title":{}}],["capabl",{"_index":1308,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["captur",{"_index":1404,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["car",{"_index":1294,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["care",{"_index":1051,"text":{"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["case",{"_index":764,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["cast",{"_index":635,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{}},"title":{}}],["cat",{"_index":1069,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["caus",{"_index":519,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{}},"title":{}}],["ccw",{"_index":319,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{}},"title":{}}],["cell",{"_index":672,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{}},"title":{}}],["center",{"_index":196,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["centercrop",{"_index":513,"text":{"api_reference/augmentations/transforms/":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{}}}],["central",{"_index":514,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{}},"title":{}}],["chahnel",{"_index":770,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{}},"title":{}}],["chang",{"_index":98,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"contributing/":{},"contributing/#contributing":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["channel",{"_index":387,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_channel_dim":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["channel_drop_rang",{"_index":524,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{}},"title":{}}],["channeldropout",{"_index":521,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{}}}],["channelshuffl",{"_index":529,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{}}}],["check",{"_index":142,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoint":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoints":{}},"title":{}}],["check_bbox",{"_index":141,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes":{}}}],["check_keypoint",{"_index":501,"text":{"api_reference/augmentations/keypoints_utils/":{}},"title":{"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoint":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoints":{}}}],["check_valid",{"_index":152,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{}},"title":{}}],["choos",{"_index":525,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{}},"title":{}}],["chosen",{"_index":755,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{}},"title":{}}],["circl",{"_index":300,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["cl",{"_index":951,"text":{"api_reference/core/serialization/":{}},"title":{}}],["clahe",{"_index":531,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{}}}],["class",{"_index":45,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}}}],["class_categori",{"_index":1180,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["class_dict",{"_index":952,"text":{"api_reference/core/serialization/":{}},"title":{}}],["class_label",{"_index":1122,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["classif",{"_index":35,"text":{"":{},"#getting-started-with-albumentations":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"getting_started/image_augmentation/":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{}}}],["clip",{"_index":699,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["clip_limit",{"_index":535,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{}},"title":{}}],["clone",{"_index":80,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["coarsedropout",{"_index":540,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{}}}],["coco",{"_index":159,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{"getting_started/bounding_boxes_augmentation/#coco":{}}}],["code",{"_index":87,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"contributing/":{},"contributing/#contributing":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#it-is-open-source-and-mit-licensed":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["coeffici",{"_index":266,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{}},"title":{}}],["col",{"_index":122,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/keypoints_utils/":{}},"title":{}}],["collect",{"_index":1282,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["color",{"_index":473,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["color_bgr2rgb",{"_index":1162,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["color_shift",{"_index":423,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}},"title":{}}],["colorspac",{"_index":737,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}},"title":{}}],["column",{"_index":905,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["commit",{"_index":83,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["common",{"_index":1067,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["compar",{"_index":1340,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["comparison",{"_index":1323,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["competit",{"_index":15,"text":{"":{},"#welcome-to-albumentations-documentation":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{}},"title":{}}],["complet",{"_index":1034,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["compos",{"_index":914,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"api_reference/core/composition/#albumentations.core.composition.Compose":{}}}],["composit",{"_index":102,"text":{"api_reference/":{},"api_reference/core/":{},"api_reference/core/composition/":{}},"title":{"api_reference/core/composition/":{},"api_reference/core/composition/#composition-api-corecomposition":{}}}],["compress",{"_index":722,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{}},"title":{}}],["compression_typ",{"_index":726,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{}},"title":{}}],["comput",{"_index":32,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_albumentations/#extensibility":{}},"title":{}}],["confer",{"_index":372,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["consist",{"_index":1105,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{}},"title":{}}],["construct",{"_index":967,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{}},"title":{}}],["contain",{"_index":43,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["context",{"_index":1068,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["contrari",{"_index":1391,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["contrast",{"_index":532,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["contrast_limit",{"_index":809,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["contribut",{"_index":54,"text":{"":{},"#other-topics":{},"contributing/":{}},"title":{"contributing/":{},"contributing/#contributing":{}}}],["control",{"_index":738,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["convers",{"_index":518,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["convert",{"_index":154,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensorV2":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["convert_bbox_from_albument",{"_index":150,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{}}}],["convert_bbox_to_albument",{"_index":182,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{}}}],["convert_bboxes_from_albument",{"_index":200,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{}}}],["convert_bboxes_to_albument",{"_index":203,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations":{}}}],["convolut",{"_index":366,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["coord",{"_index":344,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{}},"title":{}}],["coordin",{"_index":185,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoint":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{}}}],["core",{"_index":56,"text":{"":{},"#api-reference":{},"api_reference/":{}},"title":{}}],["core.composit",{"_index":907,"text":{"api_reference/core/composition/":{}},"title":{"api_reference/core/composition/":{},"api_reference/core/composition/#composition-api-corecomposition":{}}}],["core.seri",{"_index":940,"text":{"api_reference/core/serialization/":{}},"title":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#serialization-api-coreserialization":{}}}],["core.transforms_interfac",{"_index":981,"text":{"api_reference/core/transforms_interface/":{}},"title":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#transforms-interface-coretransforms_interface":{}}}],["corner",{"_index":190,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["correct",{"_index":1273,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["correctli",{"_index":1117,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["correspond",{"_index":677,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{}},"title":{}}],["corrupt",{"_index":1357,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["cost",{"_index":1288,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["costli",{"_index":1277,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["count",{"_index":671,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{}},"title":{}}],["creat",{"_index":76,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__":{},"contributing/":{},"contributing/#contributing":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}},"title":{}}],["credit",{"_index":620,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["crop",{"_index":226,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{}}}],["crop_bbox_by_coord",{"_index":333,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{}}}],["crop_coord",{"_index":334,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{}},"title":{}}],["crop_height",{"_index":335,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{}},"title":{}}],["crop_keypoint_by_coord",{"_index":342,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{}}}],["crop_width",{"_index":336,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{}},"title":{}}],["cropnonemptymaskifexist",{"_index":556,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{}}}],["cse",{"_index":1178,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["csv",{"_index":1165,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{}}],["current",{"_index":432,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{}},"title":{}}],["current_left_up_corner_col",{"_index":495,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{}},"title":{}}],["current_left_up_corner_row",{"_index":494,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{}},"title":{}}],["custom",{"_index":1322,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["cut",{"_index":1126,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}},"title":{}}],["cutout",{"_index":568,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}}}],["cv",{"_index":377,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{}},"title":{}}],["cv2",{"_index":580,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}},"title":{}}],["cv2.border_const",{"_index":592,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["cv2.border_reflect",{"_index":594,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["cv2.border_reflect_101",{"_index":596,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["cv2.border_repl",{"_index":593,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["cv2.border_wrap",{"_index":595,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["cv2.cvtcolor",{"_index":1210,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["cv2.inter_area",{"_index":589,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["cv2.inter_cub",{"_index":588,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["cv2.inter_lanczos4",{"_index":590,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["cv2.inter_linear",{"_index":587,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{}},"title":{}}],["cv2.inter_nearest",{"_index":581,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["cvtcolor",{"_index":1161,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["d",{"_index":305,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{}},"title":{}}],["data",{"_index":640,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["data_format",{"_index":964,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{}},"title":{}}],["dataset",{"_index":1066,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["day",{"_index":279,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["deal",{"_index":1384,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["decid",{"_index":1386,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["declar",{"_index":1111,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}}}],["decreas",{"_index":574,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{}},"title":{}}],["dedic",{"_index":48,"text":{"":{},"#introduction-to-image-augmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{}},"title":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}}}],["deep",{"_index":11,"text":{"":{},"#introduction-to-image-augmentation":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{}},"title":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}}}],["defaul",{"_index":786,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{}},"title":{}}],["default",{"_index":130,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["defect",{"_index":760,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{}},"title":{}}],["defin",{"_index":744,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}}}],["definit",{"_index":1170,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}}}],["deform",{"_index":355,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["degrad",{"_index":1361,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["degre",{"_index":318,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["demo",{"_index":1191,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["demo.herokuapp.com",{"_index":1195,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["demonstr",{"_index":1193,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["denorm",{"_index":205,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{}},"title":{}}],["denormalize_bbox",{"_index":204,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{}}}],["depend",{"_index":310,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{}},"title":{}}],["deprec",{"_index":827,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{}},"title":{}}],["describ",{"_index":24,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["descript",{"_index":129,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{}},"title":{}}],["deseri",{"_index":947,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{}},"title":{}}],["desir",{"_index":793,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{}},"title":{}}],["detail",{"_index":1240,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}},"title":{}}],["detect",{"_index":40,"text":{"":{},"#getting-started-with-albumentations":{},"#welcome-to-albumentations-documentation":{},"getting_started/bounding_boxes_augmentation/":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation-for-object-detection":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}}}],["detection/discussion/114254",{"_index":761,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{}},"title":{}}],["determin",{"_index":1026,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["develop",{"_index":64,"text":{"contributing/":{},"contributing/#contributing":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["deviat",{"_index":660,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{}},"title":{}}],["dict",{"_index":921,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["dictionari",{"_index":959,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}},"title":{}}],["differ",{"_index":31,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{}},"title":{"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}}}],["difficult",{"_index":1266,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["dim",{"_index":479,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_channel_dim":{}},"title":{}}],["direct",{"_index":682,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["discov",{"_index":1321,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{}},"title":{}}],["discuss",{"_index":1175,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{}},"title":{}}],["disk",{"_index":1108,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}}}],["displac",{"_index":602,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["distanc",{"_index":663,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{}},"title":{}}],["distort",{"_index":420,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.grid_distortion":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["distort_limit",{"_index":674,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{}},"title":{}}],["distribut",{"_index":617,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["divers",{"_index":1339,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{}},"title":{"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{}}}],["divid",{"_index":244,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{}},"title":{}}],["doc",{"_index":645,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["document",{"_index":2,"text":{"":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{"":{},"#welcome-to-albumentations-documentation":{}}}],["doesn't",{"_index":974,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["dog",{"_index":1138,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["domain",{"_index":1280,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["don't",{"_index":1389,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["done",{"_index":65,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["downscal",{"_index":573,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{}}}],["draw",{"_index":1274,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["drive",{"_index":1293,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["drizzl",{"_index":839,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["drop",{"_index":523,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["drop_color",{"_index":272,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["drop_length",{"_index":270,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["drop_width",{"_index":271,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["dtype",{"_index":637,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{}},"title":{}}],["dualtransform",{"_index":990,"text":{"api_reference/core/transforms_interface/":{}},"title":{"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.DualTransform":{}}}],["dummi",{"_index":478,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_channel_dim":{}},"title":{}}],["dure",{"_index":1173,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["dx",{"_index":458,"text":{"api_reference/augmentations/functional/":{}},"title":{}}],["dy",{"_index":459,"text":{"api_reference/augmentations/functional/":{}},"title":{}}],["e",{"_index":95,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["e.g",{"_index":166,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{}},"title":{}}],["each",{"_index":250,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["easili",{"_index":1353,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#extensibility":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["edg",{"_index":686,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{}},"title":{}}],["effect",{"_index":834,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["efficientnet",{"_index":1315,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["effort",{"_index":1286,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["eigen",{"_index":407,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["elast",{"_index":354,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["elastic_transform",{"_index":345,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{}}}],["elastic_transform_approx",{"_index":375,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{}}}],["elastictransform",{"_index":582,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}}}],["element",{"_index":998,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{}}],["elementwis",{"_index":783,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{}},"title":{}}],["emboss",{"_index":1016,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{}},"title":{}}],["empti",{"_index":558,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{}},"title":{}}],["enabl",{"_index":605,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["encod",{"_index":1082,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["end",{"_index":1084,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{}},"title":{}}],["enhanc",{"_index":1374,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["enough",{"_index":1267,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["ensur",{"_index":1237,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{}},"title":{}}],["enter",{"_index":706,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["enumer",{"_index":730,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression.ImageCompressionType":{}},"title":{}}],["ep",{"_index":826,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{}},"title":{}}],["equal",{"_index":181,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{}}}],["eros",{"_index":252,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{}},"title":{}}],["erosion_r",{"_index":246,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{}},"title":{}}],["estim",{"_index":1344,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{}},"title":{}}],["etc",{"_index":747,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["even",{"_index":1269,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["ex",{"_index":924,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{}},"title":{}}],["exact",{"_index":666,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}},"title":{}}],["exampl",{"_index":1065,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["except",{"_index":179,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["exist",{"_index":985,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}},"title":{}}],["expect",{"_index":1168,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["expens",{"_index":1279,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["expert",{"_index":1281,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["explicitli",{"_index":1214,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["extens",{"_index":1351,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{}},"title":{"introduction/why_albumentations/#extensibility":{}}}],["extra",{"_index":1171,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{}}],["extract",{"_index":1198,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["extrapol",{"_index":591,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["factor",{"_index":315,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["failur",{"_index":1402,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["fals",{"_index":153,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{}},"title":{}}],["fanci",{"_index":396,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{}},"title":{}}],["fancy_pca",{"_index":395,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{}}}],["fancypca",{"_index":614,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}}}],["far",{"_index":1027,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["fashion",{"_index":678,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["fast",{"_index":3,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}},"title":{}}],["feasibl",{"_index":1287,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["featur",{"_index":71,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["few",{"_index":1119,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["field",{"_index":912,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["fight",{"_index":1342,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["file",{"_index":73,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"contributing/":{},"contributing/#contributing":{}},"title":{}}],["filepath",{"_index":963,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{}},"title":{}}],["fill",{"_index":767,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{}},"title":{}}],["fill_valu",{"_index":526,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["filter",{"_index":236,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{}},"title":{}}],["filter_bbox",{"_index":213,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{}}}],["filter_bboxes_by_vis",{"_index":232,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{}}}],["final",{"_index":227,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["find",{"_index":69,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{},"contributing/":{},"contributing/#contributing":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#it-is-open-source-and-mit-licensed":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["first",{"_index":566,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["fishey",{"_index":466,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["fix",{"_index":604,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["flag",{"_index":584,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{}},"title":{}}],["flake8",{"_index":89,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["flare",{"_index":302,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["flare_center_i",{"_index":297,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{}},"title":{}}],["flare_center_x",{"_index":296,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{}},"title":{}}],["flare_roi",{"_index":874,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["flexibl",{"_index":4,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}},"title":{}}],["flip",{"_index":306,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{}}}],["flip_left_right",{"_index":1370,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["float",{"_index":229,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["float32",{"_index":512,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{}},"title":{}}],["fog",{"_index":262,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{}},"title":{}}],["fog_coef",{"_index":258,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{}},"title":{}}],["fog_coef_low",{"_index":819,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{}},"title":{}}],["fog_coef_upp",{"_index":820,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{}},"title":{}}],["follow",{"_index":1074,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["fork",{"_index":78,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["form",{"_index":191,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["format",{"_index":155,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}}}],["formatt",{"_index":88,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["found",{"_index":945,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{}},"title":{}}],["four",{"_index":1021,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{}},"title":{}}],["fraction",{"_index":230,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["from_dict",{"_index":956,"text":{"api_reference/core/serialization/":{}},"title":{"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{}}}],["fromfloat",{"_index":632,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{}}}],["full",{"_index":949,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["func",{"_index":209,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/functional/":{}},"title":{}}],["function",{"_index":110,"text":{"api_reference/":{},"api_reference/augmentations/":{},"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#helper-functions-for-working-with-bounding-boxes-augmentationsbbox_utils":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#functional-transforms-augmentationsfunctional":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#helper-functions-for-working-with-keypoints-augmentationskeypoints_utils":{}}}],["g",{"_index":798,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["g1",{"_index":801,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{}},"title":{}}],["g2",{"_index":802,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{}},"title":{}}],["g_shift_limit",{"_index":882,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{}},"title":{}}],["gamma_limit",{"_index":823,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{}},"title":{}}],["garbag",{"_index":1403,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["gather",{"_index":1271,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["gaussian",{"_index":583,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{}},"title":{}}],["gaussianblur",{"_index":649,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{}}}],["gaussnois",{"_index":651,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{}}}],["gener",{"_index":1005,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["get",{"_index":29,"text":{"":{},"#welcome-to-albumentations-documentation":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{"#getting-started-with-albumentations":{}}}],["git+https://github.com/albument",{"_index":1236,"text":{"getting_started/installation/":{},"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{}},"title":{}}],["github",{"_index":66,"text":{"contributing/":{},"contributing/#contributing":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/installation/":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#it-is-open-source-and-mit-licensed":{}},"title":{"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{}}}],["give",{"_index":606,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["given",{"_index":329,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{}},"title":{}}],["glanc",{"_index":1365,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["glass",{"_index":658,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}},"title":{}}],["glassblur",{"_index":657,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}}}],["go",{"_index":1358,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["goe",{"_index":1204,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["good",{"_index":1263,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["googl",{"_index":1317,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["grayscal",{"_index":382,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{}},"title":{}}],["great",{"_index":1239,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}},"title":{}}],["greater",{"_index":901,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{}},"title":{}}],["green",{"_index":883,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["greyscal",{"_index":489,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{}},"title":{}}],["grid",{"_index":539,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["grid'",{"_index":830,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{}},"title":{}}],["grid.html",{"_index":421,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.grid_distortion":{}},"title":{}}],["grid_distort",{"_index":413,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.grid_distortion":{}}}],["griddistort",{"_index":670,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{}}}],["griddropout",{"_index":676,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}}}],["h",{"_index":402,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{}},"title":{}}],["h_start",{"_index":441,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{}},"title":{}}],["handl",{"_index":915,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["hard",{"_index":1268,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["haze_list",{"_index":260,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{}},"title":{}}],["healthcar",{"_index":1285,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["heavi",{"_index":840,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["height",{"_index":138,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}},"title":{}}],["height//2",{"_index":693,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["height=256",{"_index":1197,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["height_til",{"_index":498,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{}},"title":{}}],["help",{"_index":1341,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["help(typ",{"_index":954,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__":{}},"title":{}}],["helper",{"_index":60,"text":{"":{},"#api-reference":{},"api_reference/":{},"api_reference/augmentations/":{},"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/keypoints_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#helper-functions-for-working-with-bounding-boxes-augmentationsbbox_utils":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#helper-functions-for-working-with-keypoints-augmentationskeypoints_utils":{}}}],["here",{"_index":1110,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["high",{"_index":474,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"introduction/why_albumentations/":{}},"title":{"introduction/why_albumentations/#high-performance":{}}}],["higher",{"_index":1229,"text":{"getting_started/installation/":{},"getting_started/installation/#installation":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["highli",{"_index":1347,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["histogram",{"_index":380,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{}},"title":{}}],["histor",{"_index":1211,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["hl",{"_index":736,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}},"title":{}}],["hole",{"_index":545,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["hole_height",{"_index":703,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["hole_width",{"_index":701,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["holes_number_i",{"_index":688,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["holes_number_x",{"_index":687,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["hood",{"_index":1209,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["hook",{"_index":85,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["horizont",{"_index":308,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["horizontalflip",{"_index":710,"text":{"api_reference/augmentations/transforms/":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{}}}],["http://papers.nips.cc/paper/4824",{"_index":398,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["http://pythology.blogspot.sg/2014/03/interpol",{"_index":418,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.grid_distortion":{}},"title":{}}],["http://www.coldvision.io/2017/03/02/advanc",{"_index":468,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["https://albument",{"_index":1194,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["https://arxiv.org/abs/1708.04552",{"_index":551,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}},"title":{}}],["https://arxiv.org/abs/1903.12261",{"_index":667,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}},"title":{}}],["https://arxiv.org/abs/2001.04086",{"_index":709,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["https://deshanadesai.github.io/notes/f",{"_index":621,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["https://docs.scipy.org/doc/numpy/user/basics.types.html",{"_index":648,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{}},"title":{}}],["https://gist.github.com/erniejunior/601cdf56d2b424757de5",{"_index":359,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["https://github.com/albument",{"_index":67,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["https://github.com/aleju/imgaug/blob/master/imgaug/augmenters/arithmetic.pi",{"_index":554,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}},"title":{}}],["https://github.com/hendrycks/robustness/blob/master/imagenet",{"_index":668,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}},"title":{}}],["https://github.com/ujjwalsaxena/automold",{"_index":263,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["https://github.com/uoguelph",{"_index":552,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}},"title":{}}],["https://pixelatedbrian.github.io/2018",{"_index":623,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["https://stackoverflow.com/questions/10364201/imag",{"_index":464,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["https://stackoverflow.com/questions/2477774/correct",{"_index":465,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["https://stackoverflow.com/questions/6199636/formula",{"_index":463,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["https://www.kaggle.com/c/severst",{"_index":758,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{}},"title":{}}],["hue",{"_index":712,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}},"title":{}}],["hue_shift_limit",{"_index":714,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{}},"title":{}}],["huesaturationvalu",{"_index":711,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{}}}],["i.",{"_index":1043,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["iaaadditivegaussiannois",{"_index":1003,"text":{"api_reference/imgaug/transforms/":{}},"title":{"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{}}}],["iaaaffin",{"_index":1007,"text":{"api_reference/imgaug/transforms/":{}},"title":{"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{}}}],["iaaemboss",{"_index":1015,"text":{"api_reference/imgaug/transforms/":{}},"title":{"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{}}}],["iaaperspect",{"_index":1020,"text":{"api_reference/imgaug/transforms/":{}},"title":{"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{}}}],["iaapiecewiseaffin",{"_index":1025,"text":{"api_reference/imgaug/transforms/":{}},"title":{"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}}}],["iaasharpen",{"_index":1030,"text":{"api_reference/imgaug/transforms/":{}},"title":{"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{}}}],["iaasuperpixel",{"_index":1033,"text":{"api_reference/imgaug/transforms/":{}},"title":{"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}}}],["ignor",{"_index":560,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{}},"title":{}}],["ignore_channel",{"_index":565,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{}},"title":{}}],["ignore_channels=[0",{"_index":567,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{}},"title":{}}],["ignore_valu",{"_index":559,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{}},"title":{}}],["ignore_values=[5",{"_index":564,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{}},"title":{}}],["imag",{"_index":5,"text":{"":{},"#getting-started-with-albumentations":{},"#introduction-to-image-augmentation":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_shape":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoint":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoints":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.ImageOnlyTransform":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensorV2":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"#introduction-to-image-augmentation":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}}}],["image'",{"_index":1024,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{}},"title":{}}],["image.jpg",{"_index":1217,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{}},"title":{}}],["image2",{"_index":925,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{}},"title":{}}],["image_fill_valu",{"_index":763,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{}},"title":{}}],["image_width//10",{"_index":692,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["imagecompress",{"_index":719,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{}}}],["imagecompressiontyp",{"_index":727,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression.ImageCompressionType":{}}}],["imagecompressiontype.jpeg",{"_index":728,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{}},"title":{}}],["imagecompressiontype.webp",{"_index":729,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{}},"title":{}}],["imageenh",{"_index":1367,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["imagenet",{"_index":399,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["imageonlytransform",{"_index":991,"text":{"api_reference/core/transforms_interface/":{}},"title":{"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.ImageOnlyTransform":{}}}],["img",{"_index":257,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/transforms/":{}},"title":{}}],["imgaug",{"_index":59,"text":{"":{},"#api-reference":{},"api_reference/":{}},"title":{}}],["imgaug.transform",{"_index":1002,"text":{"api_reference/imgaug/transforms/":{}},"title":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#transforms-imgaugtransforms":{}}}],["imit",{"_index":290,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{}},"title":{}}],["implement",{"_index":975,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{}},"title":{}}],["import",{"_index":1107,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}}}],["imposs",{"_index":1270,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["improv",{"_index":46,"text":{"":{},"#introduction-to-image-augmentation":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}}}],["imread",{"_index":1159,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["incept",{"_index":1313,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["includ",{"_index":385,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}},"title":{}}],["incorrect",{"_index":1360,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["increas",{"_index":1397,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["index",{"_index":55,"text":{"":{},"#api-reference":{}},"title":{"api_reference/":{},"api_reference/augmentations/":{},"api_reference/core/":{},"api_reference/imgaug/":{},"api_reference/pytorch/":{}}}],["indic",{"_index":748,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}},"title":{}}],["industri",{"_index":10,"text":{"":{},"#welcome-to-albumentations-documentation":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{}},"title":{}}],["inf",{"_index":507,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["infer",{"_index":639,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{}},"title":{}}],["infinit",{"_index":1301,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}},"title":{}}],["info",{"_index":1181,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["inform",{"_index":1169,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{}}],["initi",{"_index":92,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"contributing/":{},"contributing/#contributing":{}},"title":{}}],["inpain",{"_index":769,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{}},"title":{}}],["inpaint",{"_index":768,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{}},"title":{}}],["input",{"_index":431,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["inria",{"_index":1255,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["insid",{"_index":1136,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{}}],["inspect",{"_index":898,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{}},"title":{}}],["inspir",{"_index":757,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{}},"title":{}}],["instal",{"_index":49,"text":{"":{},"#getting-started-with-albumentations":{},"contributing/":{},"contributing/#contributing":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/installation/":{},"getting_started/installation/#install-the-latest-stable-version-from-pypi":{},"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{}},"title":{"getting_started/installation/":{},"getting_started/installation/#install-the-latest-stable-version-from-pypi":{},"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{},"getting_started/installation/#installation":{}}}],["instanc",{"_index":38,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{}},"title":{}}],["instead",{"_index":1260,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}},"title":{}}],["int",{"_index":137,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["intact",{"_index":1379,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["integ",{"_index":980,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{}},"title":{}}],["intens",{"_index":424,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["interfac",{"_index":107,"text":{"api_reference/":{},"api_reference/core/":{},"api_reference/core/transforms_interface/":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_albumentations/#extensibility":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#transforms-interface-coretransforms_interface":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}}}],["intern",{"_index":371,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{}},"title":{}}],["interpol",{"_index":348,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["introduc",{"_index":1012,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["introduct",{"_index":22,"text":{"":{},"#welcome-to-albumentations-documentation":{}},"title":{"#introduction-to-image-augmentation":{}}}],["invari",{"_index":1380,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["invers",{"_index":207,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{}},"title":{}}],["invert",{"_index":488,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{}},"title":{}}],["invertimg",{"_index":731,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{}}}],["invis",{"_index":935,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["iso_nois",{"_index":422,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{}}}],["isonois",{"_index":733,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}}}],["issu",{"_index":74,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["it'",{"_index":765,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{}},"title":{}}],["item",{"_index":1156,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["iter",{"_index":664,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}},"title":{}}],["join",{"_index":913,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{}},"title":{}}],["jpeg",{"_index":720,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{}},"title":{}}],["jpegcompress",{"_index":741,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{}}}],["json",{"_index":965,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["k",{"_index":457,"text":{"api_reference/augmentations/functional/":{}},"title":{}}],["keep",{"_index":752,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["kernel",{"_index":505,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{}},"title":{}}],["key",{"_index":922,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_albumentations/":{}},"title":{"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{}}}],["keypoint",{"_index":114,"text":{"api_reference/":{},"api_reference/augmentations/":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoint":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoints":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{}},"title":{"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#helper-functions-for-working-with-keypoints-augmentationskeypoints_utils":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}}}],["keypoint_center_crop",{"_index":440,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{}}}],["keypoint_flip",{"_index":443,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{}}}],["keypoint_hflip",{"_index":444,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{}}}],["keypoint_param",{"_index":918,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{}},"title":{}}],["keypoint_random_crop",{"_index":445,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{}}}],["keypoint_rot",{"_index":450,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{}}}],["keypoint_rot90",{"_index":447,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{}}}],["keypoint_scal",{"_index":451,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{}}}],["keypoint_transpos",{"_index":454,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{}}}],["keypoint_vflip",{"_index":455,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{}}}],["keypointparam",{"_index":919,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{}},"title":{"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}}}],["keypointparams.angle_in_degre",{"_index":933,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["know",{"_index":1116,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["kp",{"_index":502,"text":{"api_reference/augmentations/keypoints_utils/":{}},"title":{}}],["krizhevsky'",{"_index":615,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["kwarg",{"_index":425,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}},"title":{}}],["label",{"_index":199,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}}}],["label_field",{"_index":911,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["labor",{"_index":1276,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["lambda",{"_index":742,"text":{"api_reference/augmentations/transforms/":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}}}],["lambda_transform",{"_index":958,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{}},"title":{}}],["lane",{"_index":469,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["larg",{"_index":609,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["larger",{"_index":871,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}},"title":{}}],["later",{"_index":946,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{}},"title":{}}],["latest",{"_index":1230,"text":{"getting_started/installation/":{}},"title":{"getting_started/installation/#install-the-latest-stable-version-from-pypi":{},"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{}}}],["lead",{"_index":872,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}},"title":{}}],["learn",{"_index":12,"text":{"":{},"#welcome-to-albumentations-documentation":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{}},"title":{}}],["left",{"_index":187,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["legal",{"_index":1283,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["length",{"_index":1250,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["less",{"_index":211,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoint":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoints":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["lesser",{"_index":148,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes":{}},"title":{}}],["let'",{"_index":1063,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["level",{"_index":439,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["li",{"_index":1135,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["librari",{"_index":7,"text":{"":{},"#introduction-to-image-augmentation":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"contributing/":{},"contributing/#contributing":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}}}],["licens",{"_index":1364,"text":{"introduction/why_albumentations/":{}},"title":{"introduction/why_albumentations/#it-is-open-source-and-mit-licensed":{}}}],["lie",{"_index":218,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{}},"title":{}}],["light",{"_index":1032,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{}},"title":{}}],["limit",{"_index":533,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["line",{"_index":837,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["linear",{"_index":774,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{}},"title":{}}],["linter",{"_index":90,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["lisf",{"_index":550,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}},"title":{}}],["lisft",{"_index":795,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{}},"title":{}}],["list",{"_index":201,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{}}}],["list[tupl",{"_index":202,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{}},"title":{}}],["littl",{"_index":1297,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}},"title":{}}],["load",{"_index":962,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"api_reference/core/serialization/#albumentations.core.serialization.load":{}}}],["loc",{"_index":1004,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{}},"title":{}}],["local",{"_index":81,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["locat",{"_index":1392,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["longer",{"_index":1158,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{}},"title":{}}],["longestmaxs",{"_index":749,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{}}}],["longtensor",{"_index":1055,"text":{"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["look",{"_index":165,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["lose",{"_index":253,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{}},"title":{}}],["loss",{"_index":859,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{}},"title":{}}],["lot",{"_index":1207,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["low",{"_index":995,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["lower",{"_index":555,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["lower_bond",{"_index":867,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}},"title":{}}],["luminac",{"_index":740,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}},"title":{}}],["machin",{"_index":14,"text":{"":{},"#welcome-to-albumentations-documentation":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{}},"title":{}}],["magnitud",{"_index":1222,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["main",{"_index":330,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{}},"title":{}}],["make",{"_index":97,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"contributing/":{},"contributing/#contributing":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["mani",{"_index":1183,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["manual",{"_index":1275,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["map",{"_index":603,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["mark",{"_index":1060,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["mask",{"_index":50,"text":{"":{},"#getting-started-with-albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensorV2":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_albumentations/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{}}}],["mask_1",{"_index":1244,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["mask_2",{"_index":1246,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["mask_3",{"_index":1248,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["mask_fill_valu",{"_index":707,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{}},"title":{}}],["mask_param",{"_index":613,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{}},"title":{}}],["mask_valu",{"_index":598,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["maskdropout",{"_index":754,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{}}}],["master'",{"_index":1234,"text":{"getting_started/installation/":{}},"title":{"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{}}}],["max",{"_index":662,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["max_delta",{"_index":661,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}},"title":{}}],["max_h_siz",{"_index":571,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}},"title":{}}],["max_height",{"_index":544,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{}},"title":{}}],["max_hol",{"_index":543,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{}},"title":{}}],["max_object",{"_index":762,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{}},"title":{}}],["max_part_shift",{"_index":817,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{}},"title":{}}],["max_pixel_valu",{"_index":789,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{}},"title":{}}],["max_siz",{"_index":751,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{}},"title":{}}],["max_valu",{"_index":634,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{}},"title":{}}],["max_w_siz",{"_index":572,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}},"title":{}}],["max_width",{"_index":546,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{}},"title":{}}],["maximum",{"_index":149,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["mayb",{"_index":386,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{}},"title":{}}],["mean",{"_index":656,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["measur",{"_index":734,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}},"title":{}}],["median",{"_index":772,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{}},"title":{}}],["medianblur",{"_index":771,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{}}}],["medic",{"_index":1278,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["metaclass",{"_index":942,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{}},"title":{}}],["method",{"_index":44,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{}},"title":{}}],["min",{"_index":766,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["min_area",{"_index":214,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}}}],["min_height",{"_index":548,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{}},"title":{}}],["min_hol",{"_index":547,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{}},"title":{}}],["min_max_height",{"_index":863,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{}},"title":{}}],["min_vis",{"_index":216,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}}}],["min_visiibl",{"_index":1129,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["min_width",{"_index":549,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{}},"title":{}}],["minim",{"_index":239,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["minimum",{"_index":147,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["mirror",{"_index":1300,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["mirrored_imag",{"_index":1369,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["mislead",{"_index":1383,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["mit",{"_index":1363,"text":{"introduction/why_albumentations/":{}},"title":{"introduction/why_albumentations/#it-is-open-source-and-mit-licensed":{}}}],["mlrg/cutout/blob/master/util/cutout.pi",{"_index":553,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}},"title":{}}],["mode",{"_index":94,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"contributing/":{},"contributing/#contributing":{}},"title":{}}],["model",{"_index":1306,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{}},"title":{}}],["modif",{"_index":357,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["modifi",{"_index":1202,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["money",{"_index":1289,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["more",{"_index":221,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["motion",{"_index":776,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{}},"title":{}}],["motionblur",{"_index":775,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{}}}],["move",{"_index":1009,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["mu=0",{"_index":618,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["much",{"_index":249,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"introduction/image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}}}],["multipl",{"_index":435,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["multipli",{"_index":206,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{}}}],["multiplicativenois",{"_index":777,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{}}}],["multiplier[0",{"_index":778,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{}},"title":{}}],["multiplier[1",{"_index":779,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{}},"title":{}}],["n_segment",{"_index":1046,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["name",{"_index":127,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["nb_col",{"_index":1029,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["nb_row",{"_index":1028,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["need",{"_index":47,"text":{"":{},"#introduction-to-image-augmentation":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}}}],["neighbourhood",{"_index":1010,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["network",{"_index":27,"text":{"":{},"#introduction-to-image-augmentation":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}}}],["networks.pdf",{"_index":400,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["neural",{"_index":26,"text":{"":{},"#introduction-to-image-augmentation":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}}}],["new",{"_index":19,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#extensibility":{}},"title":{}}],["next",{"_index":1130,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["nois",{"_index":427,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{}},"title":{}}],["non",{"_index":557,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{}},"title":{}}],["none",{"_index":351,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["noop",{"_index":992,"text":{"api_reference/core/transforms_interface/":{}},"title":{"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.NoOp":{}}}],["normal",{"_index":184,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{}}}],["normalize_bbox",{"_index":243,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{}}}],["note",{"_index":164,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["noth",{"_index":993,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.NoOp":{}},"title":{}}],["notic",{"_index":437,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{}},"title":{}}],["notimplementederror",{"_index":977,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{}},"title":{}}],["now",{"_index":1113,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["np",{"_index":1215,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{}},"title":{}}],["np.ndarray",{"_index":493,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{}},"title":{}}],["np.rot90",{"_index":321,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{}},"title":{}}],["num_bit",{"_index":796,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{}},"title":{}}],["num_class",{"_index":1053,"text":{"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["num_flare_circles_low",{"_index":877,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["num_flare_circles_upp",{"_index":878,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["num_hol",{"_index":570,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}},"title":{}}],["num_shadows_low",{"_index":853,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{}},"title":{}}],["num_shadows_upp",{"_index":854,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{}},"title":{}}],["num_step",{"_index":414,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{}},"title":{}}],["number",{"_index":292,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["numpi",{"_index":401,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["numpy.ndarray",{"_index":265,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{}},"title":{}}],["obj",{"_index":968,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{}},"title":{}}],["obj1_mask",{"_index":987,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{}},"title":{}}],["obj2_mask",{"_index":988,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{}},"title":{}}],["object",{"_index":39,"text":{"":{},"#getting-started-with-albumentations":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation-for-object-detection":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}}}],["obtain",{"_index":1262,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["odd",{"_index":650,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{}},"title":{}}],["offset",{"_index":697,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["old",{"_index":923,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{}},"title":{}}],["old_left_up_corner_col",{"_index":497,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{}},"title":{}}],["old_left_up_corner_row",{"_index":496,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{}},"title":{}}],["on",{"_index":586,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}},"title":{}}],["on_not_implemented_error",{"_index":971,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{}},"title":{}}],["onc",{"_index":784,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{}},"title":{}}],["oneof",{"_index":937,"text":{"api_reference/core/composition/":{}},"title":{"api_reference/core/composition/#albumentations.core.composition.OneOf":{}}}],["open",{"_index":16,"text":{"":{},"#welcome-to-albumentations-documentation":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{"introduction/why_albumentations/#it-is-open-source-and-mit-licensed":{}}}],["opencv",{"_index":390,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["oper",{"_index":208,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["optical_distort",{"_index":456,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}}}],["opticaldistort",{"_index":790,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{}}}],["optim",{"_index":1346,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["optin",{"_index":746,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}},"title":{}}],["option",{"_index":383,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["order",{"_index":1206,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["orient",{"_index":931,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["origin",{"_index":240,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["original_shap",{"_index":233,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{}},"title":{}}],["ot",{"_index":198,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{}},"title":{}}],["otherwis",{"_index":517,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["out",{"_index":289,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}},"title":{}}],["output",{"_index":158,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["outsid",{"_index":219,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{}},"title":{}}],["overfit",{"_index":1265,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["overlay",{"_index":1017,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{}},"title":{}}],["p",{"_index":509,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["p=0.5",{"_index":1200,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["p_replac",{"_index":1040,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["pad",{"_index":597,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["padifneed",{"_index":792,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{}}}],["page",{"_index":644,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{}},"title":{}}],["palett",{"_index":1390,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["paper",{"_index":410,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["param",{"_index":448,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["paramet",{"_index":126,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["parrot",{"_index":1177,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["parrot.jpg",{"_index":1368,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["part",{"_index":515,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["partial",{"_index":1035,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["pascal",{"_index":1080,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{}},"title":{}}],["pascal_voc",{"_index":160,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{"getting_started/bounding_boxes_augmentation/#pascal_voc":{}}}],["pass",{"_index":939,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}},"title":{"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}}}],["patch",{"_index":1199,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["path/to/image.jpg",{"_index":1160,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["path/to/mask.png",{"_index":1242,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["path/to/mask_1.png",{"_index":1245,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["path/to/mask_2.png",{"_index":1247,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["path/to/mask_3.png",{"_index":1249,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["pay",{"_index":1291,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["pca",{"_index":397,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["per",{"_index":745,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["per_channel",{"_index":782,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{}},"title":{}}],["perchannel",{"_index":938,"text":{"api_reference/core/composition/":{}},"title":{"api_reference/core/composition/#albumentations.core.composition.PerChannel":{}}}],["perform",{"_index":28,"text":{"":{},"#introduction-to-image-augmentation":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/#high-performance":{}}}],["perspect",{"_index":1022,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{}},"title":{}}],["perturb/scal",{"_index":406,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["photo",{"_index":1257,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["pick",{"_index":887,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{}},"title":{}}],["piec",{"_index":1299,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}},"title":{}}],["pil",{"_index":389,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["pillow",{"_index":391,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{"getting_started/image_augmentation/#pillow":{}}}],["pillow_imag",{"_index":1216,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{}},"title":{}}],["pincushion",{"_index":461,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["pip",{"_index":91,"text":{"contributing/":{},"contributing/#contributing":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/installation/":{},"getting_started/installation/#install-the-latest-stable-version-from-pypi":{},"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{}},"title":{}}],["pipelin",{"_index":948,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#extensibility":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}}}],["pitfal",{"_index":1378,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["pixel",{"_index":125,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["pixelwis",{"_index":785,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{}},"title":{}}],["place",{"_index":1008,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["platt",{"_index":363,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["playground",{"_index":1192,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["pleas",{"_index":1050,"text":{"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["point",{"_index":293,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"introduction/why_albumentations/":{}},"title":{"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{}}}],["poisson",{"_index":426,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{}},"title":{}}],["polygon",{"_index":856,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["popular",{"_index":1095,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["pose",{"_index":1343,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{}},"title":{}}],["possibl",{"_index":642,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["poster",{"_index":470,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{}}}],["practic",{"_index":365,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["pre",{"_index":82,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["prepar",{"_index":1167,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{}}],["present",{"_index":1127,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["preserv",{"_index":477,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_channel_dim":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_shape":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["preserve_channel_dim",{"_index":476,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_channel_dim":{}}}],["preserve_shap",{"_index":480,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_shape":{}}}],["prevent",{"_index":1264,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["probabl",{"_index":510,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}}}],["problem",{"_index":1388,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["proc",{"_index":370,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["process",{"_index":1104,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["produc",{"_index":436,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{}},"title":{}}],["programmat",{"_index":467,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["project",{"_index":18,"text":{"":{},"#welcome-to-albumentations-documentation":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{}},"title":{}}],["provid",{"_index":337,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{}},"title":{}}],["publish",{"_index":1318,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["pull",{"_index":77,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["push",{"_index":100,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["py3round",{"_index":481,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.py3round":{}}}],["pypi",{"_index":1232,"text":{"getting_started/installation/":{}},"title":{"getting_started/installation/#install-the-latest-stable-version-from-pypi":{}}}],["pytest",{"_index":99,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["python",{"_index":484,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.py3round":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#pillow":{},"getting_started/installation/":{},"getting_started/installation/#installation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["pytorch",{"_index":62,"text":{"":{},"#api-reference":{},"api_reference/":{}},"title":{}}],["pytorch.transform",{"_index":1047,"text":{"api_reference/pytorch/transforms/":{}},"title":{"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#transforms-pytorchtransforms":{}}}],["qualiti",{"_index":575,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"introduction/image_augmentation/":{}},"title":{"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}}}],["quality_low",{"_index":723,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{}},"title":{}}],["quality_upp",{"_index":725,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{}},"title":{}}],["r",{"_index":797,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["r1",{"_index":800,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{}},"title":{}}],["r_shift_limit",{"_index":880,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{}},"title":{}}],["radian",{"_index":932,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["rain",{"_index":833,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["rain_drop",{"_index":275,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{}},"title":{}}],["rain_typ",{"_index":838,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["raini",{"_index":276,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["rais",{"_index":972,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{}},"title":{}}],["random",{"_index":446,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["random_offset",{"_index":704,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["random_st",{"_index":352,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{}},"title":{}}],["randombright",{"_index":805,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{}}}],["randombrightnesscontrast",{"_index":807,"text":{"api_reference/augmentations/transforms/":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{}}}],["randomcontrast",{"_index":812,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{}}}],["randomcrop",{"_index":813,"text":{"api_reference/augmentations/transforms/":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{}}}],["randomcropnearbbox",{"_index":814,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{}}}],["randomfog",{"_index":818,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{}}}],["randomgamma",{"_index":822,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{}}}],["randomgridshuffl",{"_index":828,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{}}}],["randomli",{"_index":522,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["randomrain",{"_index":832,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}}}],["randomresizedcrop",{"_index":842,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{}}}],["randomrotate90",{"_index":846,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{}}}],["randomscal",{"_index":848,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{}}}],["randomshadow",{"_index":850,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{}}}],["randomsizedbboxsafecrop",{"_index":857,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{}}}],["randomsizedcrop",{"_index":862,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{}}}],["randomsnow",{"_index":865,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}}}],["randomsunflar",{"_index":873,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}}}],["rang",{"_index":144,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.check_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{}},"title":{}}],["range(0",{"_index":412,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{}},"title":{}}],["rate",{"_index":860,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{}},"title":{}}],["ratio",{"_index":679,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["read",{"_index":969,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#pillow":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}}}],["rearrang",{"_index":530,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{}},"title":{}}],["reason",{"_index":1212,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["receiv",{"_index":1109,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}}}],["recognit",{"_index":373,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["recommend",{"_index":516,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{}},"title":{}}],["rectangl",{"_index":1059,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["rectangular",{"_index":541,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["red",{"_index":881,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["reduc",{"_index":472,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{}},"title":{}}],["refer",{"_index":42,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.grid_distortion":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{"#api-reference":{}}}],["reflect",{"_index":1310,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["region",{"_index":542,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["regist",{"_index":943,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{}},"title":{}}],["regrad",{"_index":916,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{}},"title":{}}],["regress",{"_index":1405,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["regular",{"_index":419,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.grid_distortion":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{}},"title":{}}],["regularli",{"_index":1348,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["remain",{"_index":231,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["remov",{"_index":217,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["remove_invis",{"_index":934,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["repeat",{"_index":665,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}},"title":{}}],["replac",{"_index":1042,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["repo",{"_index":101,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["report",{"_index":1406,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["repositori",{"_index":79,"text":{"contributing/":{},"contributing/#contributing":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["repres",{"_index":1064,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["represent",{"_index":394,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["request",{"_index":72,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["requir",{"_index":136,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/installation/":{},"getting_started/installation/#installation":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}}}],["rescal",{"_index":750,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{}},"title":{}}],["rescu",{"_index":1295,"text":{"introduction/image_augmentation/":{}},"title":{"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}}}],["research",{"_index":13,"text":{"":{},"#welcome-to-albumentations-documentation":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{}},"title":{}}],["resiz",{"_index":845,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{}}}],["resnet",{"_index":1314,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["respect",{"_index":961,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["restor",{"_index":960,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{}},"title":{}}],["restrict",{"_index":1284,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["result",{"_index":636,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["return",{"_index":140,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}},"title":{}}],["rgb",{"_index":381,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["rgbshift",{"_index":879,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{}}}],["right",{"_index":189,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["rigor",{"_index":1355,"text":{"introduction/why_albumentations/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{}},"title":{"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}}}],["risk",{"_index":1387,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["road",{"_index":264,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["rotat",{"_index":316,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{}}}],["rotate_limit",{"_index":893,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["rotated_imag",{"_index":1371,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["round",{"_index":483,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.py3round":{}},"title":{}}],["row",{"_index":121,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["rule",{"_index":1381,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["run",{"_index":84,"text":{"contributing/":{},"contributing/#contributing":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["s",{"_index":930,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["same",{"_index":681,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}}}],["sampl",{"_index":616,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["sat_shift_limit",{"_index":716,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{}},"title":{}}],["satellit",{"_index":1290,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["satur",{"_index":713,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{}},"title":{}}],["save",{"_index":970,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{}},"title":{"api_reference/core/serialization/#albumentations.core.serialization.save":{}}}],["scalar",{"_index":997,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["scale",{"_index":343,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["scale_i",{"_index":453,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{}},"title":{}}],["scale_limit",{"_index":849,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["scale_max",{"_index":579,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{}},"title":{}}],["scale_min",{"_index":578,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{}},"title":{}}],["scale_x",{"_index":452,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{}},"title":{}}],["scene",{"_index":1292,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["scikit",{"_index":622,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["second",{"_index":1000,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["secondari",{"_index":331,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{}},"title":{}}],["section",{"_index":23,"text":{"":{},"#welcome-to-albumentations-documentation":{}},"title":{}}],["see",{"_index":320,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{}},"title":{}}],["seen",{"_index":630,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{}},"title":{}}],["segment",{"_index":37,"text":{"":{},"#getting-started-with-albumentations":{},"#welcome-to-albumentations-documentation":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.DualTransform":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}}}],["select",{"_index":384,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{}},"title":{}}],["self",{"_index":627,"text":{"api_reference/augmentations/transforms/":{},"api_reference/core/transforms_interface/":{}},"title":{}}],["semant",{"_index":36,"text":{"":{},"#welcome-to-albumentations-documentation":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["sensor",{"_index":430,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}},"title":{}}],["separ",{"_index":392,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{}},"title":{"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{}}}],["sepia",{"_index":904,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{}},"title":{}}],["serial",{"_index":104,"text":{"api_reference/":{},"api_reference/core/":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#serialization-api-coreserialization":{}}}],["serializ",{"_index":979,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{}},"title":{}}],["serializable_registri",{"_index":944,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{}},"title":{}}],["serializablemeta",{"_index":941,"text":{"api_reference/core/serialization/":{}},"title":{"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{}}}],["set",{"_index":225,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{}}}],["setup",{"_index":689,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["shadi",{"_index":281,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["shadow",{"_index":284,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{}},"title":{}}],["shadow_dimens",{"_index":855,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{}},"title":{}}],["shadow_roi",{"_index":851,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{}},"title":{}}],["shape",{"_index":241,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.preserve_shape":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoint":{},"api_reference/augmentations/keypoints_utils/#albumentations.augmentations.keypoints_utils.check_keypoints":{}},"title":{}}],["sharpen",{"_index":1031,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{}},"title":{}}],["shift",{"_index":815,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["shift_i",{"_index":702,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["shift_limit",{"_index":791,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["shift_x",{"_index":696,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["shiftscalerot",{"_index":888,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}}}],["shorter",{"_index":685,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["show",{"_index":30,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["shrink",{"_index":251,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{}},"title":{}}],["shuffl",{"_index":829,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{}},"title":{}}],["side",{"_index":673,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{}},"title":{}}],["sigma",{"_index":346,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{}},"title":{}}],["sigma=alpha",{"_index":619,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["sigmoid",{"_index":1054,"text":{"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["signatur",{"_index":611,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta.__new__":{}},"title":{}}],["silent",{"_index":1356,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["simard",{"_index":361,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["simard2003",{"_index":360,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["simard2003]_",{"_index":356,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["similar",{"_index":1089,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{}},"title":{}}],["simpl",{"_index":1366,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["simplifi",{"_index":1253,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["simul",{"_index":428,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["simultan",{"_index":1241,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}},"title":{}}],["singl",{"_index":537,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_albumentations/#extensibility":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{}}}],["situat",{"_index":1385,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["size",{"_index":228,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["skimage'",{"_index":1037,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["slant",{"_index":269,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{}},"title":{}}],["slant_low",{"_index":835,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["slant_upp",{"_index":836,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["slic",{"_index":1038,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["slightli",{"_index":1296,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{}},"title":{}}],["slow",{"_index":1039,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["small",{"_index":1394,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["smaller",{"_index":695,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["smallest",{"_index":896,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{}},"title":{}}],["smallestmaxs",{"_index":895,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{}}}],["smooth",{"_index":601,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["snow",{"_index":291,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}},"title":{}}],["snow_point",{"_index":286,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{}},"title":{}}],["snow_point_low",{"_index":866,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}},"title":{}}],["snow_point_upp",{"_index":869,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}},"title":{}}],["solar",{"_index":486,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{}}}],["sometim",{"_index":1243,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["sourc",{"_index":17,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{},"introduction/why_albumentations/#it-is-open-source-and-mit-licensed":{}},"title":{"introduction/why_albumentations/#it-is-open-source-and-mit-licensed":{}}}],["source_format",{"_index":183,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations":{}},"title":{}}],["space",{"_index":248,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{}},"title":{}}],["spatial",{"_index":1123,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["special",{"_index":629,"text":{"api_reference/augmentations/transforms/":{},"api_reference/core/serialization/":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["specif",{"_index":1061,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["specifi",{"_index":156,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["speed",{"_index":376,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["speedup",{"_index":608,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["split",{"_index":831,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{}},"title":{}}],["sport",{"_index":1139,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["squar",{"_index":569,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{}},"title":{}}],["src_color",{"_index":299,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["src_radiu",{"_index":298,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["stabl",{"_index":1231,"text":{"getting_started/installation/":{}},"title":{"getting_started/installation/#install-the-latest-stable-version-from-pypi":{}}}],["standard",{"_index":659,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{}},"title":{}}],["start",{"_index":20,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{"#getting-started-with-albumentations":{}}}],["state",{"_index":1304,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["staticmethod",{"_index":953,"text":{"api_reference/core/serialization/":{}},"title":{}}],["std",{"_index":788,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["std=0.1",{"_index":411,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{}},"title":{}}],["steel",{"_index":759,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{}},"title":{}}],["steinkrau",{"_index":362,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{}},"title":{}}],["step",{"_index":1106,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#bounding-boxes-augmentation":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#image-augmentation-for-classification":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}},"title":{"getting_started/bounding_boxes_augmentation/#step-1-import-the-required-libraries":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}}}],["store",{"_index":1163,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["str",{"_index":157,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{}},"title":{}}],["strength",{"_index":739,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{}},"title":{}}],["string",{"_index":643,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{}},"title":{}}],["subimage'",{"_index":1023,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{}},"title":{}}],["subtract",{"_index":732,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{}},"title":{}}],["success",{"_index":1312,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["such",{"_index":1172,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["suit",{"_index":1362,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["sun",{"_index":301,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{}},"title":{}}],["superpixel",{"_index":1036,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["support",{"_index":434,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{}},"title":{"introduction/why_albumentations/#diverse-set-of-supported-augmentations":{}}}],["swap",{"_index":492,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{}},"title":{}}],["swap_tiles_on_imag",{"_index":490,"text":{"api_reference/augmentations/functional/":{}},"title":{"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{}}}],["tabl",{"_index":1324,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["take",{"_index":633,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{}},"title":{}}],["target",{"_index":511,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["target_format",{"_index":151,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{}},"title":{}}],["target_imag",{"_index":986,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{}},"title":{}}],["task",{"_index":34,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.DualTransform":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}}}],["team/albument",{"_index":68,"text":{"contributing/":{},"contributing/#contributing":{},"getting_started/installation/":{},"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{}},"title":{}}],["team/albumentations/issu",{"_index":75,"text":{"contributing/":{},"contributing/#contributing":{}},"title":{}}],["techniqu",{"_index":1303,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["tell",{"_index":1134,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{}},"title":{}}],["test",{"_index":96,"text":{"contributing/":{},"contributing/#contributing":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{"introduction/why_albumentations/#battle-tested":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}}}],["those",{"_index":237,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["three",{"_index":1137,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["threshold",{"_index":224,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["through",{"_index":1205,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#extensibility":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["tile",{"_index":491,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{}},"title":{}}],["tile_grid_s",{"_index":538,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{}},"title":{}}],["time",{"_index":847,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["to_dict",{"_index":976,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{}},"title":{"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{}}}],["to_tupl",{"_index":994,"text":{"api_reference/core/transforms_interface/":{}},"title":{"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}}}],["tofloat",{"_index":897,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{}}}],["togray",{"_index":900,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{}}}],["tool",{"_index":1252,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{}},"title":{}}],["top",{"_index":188,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["topic",{"_index":53,"text":{"":{}},"title":{"#other-topics":{}}}],["torch.tensor",{"_index":1049,"text":{"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensorV2":{}},"title":{}}],["torchvision'",{"_index":843,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{}},"title":{}}],["torchvision.norm",{"_index":1056,"text":{"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["torresti",{"_index":841,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["tosepia",{"_index":903,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{}}}],["totensor",{"_index":1048,"text":{"api_reference/pytorch/transforms/":{}},"title":{"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}}}],["totensorv2",{"_index":1057,"text":{"api_reference/pytorch/transforms/":{}},"title":{"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensorV2":{}}}],["train",{"_index":1261,"text":{"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["tranform",{"_index":708,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["transform",{"_index":106,"text":{"api_reference/":{},"api_reference/augmentations/":{},"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.DualTransform":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.ImageOnlyTransform":{},"api_reference/imgaug/":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"api_reference/pytorch/":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/image_augmentation/#image-augmentation-to-the-rescue":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#extensibility":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#functional-transforms-augmentationsfunctional":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#transforms-augmentationstransforms":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#transforms-interface-coretransforms_interface":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#transforms-imgaugtransforms":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#transforms-pytorchtransforms":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}}}],["transform_dict",{"_index":957,"text":{"api_reference/core/serialization/":{}},"title":{}}],["transformed_bbox",{"_index":235,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["transformed_class_categori",{"_index":1182,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["transformed_class_label",{"_index":1179,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{}},"title":{}}],["transformed_imag",{"_index":1176,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}},"title":{}}],["transformed_image_1",{"_index":1225,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["transformed_image_2",{"_index":1226,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["transformed_image_3",{"_index":1227,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["transformed_mask",{"_index":1254,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{}},"title":{}}],["transformed_shap",{"_index":234,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{}},"title":{}}],["translat",{"_index":890,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["transpar",{"_index":821,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{}},"title":{}}],["transpos",{"_index":327,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{}}}],["treat",{"_index":756,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{}},"title":{}}],["tri",{"_index":638,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{}},"title":{}}],["true",{"_index":379,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["tupl",{"_index":131,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{}},"title":{}}],["two",{"_index":1128,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["type",{"_index":128,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_fog":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_snow":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_sun_flare":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.multiply":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.posterize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"api_reference/core/composition/#albumentations.core.composition.OneOf":{},"api_reference/core/composition/#albumentations.core.composition.PerChannel":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.from_dict":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAdditiveGaussianNoise":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["u",{"_index":1233,"text":{"getting_started/installation/":{},"getting_started/installation/#install-the-latest-stable-version-from-pypi":{},"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{}},"title":{}}],["uint16",{"_index":527,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{}},"title":{}}],["uint8",{"_index":433,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GlassBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.LongestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightness":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomContrast":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGridShuffle":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.SmallestMaxSize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToSepia":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Transpose":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["unchang",{"_index":1203,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["unconvent",{"_index":462,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{}},"title":{}}],["under",{"_index":223,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{}},"title":{}}],["unifi",{"_index":482,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.py3round":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}}}],["uniform",{"_index":886,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{}},"title":{}}],["union",{"_index":247,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{}},"title":{}}],["union_of_bbox",{"_index":245,"text":{"api_reference/augmentations/bbox_utils/":{}},"title":{"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{}}}],["unit",{"_index":684,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["unit32",{"_index":528,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{}},"title":{}}],["unit_s",{"_index":680,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["unit_size_max",{"_index":690,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["unit_size_min",{"_index":683,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["unit_width",{"_index":700,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["unlik",{"_index":1090,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["unnot",{"_index":1359,"text":{"introduction/why_albumentations/":{},"introduction/why_albumentations/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["updat",{"_index":1174,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["upper",{"_index":536,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.JpegCompression":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomFog":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{}},"title":{}}],["upper_bond",{"_index":870,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{}},"title":{}}],["upscal",{"_index":576,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Downscale":{}},"title":{}}],["us",{"_index":9,"text":{"":{},"#welcome-to-albumentations-documentation":{},"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.optical_distortion":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Blur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MedianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MotionBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.SerializableMeta":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-pass-class-labels-along-with-coordinates":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{},"introduction/why_albumentations/#extensibility":{},"introduction/why_albumentations/#high-performance":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["usag",{"_index":1052,"text":{"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["user",{"_index":743,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["usual",{"_index":280,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["util",{"_index":1208,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-3-read-images-from-the-disk":{}},"title":{}}],["val",{"_index":409,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["val_shift_limit",{"_index":718,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{}},"title":{}}],["valid",{"_index":163,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{}},"title":{}}],["valu",{"_index":197,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.iso_noise":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.solarize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CLAHE":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ChannelDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FromFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.InvertImg":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MultiplicativeNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.OpticalDistortion":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Posterize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomGamma":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomScale":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSnow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Rotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Solarize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToFloat":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ToGray":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.Compose":{},"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.to_tuple":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPerspective":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{"getting_started/bounding_boxes_augmentation/#1-you-can-pass-labels-along-with-bounding-boxes-coordinates-by-adding-them-as-additional-values-to-the-list-of-coordinates":{}}}],["valueerror",{"_index":180,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{}},"title":{}}],["var_limit",{"_index":652,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{}},"title":{}}],["varianc",{"_index":653,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussNoise":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ISONoise":{}},"title":{}}],["variant",{"_index":844,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{}},"title":{}}],["vec",{"_index":408,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA":{}},"title":{}}],["veri",{"_index":1238,"text":{"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#mask-augmentation-for-segmentation":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["version",{"_index":485,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.py3round":{},"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/installation/":{}},"title":{"getting_started/installation/#install-the-latest-stable-version-from-pypi":{},"getting_started/installation/#install-the-latest-version-from-the-masters-branch-on-github":{}}}],["vertic",{"_index":307,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Flip.apply":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{}},"title":{}}],["verticalflip",{"_index":906,"text":{"api_reference/augmentations/transforms/":{}},"title":{"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{}}}],["vertices_list",{"_index":283,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_shadow":{}},"title":{}}],["via",{"_index":1011,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAAffine":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAPiecewiseAffine":{}},"title":{}}],["view",{"_index":277,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.add_rain":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRain":{}},"title":{}}],["visibl",{"_index":220,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASharpen":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}],["visible,at",{"_index":1018,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAAEmboss":{}},"title":{}}],["vision",{"_index":33,"text":{"":{},"#welcome-to-albumentations-documentation":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-1-import-the-required-libraries":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_albumentations/#extensibility":{}},"title":{}}],["visual",{"_index":368,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.elastic_transform_approx":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{}},"title":{}}],["voc",{"_index":1081,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{}},"title":{}}],["volum",{"_index":254,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{}},"title":{}}],["w",{"_index":403,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.fancy_pca":{}},"title":{}}],["w2h_ratio",{"_index":864,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{}},"title":{}}],["w_start",{"_index":442,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{}},"title":{}}],["want",{"_index":1185,"text":{"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/image_augmentation/#step-4-pass-images-to-the-augmentation-pipeline-and-receive-augmented-images":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}},"title":{}}],["warn",{"_index":978,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"api_reference/core/serialization/#albumentations.core.serialization.to_dict":{},"api_reference/pytorch/transforms/":{},"api_reference/pytorch/transforms/#albumentations.pytorch.transforms.ToTensor":{}},"title":{}}],["way",{"_index":984,"text":{"api_reference/core/transforms_interface/":{},"api_reference/core/transforms_interface/#albumentations.core.transforms_interface.BasicTransform.add_targets":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#class-labels-for-bounding-boxes":{},"getting_started/bounding_boxes_augmentation/#step-4-pass-an-image-and-bounding-boxes-to-the-augmentation-pipeline-and-receive-augmented-images-and-boxes":{}},"title":{}}],["weather",{"_index":705,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["webp",{"_index":721,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ImageCompression":{}},"title":{}}],["welcom",{"_index":0,"text":{"":{}},"title":{"":{},"#welcome-to-albumentations-documentation":{}}}],["well",{"_index":1098,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2you-can-pass-labels-for-bounding-boxes-as-a-separate-list":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-4-pass-image-and-masks-to-the-augmentation-pipeline-and-receive-augmented-images-and-masks":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#how-much-does-image-augmentation-improves-the-quality-and-performance-of-deep-neural-networks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#why-you-need-a-dedicated-library-for-image-augmentation":{}},"title":{}}],["whatev",{"_index":694,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["whether",{"_index":600,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ElasticTransform":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Lambda":{}},"title":{}}],["whose",{"_index":222,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["wide",{"_index":8,"text":{"":{},"#welcome-to-albumentations-documentation":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#battle-tested":{}},"title":{}}],["width",{"_index":139,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CropNonEmptyMaskIfExists":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.PadIfNeeded":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomResizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedCrop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Resize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.ShiftScaleRotate":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#2-pass-class-labels-in-a-separate-argument-to-transform":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/mask_augmentation/":{},"getting_started/mask_augmentation/#step-3-read-images-and-masks-from-the-disk":{},"getting_started/mask_augmentation/#steps-1-and-2-import-the-required-libraries-and-define-an-augmentation-pipeline":{}},"title":{}}],["width//2",{"_index":691,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{}},"title":{}}],["width_til",{"_index":499,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.swap_tiles_on_image":{}},"title":{}}],["within",{"_index":1045,"text":{"api_reference/imgaug/transforms/":{},"api_reference/imgaug/transforms/#albumentations.imgaug.transforms.IAASuperpixels":{}},"title":{}}],["without",{"_index":858,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSizedBBoxSafeCrop":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["won't",{"_index":1125,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{},"getting_started/image_augmentation/":{},"getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#rigorous-testing":{}},"title":{}}],["word",{"_index":909,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{}},"title":{}}],["work",{"_index":112,"text":{"api_reference/":{},"api_reference/augmentations/":{},"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"introduction/image_augmentation/":{},"introduction/image_augmentation/#what-is-image-augmentation-and-how-it-can-improve-the-performance-of-deep-neural-networks":{},"introduction/why_albumentations/":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{}},"title":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#helper-functions-for-working-with-bounding-boxes-augmentationsbbox_utils":{},"api_reference/augmentations/keypoints_utils/":{},"api_reference/augmentations/keypoints_utils/#helper-functions-for-working-with-keypoints-augmentationskeypoints_utils":{},"introduction/why_albumentations/#a-single-interface-to-work-with-images-masks-bounding-boxes-and-key-points":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#working-with-probabilities":{}}}],["wors",{"_index":520,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CenterCrop":{}},"title":{}}],["write",{"_index":973,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{}},"title":{}}],["wrong",{"_index":1382,"text":{"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#the-need-to-apply-the-same-transform-to-an-image-and-for-labels-for-segmentation-object-detection-and-keypoint-detection-tasks":{}},"title":{}}],["x",{"_index":173,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.VerticalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#yolo":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["x,i",{"_index":816,"text":{"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomCropNearBBox":{}},"title":{}}],["x1",{"_index":338,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{}},"title":{}}],["x2",{"_index":340,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{}},"title":{}}],["x_center",{"_index":1096,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["x_max",{"_index":134,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{}},"title":{}}],["x_min",{"_index":132,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{}},"title":{}}],["xml",{"_index":1164,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{}},"title":{}}],["xstep",{"_index":416,"text":{"api_reference/augmentations/functional/":{}},"title":{}}],["xy",{"_index":926,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["xya",{"_index":928,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["xysa",{"_index":929,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["y",{"_index":174,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_center_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_random_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_scale":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.keypoint_vflip":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GridDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HorizontalFlip":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["y1",{"_index":339,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{}},"title":{}}],["y2",{"_index":341,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_keypoint_by_coords":{}},"title":{}}],["y_center",{"_index":1097,"text":{"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{}}],["y_max",{"_index":135,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{}},"title":{}}],["y_min",{"_index":133,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.calculate_bbox_area":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.filter_bboxes_by_visibility":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bboxes":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.union_of_bboxes":{},"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_crop":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_flip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_hflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rot90":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_rotate":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_transpose":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.bbox_vflip":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.crop_bbox_by_coords":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Crop":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomShadow":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomSunFlare":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#albumentations":{},"getting_started/bounding_boxes_augmentation/#coco":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#pascal_voc":{}},"title":{}}],["yaml",{"_index":966,"text":{"api_reference/core/serialization/":{},"api_reference/core/serialization/#albumentations.core.serialization.load":{},"api_reference/core/serialization/#albumentations.core.serialization.save":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/":{},"introduction/why_you_need_a_dedicated_library_for_image_augmentation/#declarative-definition-of-the-augmentation-pipeline-and-unified-interface":{}},"title":{}}],["ycbcr",{"_index":393,"text":{"api_reference/augmentations/functional/":{},"api_reference/augmentations/functional/#albumentations.augmentations.functional.equalize":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Equalize":{}},"title":{}}],["yolo",{"_index":161,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_from_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bbox_to_albumentations":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.convert_bboxes_from_albumentations":{},"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.BboxParams":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#different-annotations-formats":{},"getting_started/bounding_boxes_augmentation/#step-2-define-an-augmentation-pipeline":{},"getting_started/bounding_boxes_augmentation/#step-3-read-images-and-bounding-boxes-from-the-disk":{},"getting_started/bounding_boxes_augmentation/#yolo":{}},"title":{"getting_started/bounding_boxes_augmentation/#yolo":{}}}],["ystep",{"_index":417,"text":{"api_reference/augmentations/functional/":{}},"title":{}}],["yx",{"_index":927,"text":{"api_reference/core/composition/":{},"api_reference/core/composition/#albumentations.core.composition.KeypointParams":{}},"title":{}}],["zero",{"_index":212,"text":{"api_reference/augmentations/bbox_utils/":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.denormalize_bbox":{},"api_reference/augmentations/bbox_utils/#albumentations.augmentations.bbox_utils.normalize_bbox":{},"api_reference/augmentations/transforms/":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.CoarseDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Cutout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.GaussianBlur":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.MaskDropout.__init__":{},"api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomRotate90":{},"getting_started/bounding_boxes_augmentation/":{},"getting_started/bounding_boxes_augmentation/#min_area-and-min_visibility":{}},"title":{}}]],"pipeline":["stemmer"],"version":"2.3.8"}}